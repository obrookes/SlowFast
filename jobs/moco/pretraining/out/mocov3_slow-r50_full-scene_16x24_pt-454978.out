	CUDA-11.2 loaded

config files: ['configs/contrastive_ssl/MoCo_SlowR50_FullScene_16x24.yaml']
[03/30 19:36:54][INFO] train_net.py:  536: Train with config:
[03/30 19:36:54][INFO] train_net.py:  537: {'AUG': {'AA_TYPE': 'rand-m9-mstd0.5-inc1',
         'COLOR_JITTER': 0.4,
         'ENABLE': False,
         'GEN_MASK_LOADER': False,
         'INTERPOLATION': 'bicubic',
         'MASK_FRAMES': False,
         'MASK_RATIO': 0.0,
         'MASK_TUBE': False,
         'MASK_WINDOW_SIZE': [8, 7, 7],
         'MAX_MASK_PATCHES_PER_BLOCK': None,
         'NUM_SAMPLE': 1,
         'RE_COUNT': 1,
         'RE_MODE': 'pixel',
         'RE_PROB': 0.25,
         'RE_SPLIT': False},
 'AVA': {'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.9,
         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv',
         'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/',
         'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'],
         'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'],
         'TRAIN_LISTS': ['train.csv'],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': [],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'GLOBAL_SYNC': False,
        'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'CONTRASTIVE': {'BN_MLP': False,
                 'BN_SYNC_MLP': False,
                 'DELTA_CLIPS_MAX': inf,
                 'DELTA_CLIPS_MIN': -inf,
                 'DIM': 128,
                 'INTERP_MEMORY': False,
                 'KNN_ON': True,
                 'LENGTH': 5045,
                 'LOCAL_SHUFFLE_BN': True,
                 'MEM_TYPE': '1d',
                 'MLP_DIM': 2048,
                 'MOCO_MULTI_VIEW_QUEUE': True,
                 'MOMENTUM': 0.994,
                 'MOMENTUM_ANNEALING': True,
                 'NUM_CLASSES_DOWNSTREAM': 400,
                 'NUM_MLP_LAYERS': 3,
                 'PREDICTOR_DEPTHS': [],
                 'QUEUE_LEN': 65536,
                 'SEQUENTIAL': True,
                 'SIMCLR_DIST_ON': True,
                 'SWAV_QEUE_LEN': 0,
                 'T': 0.1,
                 'TYPE': 'moco'},
 'DATA': {'COLOR_RND_GRAYSCALE': 0.2,
          'DECODING_BACKEND': 'torchvision',
          'DECODING_SHORT_SIZE': 256,
          'DUMMY_LOAD': False,
          'ENSEMBLE_METHOD': 'sum',
          'IN22K_TRAINVAL': False,
          'IN22k_VAL_IN1K': '',
          'INPUT_CHANNEL_NUM': [3],
          'INV_UNIFORM_SAMPLE': False,
          'IN_VAL_CROP_RATIO': 0.875,
          'LOADER_CHUNK_OVERALL_SIZE': 0,
          'LOADER_CHUNK_SIZE': 0,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 16,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/jmain02/home/J2AD001/wwp02/oxb63-wwp02/data/panaf_5k/annotations/kinetics',
          'PATH_TO_PRELOAD_IMDB': '',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 24,
          'SKIP_ROWS': 0,
          'SSL_BLUR_SIGMA_MAX': [0.0, 2.0],
          'SSL_BLUR_SIGMA_MIN': [0.0, 0.1],
          'SSL_COLOR_BRI_CON_SAT': [0.6, 0.6, 0.6],
          'SSL_COLOR_HUE': 0.15,
          'SSL_COLOR_JITTER': True,
          'SSL_MOCOV2_AUG': True,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 30,
          'TEST_CROP_SIZE': 256,
          'TIME_DIFF_PROB': 0.0,
          'TRAIN_CROP_NUM_SPATIAL': 1,
          'TRAIN_CROP_NUM_TEMPORAL': 4,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333],
          'TRAIN_JITTER_FPS': 0.0,
          'TRAIN_JITTER_MOTION_SHIFT': False,
          'TRAIN_JITTER_SCALES': [256, 320],
          'TRAIN_JITTER_SCALES_RELATIVE': [0.2, 0.766],
          'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
          'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                               [-0.5808, -0.0045, -0.814],
                               [-0.5836, -0.6948, 0.4203]],
          'USE_OFFSET_SAMPLING': False},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 2,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': False,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 10,
 'MASK': {'DECODER_DEPTH': 0,
          'DECODER_EMBED_DIM': 512,
          'DECODER_SEP_POS_EMBED': False,
          'DEC_KV_KERNEL': [],
          'DEC_KV_STRIDE': [],
          'ENABLE': False,
          'HEAD_TYPE': 'separate',
          'MAE_ON': False,
          'MAE_RND_MASK': False,
          'NORM_PRED_PIXEL': True,
          'PER_FRAME_MASKING': False,
          'PRED_HOG': False,
          'PRETRAIN_DEPTH': [15],
          'SCALE_INIT_BY_DEPTH': False,
          'TIME_STRIDE_LOSS': True},
 'MIXUP': {'ALPHA': 0.8,
           'CUTMIX_ALPHA': 1.0,
           'ENABLE': False,
           'LABEL_SMOOTH_VALUE': 0.1,
           'PROB': 1.0,
           'SWITCH_PROB': 0.5},
 'MODEL': {'ACT_CHECKPOINT': False,
           'ARCH': 'slow',
           'DETACH_FINAL_FC': False,
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.0,
           'FC_INIT_STD': 0.01,
           'FP16_ALLREDUCE': False,
           'FROZEN_BN': False,
           'HEAD_ACT': 'none',
           'LOSS_FUNC': 'contrastive_loss',
           'MODEL_NAME': 'ContrastiveModel',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 128,
           'SINGLE_PATHWAY_ARCH': ['2d',
                                   'c2d',
                                   'i3d',
                                   'slow',
                                   'x3d',
                                   'mvit',
                                   'maskmvit']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'MVIT': {'CLS_EMBED_ON': True,
          'DEPTH': 16,
          'DIM_MUL': [],
          'DIM_MUL_IN_ATT': False,
          'DROPOUT_RATE': 0.0,
          'DROPPATH_RATE': 0.1,
          'EMBED_DIM': 96,
          'HEAD_INIT_SCALE': 1.0,
          'HEAD_MUL': [],
          'LAYER_SCALE_INIT_VALUE': 0.0,
          'MLP_RATIO': 4.0,
          'MODE': 'conv',
          'NORM': 'layernorm',
          'NORM_STEM': False,
          'NUM_HEADS': 1,
          'PATCH_2D': False,
          'PATCH_KERNEL': [3, 7, 7],
          'PATCH_PADDING': [2, 4, 4],
          'PATCH_STRIDE': [2, 4, 4],
          'POOL_FIRST': False,
          'POOL_KVQ_KERNEL': None,
          'POOL_KV_STRIDE': [],
          'POOL_KV_STRIDE_ADAPTIVE': None,
          'POOL_Q_STRIDE': [],
          'QKV_BIAS': True,
          'REL_POS_SPATIAL': False,
          'REL_POS_TEMPORAL': False,
          'REL_POS_ZERO_INIT': False,
          'RESIDUAL_POOLING': False,
          'REV': {'BUFFER_LAYERS': [],
                  'ENABLE': False,
                  'PRE_Q_FUSION': 'avg',
                  'RESPATH_FUSE': 'concat',
                  'RES_PATH': 'conv'},
          'SEPARATE_QKV': False,
          'SEP_POS_EMBED': False,
          'USE_ABS_POS': True,
          'USE_FIXED_SINCOS_POS': False,
          'USE_MEAN_POOLING': False,
          'ZERO_DECAY_POS_CLS': True},
 'NONLOCAL': {'GROUP': [[1], [1], [1], [1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[]], [[]], [[]], [[]]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 8,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'checkpoints/ssl/mocov3/scratch',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1], [1], [1], [1]],
            'SPATIAL_STRIDES': [[1], [2], [2], [2]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': False,
            'ZERO_INIT_FINAL_CONV': False},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 8,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 5},
 'SOLVER': {'BASE_LR': 0.1,
            'BASE_LR_SCALE_NUM_SHARDS': True,
            'BETAS': (0.9, 0.999),
            'CLIP_GRAD_L2NORM': None,
            'CLIP_GRAD_VAL': None,
            'COSINE_AFTER_WARMUP': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LARS_ON': False,
            'LAYER_DECAY': 1.0,
            'LRS': [],
            'LR_POLICY': 'cosine',
            'MAX_EPOCH': 600,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'sgd',
            'STEPS': [],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 35.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 0.001,
            'WEIGHT_DECAY': 0.0001,
            'ZERO_WD_1D_PARAM': False},
 'TASK': 'ssl',
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': False,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 256,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'kinetics',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 3,
          'NUM_TEMPORAL_CLIPS': [],
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 256,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_IN_INIT': False,
           'CHECKPOINT_PERIOD': 50,
           'CHECKPOINT_TYPE': 'pytorch',
           'DATASET': 'kinetics',
           'ENABLE': True,
           'EVAL_PERIOD': 600,
           'KILL_LOSS_EXPLOSION_FACTOR': 0.0,
           'MIXED_PRECISION': True},
 'VIS_MASK': CfgNode({'ENABLE': False}),
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[03/30 19:37:06][INFO] misc.py:  185: Model:
DistributedDataParallel(
  (module): ContrastiveModel(
    (backbone): ResNet(
      (s1): VideoModelStem(
        (pathway0_stem): ResNetBasicStem(
          (conv): Conv3d(3, 64, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3), bias=False)
          (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
        )
      )
      (s2): ResStage(
        (pathway0_res0): ResBlock(
          (branch1): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (branch2): BottleneckTransform(
            (a): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
        (pathway0_res1): ResBlock(
          (branch2): BottleneckTransform(
            (a): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
        (pathway0_res2): ResBlock(
          (branch2): BottleneckTransform(
            (a): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
      )
      (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
      (s3): ResStage(
        (pathway0_res0): ResBlock(
          (branch1): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)
          (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (branch2): BottleneckTransform(
            (a): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
        (pathway0_res1): ResBlock(
          (branch2): BottleneckTransform(
            (a): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
        (pathway0_res2): ResBlock(
          (branch2): BottleneckTransform(
            (a): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
        (pathway0_res3): ResBlock(
          (branch2): BottleneckTransform(
            (a): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
      )
      (s4): ResStage(
        (pathway0_res0): ResBlock(
          (branch1): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)
          (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (branch2): BottleneckTransform(
            (a): Conv3d(512, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
            (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
        (pathway0_res1): ResBlock(
          (branch2): BottleneckTransform(
            (a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
            (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
        (pathway0_res2): ResBlock(
          (branch2): BottleneckTransform(
            (a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
            (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
        (pathway0_res3): ResBlock(
          (branch2): BottleneckTransform(
            (a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
            (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
        (pathway0_res4): ResBlock(
          (branch2): BottleneckTransform(
            (a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
            (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
        (pathway0_res5): ResBlock(
          (branch2): BottleneckTransform(
            (a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
            (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
      )
      (s5): ResStage(
        (pathway0_res0): ResBlock(
          (branch1): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)
          (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (branch2): BottleneckTransform(
            (a): Conv3d(1024, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
            (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
        (pathway0_res1): ResBlock(
          (branch2): BottleneckTransform(
            (a): Conv3d(2048, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
            (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
        (pathway0_res2): ResBlock(
          (branch2): BottleneckTransform(
            (a): Conv3d(2048, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
            (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
      )
      (head): ResNetBasicHead(
        (predictors): ModuleList()
        (pathway0_avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))
        (projection): MLPHead(
          (projection): Sequential(
            (0): Linear(in_features=2048, out_features=2048, bias=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=2048, out_features=2048, bias=True)
            (3): ReLU(inplace=True)
            (4): Linear(in_features=2048, out_features=128, bias=True)
          )
        )
      )
    )
    (l2_norm): Normalize()
    (nce_loss_fun): ContrastiveLoss()
    (softmax): Softmax(dim=1)
    (backbone_hist): ResNet(
      (s1): VideoModelStem(
        (pathway0_stem): ResNetBasicStem(
          (conv): Conv3d(3, 64, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3), bias=False)
          (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (pool_layer): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
        )
      )
      (s2): ResStage(
        (pathway0_res0): ResBlock(
          (branch1): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
          (branch1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (branch2): BottleneckTransform(
            (a): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
        (pathway0_res1): ResBlock(
          (branch2): BottleneckTransform(
            (a): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
        (pathway0_res2): ResBlock(
          (branch2): BottleneckTransform(
            (a): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (a_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
      )
      (pathway0_pool): MaxPool3d(kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=1, ceil_mode=False)
      (s3): ResStage(
        (pathway0_res0): ResBlock(
          (branch1): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)
          (branch1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (branch2): BottleneckTransform(
            (a): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
        (pathway0_res1): ResBlock(
          (branch2): BottleneckTransform(
            (a): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
        (pathway0_res2): ResBlock(
          (branch2): BottleneckTransform(
            (a): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
        (pathway0_res3): ResBlock(
          (branch2): BottleneckTransform(
            (a): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
      )
      (s4): ResStage(
        (pathway0_res0): ResBlock(
          (branch1): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)
          (branch1_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (branch2): BottleneckTransform(
            (a): Conv3d(512, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
            (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
        (pathway0_res1): ResBlock(
          (branch2): BottleneckTransform(
            (a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
            (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
        (pathway0_res2): ResBlock(
          (branch2): BottleneckTransform(
            (a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
            (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
        (pathway0_res3): ResBlock(
          (branch2): BottleneckTransform(
            (a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
            (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
        (pathway0_res4): ResBlock(
          (branch2): BottleneckTransform(
            (a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
            (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
        (pathway0_res5): ResBlock(
          (branch2): BottleneckTransform(
            (a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
            (a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
      )
      (s5): ResStage(
        (pathway0_res0): ResBlock(
          (branch1): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)
          (branch1_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (branch2): BottleneckTransform(
            (a): Conv3d(1024, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
            (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
        (pathway0_res1): ResBlock(
          (branch2): BottleneckTransform(
            (a): Conv3d(2048, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
            (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
        (pathway0_res2): ResBlock(
          (branch2): BottleneckTransform(
            (a): Conv3d(2048, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
            (a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (a_relu): ReLU(inplace=True)
            (b): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
            (b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (b_relu): ReLU(inplace=True)
            (c): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
            (c_bn): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (relu): ReLU(inplace=True)
        )
      )
      (head): ResNetBasicHead(
        (predictors): ModuleList()
        (pathway0_avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))
        (projection): MLPHead(
          (projection): Sequential(
            (0): Linear(in_features=2048, out_features=2048, bias=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=2048, out_features=2048, bias=True)
            (3): ReLU(inplace=True)
            (4): Linear(in_features=2048, out_features=128, bias=True)
          )
        )
      )
    )
    (knn_mem): Memory(
      (l2_norm): Normalize()
      (l2_norm2d): Normalize()
    )
  )
)
[03/30 19:37:06][INFO] misc.py:  187: Params: 80,578,944
[03/30 19:37:06][INFO] misc.py:  188: Mem: 0.6714010238647461 MB
[03/30 19:37:40][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 2 time(s)
[03/30 19:37:40][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 16 time(s)
[03/30 19:37:40][WARNING] jit_analysis.py:  499: Unsupported operator aten::adaptive_avg_pool3d encountered 1 time(s)
[03/30 19:37:40][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.backbone_hist, module.backbone_hist.head, module.backbone_hist.head.pathway0_avgpool, module.backbone_hist.head.projection, module.backbone_hist.head.projection.projection, module.backbone_hist.head.projection.projection.0, module.backbone_hist.head.projection.projection.1, module.backbone_hist.head.projection.projection.2, module.backbone_hist.head.projection.projection.3, module.backbone_hist.head.projection.projection.4, module.backbone_hist.pathway0_pool, module.backbone_hist.s1, module.backbone_hist.s1.pathway0_stem, module.backbone_hist.s1.pathway0_stem.bn, module.backbone_hist.s1.pathway0_stem.conv, module.backbone_hist.s1.pathway0_stem.pool_layer, module.backbone_hist.s1.pathway0_stem.relu, module.backbone_hist.s2, module.backbone_hist.s2.pathway0_res0, module.backbone_hist.s2.pathway0_res0.branch1, module.backbone_hist.s2.pathway0_res0.branch1_bn, module.backbone_hist.s2.pathway0_res0.branch2, module.backbone_hist.s2.pathway0_res0.branch2.a, module.backbone_hist.s2.pathway0_res0.branch2.a_bn, module.backbone_hist.s2.pathway0_res0.branch2.a_relu, module.backbone_hist.s2.pathway0_res0.branch2.b, module.backbone_hist.s2.pathway0_res0.branch2.b_bn, module.backbone_hist.s2.pathway0_res0.branch2.b_relu, module.backbone_hist.s2.pathway0_res0.branch2.c, module.backbone_hist.s2.pathway0_res0.branch2.c_bn, module.backbone_hist.s2.pathway0_res0.relu, module.backbone_hist.s2.pathway0_res1, module.backbone_hist.s2.pathway0_res1.branch2, module.backbone_hist.s2.pathway0_res1.branch2.a, module.backbone_hist.s2.pathway0_res1.branch2.a_bn, module.backbone_hist.s2.pathway0_res1.branch2.a_relu, module.backbone_hist.s2.pathway0_res1.branch2.b, module.backbone_hist.s2.pathway0_res1.branch2.b_bn, module.backbone_hist.s2.pathway0_res1.branch2.b_relu, module.backbone_hist.s2.pathway0_res1.branch2.c, module.backbone_hist.s2.pathway0_res1.branch2.c_bn, module.backbone_hist.s2.pathway0_res1.relu, module.backbone_hist.s2.pathway0_res2, module.backbone_hist.s2.pathway0_res2.branch2, module.backbone_hist.s2.pathway0_res2.branch2.a, module.backbone_hist.s2.pathway0_res2.branch2.a_bn, module.backbone_hist.s2.pathway0_res2.branch2.a_relu, module.backbone_hist.s2.pathway0_res2.branch2.b, module.backbone_hist.s2.pathway0_res2.branch2.b_bn, module.backbone_hist.s2.pathway0_res2.branch2.b_relu, module.backbone_hist.s2.pathway0_res2.branch2.c, module.backbone_hist.s2.pathway0_res2.branch2.c_bn, module.backbone_hist.s2.pathway0_res2.relu, module.backbone_hist.s3, module.backbone_hist.s3.pathway0_res0, module.backbone_hist.s3.pathway0_res0.branch1, module.backbone_hist.s3.pathway0_res0.branch1_bn, module.backbone_hist.s3.pathway0_res0.branch2, module.backbone_hist.s3.pathway0_res0.branch2.a, module.backbone_hist.s3.pathway0_res0.branch2.a_bn, module.backbone_hist.s3.pathway0_res0.branch2.a_relu, module.backbone_hist.s3.pathway0_res0.branch2.b, module.backbone_hist.s3.pathway0_res0.branch2.b_bn, module.backbone_hist.s3.pathway0_res0.branch2.b_relu, module.backbone_hist.s3.pathway0_res0.branch2.c, module.backbone_hist.s3.pathway0_res0.branch2.c_bn, module.backbone_hist.s3.pathway0_res0.relu, module.backbone_hist.s3.pathway0_res1, module.backbone_hist.s3.pathway0_res1.branch2, module.backbone_hist.s3.pathway0_res1.branch2.a, module.backbone_hist.s3.pathway0_res1.branch2.a_bn, module.backbone_hist.s3.pathway0_res1.branch2.a_relu, module.backbone_hist.s3.pathway0_res1.branch2.b, module.backbone_hist.s3.pathway0_res1.branch2.b_bn, module.backbone_hist.s3.pathway0_res1.branch2.b_relu, module.backbone_hist.s3.pathway0_res1.branch2.c, module.backbone_hist.s3.pathway0_res1.branch2.c_bn, module.backbone_hist.s3.pathway0_res1.relu, module.backbone_hist.s3.pathway0_res2, module.backbone_hist.s3.pathway0_res2.branch2, module.backbone_hist.s3.pathway0_res2.branch2.a, module.backbone_hist.s3.pathway0_res2.branch2.a_bn, module.backbone_hist.s3.pathway0_res2.branch2.a_relu, module.backbone_hist.s3.pathway0_res2.branch2.b, module.backbone_hist.s3.pathway0_res2.branch2.b_bn, module.backbone_hist.s3.pathway0_res2.branch2.b_relu, module.backbone_hist.s3.pathway0_res2.branch2.c, module.backbone_hist.s3.pathway0_res2.branch2.c_bn, module.backbone_hist.s3.pathway0_res2.relu, module.backbone_hist.s3.pathway0_res3, module.backbone_hist.s3.pathway0_res3.branch2, module.backbone_hist.s3.pathway0_res3.branch2.a, module.backbone_hist.s3.pathway0_res3.branch2.a_bn, module.backbone_hist.s3.pathway0_res3.branch2.a_relu, module.backbone_hist.s3.pathway0_res3.branch2.b, module.backbone_hist.s3.pathway0_res3.branch2.b_bn, module.backbone_hist.s3.pathway0_res3.branch2.b_relu, module.backbone_hist.s3.pathway0_res3.branch2.c, module.backbone_hist.s3.pathway0_res3.branch2.c_bn, module.backbone_hist.s3.pathway0_res3.relu, module.backbone_hist.s4, module.backbone_hist.s4.pathway0_res0, module.backbone_hist.s4.pathway0_res0.branch1, module.backbone_hist.s4.pathway0_res0.branch1_bn, module.backbone_hist.s4.pathway0_res0.branch2, module.backbone_hist.s4.pathway0_res0.branch2.a, module.backbone_hist.s4.pathway0_res0.branch2.a_bn, module.backbone_hist.s4.pathway0_res0.branch2.a_relu, module.backbone_hist.s4.pathway0_res0.branch2.b, module.backbone_hist.s4.pathway0_res0.branch2.b_bn, module.backbone_hist.s4.pathway0_res0.branch2.b_relu, module.backbone_hist.s4.pathway0_res0.branch2.c, module.backbone_hist.s4.pathway0_res0.branch2.c_bn, module.backbone_hist.s4.pathway0_res0.relu, module.backbone_hist.s4.pathway0_res1, module.backbone_hist.s4.pathway0_res1.branch2, module.backbone_hist.s4.pathway0_res1.branch2.a, module.backbone_hist.s4.pathway0_res1.branch2.a_bn, module.backbone_hist.s4.pathway0_res1.branch2.a_relu, module.backbone_hist.s4.pathway0_res1.branch2.b, module.backbone_hist.s4.pathway0_res1.branch2.b_bn, module.backbone_hist.s4.pathway0_res1.branch2.b_relu, module.backbone_hist.s4.pathway0_res1.branch2.c, module.backbone_hist.s4.pathway0_res1.branch2.c_bn, module.backbone_hist.s4.pathway0_res1.relu, module.backbone_hist.s4.pathway0_res2, module.backbone_hist.s4.pathway0_res2.branch2, module.backbone_hist.s4.pathway0_res2.branch2.a, module.backbone_hist.s4.pathway0_res2.branch2.a_bn, module.backbone_hist.s4.pathway0_res2.branch2.a_relu, module.backbone_hist.s4.pathway0_res2.branch2.b, module.backbone_hist.s4.pathway0_res2.branch2.b_bn, module.backbone_hist.s4.pathway0_res2.branch2.b_relu, module.backbone_hist.s4.pathway0_res2.branch2.c, module.backbone_hist.s4.pathway0_res2.branch2.c_bn, module.backbone_hist.s4.pathway0_res2.relu, module.backbone_hist.s4.pathway0_res3, module.backbone_hist.s4.pathway0_res3.branch2, module.backbone_hist.s4.pathway0_res3.branch2.a, module.backbone_hist.s4.pathway0_res3.branch2.a_bn, module.backbone_hist.s4.pathway0_res3.branch2.a_relu, module.backbone_hist.s4.pathway0_res3.branch2.b, module.backbone_hist.s4.pathway0_res3.branch2.b_bn, module.backbone_hist.s4.pathway0_res3.branch2.b_relu, module.backbone_hist.s4.pathway0_res3.branch2.c, module.backbone_hist.s4.pathway0_res3.branch2.c_bn, module.backbone_hist.s4.pathway0_res3.relu, module.backbone_hist.s4.pathway0_res4, module.backbone_hist.s4.pathway0_res4.branch2, module.backbone_hist.s4.pathway0_res4.branch2.a, module.backbone_hist.s4.pathway0_res4.branch2.a_bn, module.backbone_hist.s4.pathway0_res4.branch2.a_relu, module.backbone_hist.s4.pathway0_res4.branch2.b, module.backbone_hist.s4.pathway0_res4.branch2.b_bn, module.backbone_hist.s4.pathway0_res4.branch2.b_relu, module.backbone_hist.s4.pathway0_res4.branch2.c, module.backbone_hist.s4.pathway0_res4.branch2.c_bn, module.backbone_hist.s4.pathway0_res4.relu, module.backbone_hist.s4.pathway0_res5, module.backbone_hist.s4.pathway0_res5.branch2, module.backbone_hist.s4.pathway0_res5.branch2.a, module.backbone_hist.s4.pathway0_res5.branch2.a_bn, module.backbone_hist.s4.pathway0_res5.branch2.a_relu, module.backbone_hist.s4.pathway0_res5.branch2.b, module.backbone_hist.s4.pathway0_res5.branch2.b_bn, module.backbone_hist.s4.pathway0_res5.branch2.b_relu, module.backbone_hist.s4.pathway0_res5.branch2.c, module.backbone_hist.s4.pathway0_res5.branch2.c_bn, module.backbone_hist.s4.pathway0_res5.relu, module.backbone_hist.s5, module.backbone_hist.s5.pathway0_res0, module.backbone_hist.s5.pathway0_res0.branch1, module.backbone_hist.s5.pathway0_res0.branch1_bn, module.backbone_hist.s5.pathway0_res0.branch2, module.backbone_hist.s5.pathway0_res0.branch2.a, module.backbone_hist.s5.pathway0_res0.branch2.a_bn, module.backbone_hist.s5.pathway0_res0.branch2.a_relu, module.backbone_hist.s5.pathway0_res0.branch2.b, module.backbone_hist.s5.pathway0_res0.branch2.b_bn, module.backbone_hist.s5.pathway0_res0.branch2.b_relu, module.backbone_hist.s5.pathway0_res0.branch2.c, module.backbone_hist.s5.pathway0_res0.branch2.c_bn, module.backbone_hist.s5.pathway0_res0.relu, module.backbone_hist.s5.pathway0_res1, module.backbone_hist.s5.pathway0_res1.branch2, module.backbone_hist.s5.pathway0_res1.branch2.a, module.backbone_hist.s5.pathway0_res1.branch2.a_bn, module.backbone_hist.s5.pathway0_res1.branch2.a_relu, module.backbone_hist.s5.pathway0_res1.branch2.b, module.backbone_hist.s5.pathway0_res1.branch2.b_bn, module.backbone_hist.s5.pathway0_res1.branch2.b_relu, module.backbone_hist.s5.pathway0_res1.branch2.c, module.backbone_hist.s5.pathway0_res1.branch2.c_bn, module.backbone_hist.s5.pathway0_res1.relu, module.backbone_hist.s5.pathway0_res2, module.backbone_hist.s5.pathway0_res2.branch2, module.backbone_hist.s5.pathway0_res2.branch2.a, module.backbone_hist.s5.pathway0_res2.branch2.a_bn, module.backbone_hist.s5.pathway0_res2.branch2.a_relu, module.backbone_hist.s5.pathway0_res2.branch2.b, module.backbone_hist.s5.pathway0_res2.branch2.b_bn, module.backbone_hist.s5.pathway0_res2.branch2.b_relu, module.backbone_hist.s5.pathway0_res2.branch2.c, module.backbone_hist.s5.pathway0_res2.branch2.c_bn, module.backbone_hist.s5.pathway0_res2.relu, module.knn_mem, module.knn_mem.l2_norm, module.knn_mem.l2_norm2d, module.l2_norm, module.nce_loss_fun, module.softmax
[03/30 19:37:40][INFO] misc.py:  190: Flops: 83.84431718399999 G
[03/30 19:37:40][WARNING] jit_analysis.py:  499: Unsupported operator aten::batch_norm encountered 53 time(s)
[03/30 19:37:40][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 2 time(s)
[03/30 19:37:40][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 16 time(s)
[03/30 19:37:40][WARNING] jit_analysis.py:  499: Unsupported operator aten::adaptive_avg_pool3d encountered 1 time(s)
[03/30 19:37:40][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.backbone_hist, module.backbone_hist.head, module.backbone_hist.head.pathway0_avgpool, module.backbone_hist.head.projection, module.backbone_hist.head.projection.projection, module.backbone_hist.head.projection.projection.0, module.backbone_hist.head.projection.projection.1, module.backbone_hist.head.projection.projection.2, module.backbone_hist.head.projection.projection.3, module.backbone_hist.head.projection.projection.4, module.backbone_hist.pathway0_pool, module.backbone_hist.s1, module.backbone_hist.s1.pathway0_stem, module.backbone_hist.s1.pathway0_stem.bn, module.backbone_hist.s1.pathway0_stem.conv, module.backbone_hist.s1.pathway0_stem.pool_layer, module.backbone_hist.s1.pathway0_stem.relu, module.backbone_hist.s2, module.backbone_hist.s2.pathway0_res0, module.backbone_hist.s2.pathway0_res0.branch1, module.backbone_hist.s2.pathway0_res0.branch1_bn, module.backbone_hist.s2.pathway0_res0.branch2, module.backbone_hist.s2.pathway0_res0.branch2.a, module.backbone_hist.s2.pathway0_res0.branch2.a_bn, module.backbone_hist.s2.pathway0_res0.branch2.a_relu, module.backbone_hist.s2.pathway0_res0.branch2.b, module.backbone_hist.s2.pathway0_res0.branch2.b_bn, module.backbone_hist.s2.pathway0_res0.branch2.b_relu, module.backbone_hist.s2.pathway0_res0.branch2.c, module.backbone_hist.s2.pathway0_res0.branch2.c_bn, module.backbone_hist.s2.pathway0_res0.relu, module.backbone_hist.s2.pathway0_res1, module.backbone_hist.s2.pathway0_res1.branch2, module.backbone_hist.s2.pathway0_res1.branch2.a, module.backbone_hist.s2.pathway0_res1.branch2.a_bn, module.backbone_hist.s2.pathway0_res1.branch2.a_relu, module.backbone_hist.s2.pathway0_res1.branch2.b, module.backbone_hist.s2.pathway0_res1.branch2.b_bn, module.backbone_hist.s2.pathway0_res1.branch2.b_relu, module.backbone_hist.s2.pathway0_res1.branch2.c, module.backbone_hist.s2.pathway0_res1.branch2.c_bn, module.backbone_hist.s2.pathway0_res1.relu, module.backbone_hist.s2.pathway0_res2, module.backbone_hist.s2.pathway0_res2.branch2, module.backbone_hist.s2.pathway0_res2.branch2.a, module.backbone_hist.s2.pathway0_res2.branch2.a_bn, module.backbone_hist.s2.pathway0_res2.branch2.a_relu, module.backbone_hist.s2.pathway0_res2.branch2.b, module.backbone_hist.s2.pathway0_res2.branch2.b_bn, module.backbone_hist.s2.pathway0_res2.branch2.b_relu, module.backbone_hist.s2.pathway0_res2.branch2.c, module.backbone_hist.s2.pathway0_res2.branch2.c_bn, module.backbone_hist.s2.pathway0_res2.relu, module.backbone_hist.s3, module.backbone_hist.s3.pathway0_res0, module.backbone_hist.s3.pathway0_res0.branch1, module.backbone_hist.s3.pathway0_res0.branch1_bn, module.backbone_hist.s3.pathway0_res0.branch2, module.backbone_hist.s3.pathway0_res0.branch2.a, module.backbone_hist.s3.pathway0_res0.branch2.a_bn, module.backbone_hist.s3.pathway0_res0.branch2.a_relu, module.backbone_hist.s3.pathway0_res0.branch2.b, module.backbone_hist.s3.pathway0_res0.branch2.b_bn, module.backbone_hist.s3.pathway0_res0.branch2.b_relu, module.backbone_hist.s3.pathway0_res0.branch2.c, module.backbone_hist.s3.pathway0_res0.branch2.c_bn, module.backbone_hist.s3.pathway0_res0.relu, module.backbone_hist.s3.pathway0_res1, module.backbone_hist.s3.pathway0_res1.branch2, module.backbone_hist.s3.pathway0_res1.branch2.a, module.backbone_hist.s3.pathway0_res1.branch2.a_bn, module.backbone_hist.s3.pathway0_res1.branch2.a_relu, module.backbone_hist.s3.pathway0_res1.branch2.b, module.backbone_hist.s3.pathway0_res1.branch2.b_bn, module.backbone_hist.s3.pathway0_res1.branch2.b_relu, module.backbone_hist.s3.pathway0_res1.branch2.c, module.backbone_hist.s3.pathway0_res1.branch2.c_bn, module.backbone_hist.s3.pathway0_res1.relu, module.backbone_hist.s3.pathway0_res2, module.backbone_hist.s3.pathway0_res2.branch2, module.backbone_hist.s3.pathway0_res2.branch2.a, module.backbone_hist.s3.pathway0_res2.branch2.a_bn, module.backbone_hist.s3.pathway0_res2.branch2.a_relu, module.backbone_hist.s3.pathway0_res2.branch2.b, module.backbone_hist.s3.pathway0_res2.branch2.b_bn, module.backbone_hist.s3.pathway0_res2.branch2.b_relu, module.backbone_hist.s3.pathway0_res2.branch2.c, module.backbone_hist.s3.pathway0_res2.branch2.c_bn, module.backbone_hist.s3.pathway0_res2.relu, module.backbone_hist.s3.pathway0_res3, module.backbone_hist.s3.pathway0_res3.branch2, module.backbone_hist.s3.pathway0_res3.branch2.a, module.backbone_hist.s3.pathway0_res3.branch2.a_bn, module.backbone_hist.s3.pathway0_res3.branch2.a_relu, module.backbone_hist.s3.pathway0_res3.branch2.b, module.backbone_hist.s3.pathway0_res3.branch2.b_bn, module.backbone_hist.s3.pathway0_res3.branch2.b_relu, module.backbone_hist.s3.pathway0_res3.branch2.c, module.backbone_hist.s3.pathway0_res3.branch2.c_bn, module.backbone_hist.s3.pathway0_res3.relu, module.backbone_hist.s4, module.backbone_hist.s4.pathway0_res0, module.backbone_hist.s4.pathway0_res0.branch1, module.backbone_hist.s4.pathway0_res0.branch1_bn, module.backbone_hist.s4.pathway0_res0.branch2, module.backbone_hist.s4.pathway0_res0.branch2.a, module.backbone_hist.s4.pathway0_res0.branch2.a_bn, module.backbone_hist.s4.pathway0_res0.branch2.a_relu, module.backbone_hist.s4.pathway0_res0.branch2.b, module.backbone_hist.s4.pathway0_res0.branch2.b_bn, module.backbone_hist.s4.pathway0_res0.branch2.b_relu, module.backbone_hist.s4.pathway0_res0.branch2.c, module.backbone_hist.s4.pathway0_res0.branch2.c_bn, module.backbone_hist.s4.pathway0_res0.relu, module.backbone_hist.s4.pathway0_res1, module.backbone_hist.s4.pathway0_res1.branch2, module.backbone_hist.s4.pathway0_res1.branch2.a, module.backbone_hist.s4.pathway0_res1.branch2.a_bn, module.backbone_hist.s4.pathway0_res1.branch2.a_relu, module.backbone_hist.s4.pathway0_res1.branch2.b, module.backbone_hist.s4.pathway0_res1.branch2.b_bn, module.backbone_hist.s4.pathway0_res1.branch2.b_relu, module.backbone_hist.s4.pathway0_res1.branch2.c, module.backbone_hist.s4.pathway0_res1.branch2.c_bn, module.backbone_hist.s4.pathway0_res1.relu, module.backbone_hist.s4.pathway0_res2, module.backbone_hist.s4.pathway0_res2.branch2, module.backbone_hist.s4.pathway0_res2.branch2.a, module.backbone_hist.s4.pathway0_res2.branch2.a_bn, module.backbone_hist.s4.pathway0_res2.branch2.a_relu, module.backbone_hist.s4.pathway0_res2.branch2.b, module.backbone_hist.s4.pathway0_res2.branch2.b_bn, module.backbone_hist.s4.pathway0_res2.branch2.b_relu, module.backbone_hist.s4.pathway0_res2.branch2.c, module.backbone_hist.s4.pathway0_res2.branch2.c_bn, module.backbone_hist.s4.pathway0_res2.relu, module.backbone_hist.s4.pathway0_res3, module.backbone_hist.s4.pathway0_res3.branch2, module.backbone_hist.s4.pathway0_res3.branch2.a, module.backbone_hist.s4.pathway0_res3.branch2.a_bn, module.backbone_hist.s4.pathway0_res3.branch2.a_relu, module.backbone_hist.s4.pathway0_res3.branch2.b, module.backbone_hist.s4.pathway0_res3.branch2.b_bn, module.backbone_hist.s4.pathway0_res3.branch2.b_relu, module.backbone_hist.s4.pathway0_res3.branch2.c, module.backbone_hist.s4.pathway0_res3.branch2.c_bn, module.backbone_hist.s4.pathway0_res3.relu, module.backbone_hist.s4.pathway0_res4, module.backbone_hist.s4.pathway0_res4.branch2, module.backbone_hist.s4.pathway0_res4.branch2.a, module.backbone_hist.s4.pathway0_res4.branch2.a_bn, module.backbone_hist.s4.pathway0_res4.branch2.a_relu, module.backbone_hist.s4.pathway0_res4.branch2.b, module.backbone_hist.s4.pathway0_res4.branch2.b_bn, module.backbone_hist.s4.pathway0_res4.branch2.b_relu, module.backbone_hist.s4.pathway0_res4.branch2.c, module.backbone_hist.s4.pathway0_res4.branch2.c_bn, module.backbone_hist.s4.pathway0_res4.relu, module.backbone_hist.s4.pathway0_res5, module.backbone_hist.s4.pathway0_res5.branch2, module.backbone_hist.s4.pathway0_res5.branch2.a, module.backbone_hist.s4.pathway0_res5.branch2.a_bn, module.backbone_hist.s4.pathway0_res5.branch2.a_relu, module.backbone_hist.s4.pathway0_res5.branch2.b, module.backbone_hist.s4.pathway0_res5.branch2.b_bn, module.backbone_hist.s4.pathway0_res5.branch2.b_relu, module.backbone_hist.s4.pathway0_res5.branch2.c, module.backbone_hist.s4.pathway0_res5.branch2.c_bn, module.backbone_hist.s4.pathway0_res5.relu, module.backbone_hist.s5, module.backbone_hist.s5.pathway0_res0, module.backbone_hist.s5.pathway0_res0.branch1, module.backbone_hist.s5.pathway0_res0.branch1_bn, module.backbone_hist.s5.pathway0_res0.branch2, module.backbone_hist.s5.pathway0_res0.branch2.a, module.backbone_hist.s5.pathway0_res0.branch2.a_bn, module.backbone_hist.s5.pathway0_res0.branch2.a_relu, module.backbone_hist.s5.pathway0_res0.branch2.b, module.backbone_hist.s5.pathway0_res0.branch2.b_bn, module.backbone_hist.s5.pathway0_res0.branch2.b_relu, module.backbone_hist.s5.pathway0_res0.branch2.c, module.backbone_hist.s5.pathway0_res0.branch2.c_bn, module.backbone_hist.s5.pathway0_res0.relu, module.backbone_hist.s5.pathway0_res1, module.backbone_hist.s5.pathway0_res1.branch2, module.backbone_hist.s5.pathway0_res1.branch2.a, module.backbone_hist.s5.pathway0_res1.branch2.a_bn, module.backbone_hist.s5.pathway0_res1.branch2.a_relu, module.backbone_hist.s5.pathway0_res1.branch2.b, module.backbone_hist.s5.pathway0_res1.branch2.b_bn, module.backbone_hist.s5.pathway0_res1.branch2.b_relu, module.backbone_hist.s5.pathway0_res1.branch2.c, module.backbone_hist.s5.pathway0_res1.branch2.c_bn, module.backbone_hist.s5.pathway0_res1.relu, module.backbone_hist.s5.pathway0_res2, module.backbone_hist.s5.pathway0_res2.branch2, module.backbone_hist.s5.pathway0_res2.branch2.a, module.backbone_hist.s5.pathway0_res2.branch2.a_bn, module.backbone_hist.s5.pathway0_res2.branch2.a_relu, module.backbone_hist.s5.pathway0_res2.branch2.b, module.backbone_hist.s5.pathway0_res2.branch2.b_bn, module.backbone_hist.s5.pathway0_res2.branch2.b_relu, module.backbone_hist.s5.pathway0_res2.branch2.c, module.backbone_hist.s5.pathway0_res2.branch2.c_bn, module.backbone_hist.s5.pathway0_res2.relu, module.knn_mem, module.knn_mem.l2_norm, module.knn_mem.l2_norm2d, module.l2_norm, module.nce_loss_fun, module.softmax
[03/30 19:37:40][INFO] misc.py:  191: Activations: 177.827968 M
[03/30 19:37:40][INFO] misc.py:  196: nvidia-smi
Thu Mar 30 19:37:40 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 450.142.00   Driver Version: 450.142.00   CUDA Version: 11.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |
| N/A   35C    P0    47W / 163W |   3990MiB / 32510MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  Tesla V100-SXM2...  On   | 00000000:07:00.0 Off |                    0 |
| N/A   38C    P0    48W / 163W |   1896MiB / 32510MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  Tesla V100-SXM2...  On   | 00000000:0A:00.0 Off |                    0 |
| N/A   37C    P0    48W / 163W |   1800MiB / 32510MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  Tesla V100-SXM2...  On   | 00000000:0B:00.0 Off |                    0 |
| N/A   35C    P0    48W / 163W |   1804MiB / 32510MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   4  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |
| N/A   38C    P0    47W / 163W |   1876MiB / 32510MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   5  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |
| N/A   37C    P0    47W / 163W |   1892MiB / 32510MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   6  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |
| N/A   37C    P0    47W / 163W |   1844MiB / 32510MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   7  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |
| N/A   37C    P0    47W / 163W |   1820MiB / 32510MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A     39520      C   ...torch113_cu116/bin/python     3987MiB |
|    1   N/A  N/A     39521      C   ...torch113_cu116/bin/python     1893MiB |
|    2   N/A  N/A     39522      C   ...torch113_cu116/bin/python     1797MiB |
|    3   N/A  N/A     39523      C   ...torch113_cu116/bin/python     1801MiB |
|    4   N/A  N/A     39524      C   ...torch113_cu116/bin/python     1873MiB |
|    5   N/A  N/A     39525      C   ...torch113_cu116/bin/python     1889MiB |
|    6   N/A  N/A     39526      C   ...torch113_cu116/bin/python     1841MiB |
|    7   N/A  N/A     39527      C   ...torch113_cu116/bin/python     1817MiB |
+-----------------------------------------------------------------------------+
bn 106, non bn 59, zero 0, no grad 165
[03/30 19:37:41][INFO] kinetics.py:   93: Constructing Kinetics train...
[03/30 19:37:41][INFO] kinetics.py:  158: Constructing kinetics dataloader (size: 5045 skip_rows 0) from /jmain02/home/J2AD001/wwp02/oxb63-wwp02/data/panaf_5k/annotations/kinetics/train.csv 
[03/30 19:37:41][INFO] kinetics.py:   93: Constructing Kinetics val...
[03/30 19:37:41][INFO] kinetics.py:  158: Constructing kinetics dataloader (size: 304 skip_rows 0) from /jmain02/home/J2AD001/wwp02/oxb63-wwp02/data/panaf_5k/annotations/kinetics/val.csv 
[03/30 19:37:41][INFO] contrastive.py:  144: initializing knn labels
[03/30 19:37:41][INFO] train_net.py:  631: Start epoch: 1
[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[03/30 19:39:03][INFO] contrastive.py: 1109: Not updating parameters 0/256
[03/30 19:39:09][INFO] contrastive.py: 1109: Not updating parameters 1/256
[03/30 19:39:36][INFO] contrastive.py: 1109: Not updating parameters 2/256
[03/30 19:39:42][INFO] contrastive.py: 1109: Not updating parameters 3/256
[03/30 19:40:23][INFO] contrastive.py: 1109: Not updating parameters 4/256
[03/30 19:40:29][INFO] contrastive.py: 1109: Not updating parameters 5/256
[03/30 19:41:10][INFO] contrastive.py: 1109: Not updating parameters 6/256
[03/30 19:41:19][INFO] contrastive.py: 1109: Not updating parameters 7/256
[03/30 19:42:00][INFO] contrastive.py: 1109: Not updating parameters 8/256
[03/30 19:42:08][INFO] contrastive.py: 1109: Not updating parameters 9/256
[03/30 19:42:08][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 7.84360, "dt_data": 1.97887, "dt_net": 5.86474, "epoch": "1/600", "eta": "1 day, 0:48:58", "gpu_mem": "26.94G", "grad_norm": 7.25676, "iter": "10/19", "loss": 3.16373, "lr": 0.00233, "top1_err": 99.36523, "top5_err": 93.88021}
[03/30 19:42:47][INFO] contrastive.py: 1109: Not updating parameters 10/256
[03/30 19:42:54][INFO] contrastive.py: 1109: Not updating parameters 11/256
[03/30 19:43:36][INFO] contrastive.py: 1109: Not updating parameters 12/256
[03/30 19:43:44][INFO] contrastive.py: 1109: Not updating parameters 13/256
[03/30 19:44:22][INFO] contrastive.py: 1109: Not updating parameters 14/256
[03/30 19:44:32][INFO] contrastive.py: 1109: Not updating parameters 15/256
[03/30 19:45:07][INFO] contrastive.py: 1109: Not updating parameters 16/256
[03/30 19:45:18][INFO] contrastive.py: 1109: Not updating parameters 17/256
[03/30 19:45:49][INFO] contrastive.py: 1109: Not updating parameters 18/256
[03/30 19:45:55][INFO] logging.py:   99: json_stats: {"RAM": "77.43/503.30G", "_type": "train_epoch_ssl", "dt": 6.18849, "dt_data": 6.18849, "dt_net": 5.88157, "epoch": "1/600", "eta": "19:33:50", "gpu_mem": "26.94G", "grad_norm": 9.95061, "loss": 3.30687, "lr": 0.00366, "top1_err": 94.29653, "top5_err": 90.21724}
[03/30 19:45:55][INFO] train_net.py:  692: Epoch 0 takes 494.52s. Epochs from 0 to 0 take 494.52s in average and 494.52s in median.
[03/30 19:45:55][INFO] train_net.py:  698: For epoch 0, each iteraction takes 26.03s in average. From epoch 0 to 0, each iteraction takes 26.03s in average.
[03/30 19:50:12][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.03081, "dt_data": 0.00071, "dt_net": 6.03010, "epoch": "2/600", "eta": "19:02:56", "gpu_mem": "27.09G", "grad_norm": 3.42614, "iter": "10/19", "loss": 3.97640, "lr": 0.00513, "top1_err": 99.88606, "top5_err": 97.94922}
[03/30 19:53:56][INFO] logging.py:   99: json_stats: {"RAM": "82.23/503.30G", "_type": "train_epoch_ssl", "dt": 0.84223, "dt_data": 0.84223, "dt_net": 17.18404, "epoch": "2/600", "eta": "2:39:28", "gpu_mem": "27.09G", "grad_norm": 2.38361, "loss": 3.94849, "lr": 0.00646, "top1_err": 98.49404, "top5_err": 95.22512}
[03/30 19:53:56][INFO] train_net.py:  692: Epoch 1 takes 480.27s. Epochs from 0 to 1 take 487.40s in average and 487.40s in median.
[03/30 19:53:56][INFO] train_net.py:  698: For epoch 1, each iteraction takes 25.28s in average. From epoch 0 to 1, each iteraction takes 25.65s in average.
[03/30 19:58:15][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.04333, "dt_data": 0.00073, "dt_net": 6.04260, "epoch": "3/600", "eta": "19:03:23", "gpu_mem": "27.10G", "grad_norm": 1.79888, "iter": "10/19", "loss": 3.77059, "lr": 0.00794, "top1_err": 94.05925, "top5_err": 80.59895}
[03/30 20:02:05][INFO] logging.py:   99: json_stats: {"RAM": "79.02/503.30G", "_type": "train_epoch_ssl", "dt": 0.98398, "dt_data": 0.98398, "dt_net": 38.19005, "epoch": "3/600", "eta": "3:06:00", "gpu_mem": "27.10G", "grad_norm": 1.61797, "loss": 3.71811, "lr": 0.00927, "top1_err": 92.19607, "top5_err": 79.84512}
[03/30 20:02:05][INFO] train_net.py:  692: Epoch 2 takes 489.67s. Epochs from 0 to 2 take 488.15s in average and 489.67s in median.
[03/30 20:02:05][INFO] train_net.py:  698: For epoch 2, each iteraction takes 25.77s in average. From epoch 0 to 2, each iteraction takes 25.69s in average.
[03/30 20:06:28][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.02385, "dt_data": 0.00073, "dt_net": 6.02312, "epoch": "4/600", "eta": "18:57:48", "gpu_mem": "27.10G", "grad_norm": 2.81641, "iter": "10/19", "loss": 3.59644, "lr": 0.01074, "top1_err": 90.33203, "top5_err": 77.27864}
[03/30 20:10:14][INFO] logging.py:   99: json_stats: {"RAM": "80.61/503.30G", "_type": "train_epoch_ssl", "dt": 0.94189, "dt_data": 0.94189, "dt_net": 25.27458, "epoch": "4/600", "eta": "2:57:45", "gpu_mem": "27.10G", "grad_norm": 1.81958, "loss": 3.57104, "lr": 0.01207, "top1_err": 87.96258, "top5_err": 75.61677}
[03/30 20:10:14][INFO] train_net.py:  692: Epoch 3 takes 488.25s. Epochs from 0 to 3 take 488.18s in average and 488.96s in median.
[03/30 20:10:14][INFO] train_net.py:  698: For epoch 3, each iteraction takes 25.70s in average. From epoch 0 to 3, each iteraction takes 25.69s in average.
[03/30 20:14:40][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.10413, "dt_data": 0.00095, "dt_net": 6.10318, "epoch": "5/600", "eta": "19:11:02", "gpu_mem": "27.10G", "grad_norm": 1.50228, "iter": "10/19", "loss": 3.52393, "lr": 0.01355, "top1_err": 85.70963, "top5_err": 73.27474}
[03/30 20:18:34][INFO] logging.py:   99: json_stats: {"RAM": "78.38/503.30G", "_type": "train_epoch_ssl", "dt": 1.27292, "dt_data": 1.27292, "dt_net": 38.33140, "epoch": "5/600", "eta": "3:59:49", "gpu_mem": "27.10G", "grad_norm": 1.85440, "loss": 3.52408, "lr": 0.01488, "top1_err": 84.53604, "top5_err": 72.20052}
[03/30 20:18:34][INFO] train_net.py:  692: Epoch 4 takes 500.72s. Epochs from 0 to 4 take 490.69s in average and 489.67s in median.
[03/30 20:18:34][INFO] train_net.py:  698: For epoch 4, each iteraction takes 26.35s in average. From epoch 0 to 4, each iteraction takes 25.83s in average.
[03/30 20:22:54][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.05659, "dt_data": 0.00070, "dt_net": 6.05589, "epoch": "6/600", "eta": "19:00:09", "gpu_mem": "27.10G", "grad_norm": 3.90683, "iter": "10/19", "loss": 3.51511, "lr": 0.01635, "top1_err": 84.42382, "top5_err": 69.62891}
[03/30 20:26:47][INFO] logging.py:   99: json_stats: {"RAM": "78.43/503.30G", "_type": "train_epoch_ssl", "dt": 1.44426, "dt_data": 1.44426, "dt_net": 16.62973, "epoch": "6/600", "eta": "4:31:39", "gpu_mem": "27.10G", "grad_norm": 1.67314, "loss": 3.51542, "lr": 0.01768, "top1_err": 81.62349, "top5_err": 68.92646}
[03/30 20:26:47][INFO] train_net.py:  692: Epoch 5 takes 492.56s. Epochs from 0 to 5 take 491.00s in average and 491.11s in median.
[03/30 20:26:47][INFO] train_net.py:  698: For epoch 5, each iteraction takes 25.92s in average. From epoch 0 to 5, each iteraction takes 25.84s in average.
[03/30 20:31:17][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.11309, "dt_data": 0.00099, "dt_net": 6.11210, "epoch": "7/600", "eta": "19:08:51", "gpu_mem": "27.10G", "grad_norm": 2.76912, "iter": "10/19", "loss": 3.49303, "lr": 0.01916, "top1_err": 79.11783, "top5_err": 67.75716}
[03/30 20:35:12][INFO] logging.py:   99: json_stats: {"RAM": "82.49/503.30G", "_type": "train_epoch_ssl", "dt": 0.91266, "dt_data": 0.91266, "dt_net": 5.90768, "epoch": "7/600", "eta": "2:51:22", "gpu_mem": "27.10G", "grad_norm": 2.79938, "loss": 3.49065, "lr": 0.02048, "top1_err": 78.87541, "top5_err": 68.05270}
[03/30 20:35:12][INFO] train_net.py:  692: Epoch 6 takes 504.75s. Epochs from 0 to 6 take 492.96s in average and 492.56s in median.
[03/30 20:35:12][INFO] train_net.py:  698: For epoch 6, each iteraction takes 26.57s in average. From epoch 0 to 6, each iteraction takes 25.95s in average.
[03/30 20:39:37][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.09703, "dt_data": 0.00088, "dt_net": 6.09615, "epoch": "8/600", "eta": "19:03:54", "gpu_mem": "27.10G", "grad_norm": 1.22055, "iter": "10/19", "loss": 3.47722, "lr": 0.02196, "top1_err": 73.68164, "top5_err": 63.23242}
[03/30 20:43:30][INFO] logging.py:   99: json_stats: {"RAM": "78.42/503.30G", "_type": "train_epoch_ssl", "dt": 1.29810, "dt_data": 1.29810, "dt_net": 5.93258, "epoch": "8/600", "eta": "4:03:20", "gpu_mem": "27.10G", "grad_norm": 1.52862, "loss": 3.47330, "lr": 0.02329, "top1_err": 74.50829, "top5_err": 63.47656}
[03/30 20:43:30][INFO] train_net.py:  692: Epoch 7 takes 498.13s. Epochs from 0 to 7 take 493.61s in average and 493.54s in median.
[03/30 20:43:30][INFO] train_net.py:  698: For epoch 7, each iteraction takes 26.22s in average. From epoch 0 to 7, each iteraction takes 25.98s in average.
[03/30 20:48:02][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.48196, "dt_data": 0.60655, "dt_net": 5.87540, "epoch": "9/600", "eta": "20:14:04", "gpu_mem": "27.10G", "grad_norm": 1.48095, "iter": "10/19", "loss": 3.48675, "lr": 0.02477, "top1_err": 71.28906, "top5_err": 60.41666}
[03/30 20:51:54][INFO] logging.py:   99: json_stats: {"RAM": "78.48/503.30G", "_type": "train_epoch_ssl", "dt": 1.50458, "dt_data": 1.50458, "dt_net": 33.50138, "epoch": "9/600", "eta": "4:41:34", "gpu_mem": "27.10G", "grad_norm": 4.14733, "loss": 3.48711, "lr": 0.02609, "top1_err": 72.91495, "top5_err": 61.78214}
[03/30 20:51:54][INFO] train_net.py:  692: Epoch 8 takes 504.46s. Epochs from 0 to 8 take 494.81s in average and 494.52s in median.
[03/30 20:51:54][INFO] train_net.py:  698: For epoch 8, each iteraction takes 26.55s in average. From epoch 0 to 8, each iteraction takes 26.04s in average.
[03/30 20:56:24][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.06786, "dt_data": 0.00070, "dt_net": 6.06716, "epoch": "10/600", "eta": "18:54:35", "gpu_mem": "27.10G", "grad_norm": 1.77967, "iter": "10/19", "loss": 3.47751, "lr": 0.02757, "top1_err": 70.80078, "top5_err": 61.37695}
[03/30 21:00:16][INFO] logging.py:   99: json_stats: {"RAM": "78.44/503.30G", "_type": "train_epoch_ssl", "dt": 1.41468, "dt_data": 1.41468, "dt_net": 38.94277, "epoch": "10/600", "eta": "4:24:17", "gpu_mem": "27.10G", "grad_norm": 3.07113, "loss": 3.47461, "lr": 0.02890, "top1_err": 71.30105, "top5_err": 60.70792}
[03/30 21:00:16][INFO] train_net.py:  692: Epoch 9 takes 502.00s. Epochs from 0 to 9 take 495.53s in average and 496.33s in median.
[03/30 21:00:16][INFO] train_net.py:  698: For epoch 9, each iteraction takes 26.42s in average. From epoch 0 to 9, each iteraction takes 26.08s in average.
[03/30 21:04:51][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.07240, "dt_data": 0.00080, "dt_net": 6.07160, "epoch": "11/600", "eta": "18:53:30", "gpu_mem": "27.10G", "grad_norm": 1.70783, "iter": "10/19", "loss": 3.46762, "lr": 0.03038, "top1_err": 71.58203, "top5_err": 60.02604}
[03/30 21:08:47][INFO] logging.py:   99: json_stats: {"RAM": "79.97/503.30G", "_type": "train_epoch_ssl", "dt": 1.14000, "dt_data": 1.14000, "dt_net": 18.92699, "epoch": "11/600", "eta": "3:32:37", "gpu_mem": "27.10G", "grad_norm": 1.46030, "loss": 3.45889, "lr": 0.03170, "top1_err": 71.17941, "top5_err": 59.48807}
[03/30 21:08:47][INFO] train_net.py:  692: Epoch 10 takes 510.46s. Epochs from 0 to 10 take 496.89s in average and 498.13s in median.
[03/30 21:08:47][INFO] train_net.py:  698: For epoch 10, each iteraction takes 26.87s in average. From epoch 0 to 10, each iteraction takes 26.15s in average.
[03/30 21:13:11][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.06904, "dt_data": 0.00076, "dt_net": 6.06828, "epoch": "12/600", "eta": "18:50:57", "gpu_mem": "27.10G", "grad_norm": 1.66354, "iter": "10/19", "loss": 3.43386, "lr": 0.03318, "top1_err": 71.37044, "top5_err": 59.03320}
[03/30 21:16:57][INFO] logging.py:   99: json_stats: {"RAM": "79.96/503.30G", "_type": "train_epoch_ssl", "dt": 1.38909, "dt_data": 1.38909, "dt_net": 15.58086, "epoch": "12/600", "eta": "4:18:38", "gpu_mem": "27.10G", "grad_norm": 1.21212, "loss": 3.43599, "lr": 0.03451, "top1_err": 73.66365, "top5_err": 60.97862}
[03/30 21:16:57][INFO] train_net.py:  692: Epoch 11 takes 489.86s. Epochs from 0 to 11 take 496.30s in average and 496.33s in median.
[03/30 21:16:57][INFO] train_net.py:  698: For epoch 11, each iteraction takes 25.78s in average. From epoch 0 to 11, each iteraction takes 26.12s in average.
[03/30 21:21:29][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.13124, "dt_data": 0.00085, "dt_net": 6.13038, "epoch": "13/600", "eta": "19:00:36", "gpu_mem": "27.10G", "grad_norm": 1.49126, "iter": "10/19", "loss": 3.44669, "lr": 0.03598, "top1_err": 71.17513, "top5_err": 59.35872}
[03/30 21:25:23][INFO] logging.py:   99: json_stats: {"RAM": "80.09/503.30G", "_type": "train_epoch_ssl", "dt": 1.51457, "dt_data": 1.51457, "dt_net": 28.39080, "epoch": "13/600", "eta": "4:41:31", "gpu_mem": "27.10G", "grad_norm": 1.55262, "loss": 3.44362, "lr": 0.03731, "top1_err": 71.88699, "top5_err": 60.67194}
[03/30 21:25:23][INFO] train_net.py:  692: Epoch 12 takes 506.10s. Epochs from 0 to 12 take 497.06s in average and 498.13s in median.
[03/30 21:25:23][INFO] train_net.py:  698: For epoch 12, each iteraction takes 26.64s in average. From epoch 0 to 12, each iteraction takes 26.16s in average.
[03/30 21:29:47][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.07731, "dt_data": 0.00086, "dt_net": 6.07645, "epoch": "14/600", "eta": "18:48:39", "gpu_mem": "27.10G", "grad_norm": 1.60364, "iter": "10/19", "loss": 3.45167, "lr": 0.03879, "top1_err": 77.88086, "top5_err": 65.41341}
[03/30 21:33:33][INFO] logging.py:   99: json_stats: {"RAM": "80.62/503.30G", "_type": "train_epoch_ssl", "dt": 1.08324, "dt_data": 1.08324, "dt_net": 13.22676, "epoch": "14/600", "eta": "3:21:00", "gpu_mem": "27.10G", "grad_norm": 1.07412, "loss": 3.45455, "lr": 0.04012, "top1_err": 77.92968, "top5_err": 65.62500}
[03/30 21:33:33][INFO] train_net.py:  692: Epoch 13 takes 490.79s. Epochs from 0 to 13 take 496.61s in average and 496.33s in median.
[03/30 21:33:33][INFO] train_net.py:  698: For epoch 13, each iteraction takes 25.83s in average. From epoch 0 to 13, each iteraction takes 26.14s in average.
[03/30 21:38:01][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.17166, "dt_data": 0.00085, "dt_net": 6.17080, "epoch": "15/600", "eta": "19:04:13", "gpu_mem": "27.10G", "grad_norm": 2.66143, "iter": "10/19", "loss": 3.46621, "lr": 0.04159, "top1_err": 80.92448, "top5_err": 69.53125}
[03/30 21:41:58][INFO] logging.py:   99: json_stats: {"RAM": "80.03/503.30G", "_type": "train_epoch_ssl", "dt": 1.46877, "dt_data": 1.46877, "dt_net": 28.88923, "epoch": "15/600", "eta": "4:32:04", "gpu_mem": "27.10G", "grad_norm": 1.01660, "loss": 3.47121, "lr": 0.04292, "top1_err": 80.59724, "top5_err": 68.86992}
[03/30 21:41:58][INFO] train_net.py:  692: Epoch 14 takes 504.36s. Epochs from 0 to 14 take 497.13s in average and 498.13s in median.
[03/30 21:41:58][INFO] train_net.py:  698: For epoch 14, each iteraction takes 26.55s in average. From epoch 0 to 14, each iteraction takes 26.16s in average.
[03/30 21:46:24][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.05837, "dt_data": 0.00101, "dt_net": 6.05735, "epoch": "16/600", "eta": "18:41:18", "gpu_mem": "27.10G", "grad_norm": 1.05099, "iter": "10/19", "loss": 3.48128, "lr": 0.04440, "top1_err": 81.23372, "top5_err": 69.97070}
[03/30 21:50:12][INFO] logging.py:   99: json_stats: {"RAM": "87.35/503.30G", "_type": "train_epoch_ssl", "dt": 0.90344, "dt_data": 0.90344, "dt_net": 34.91732, "epoch": "16/600", "eta": "2:47:03", "gpu_mem": "27.10G", "grad_norm": 1.53543, "loss": 3.47790, "lr": 0.04573, "top1_err": 82.13575, "top5_err": 70.97553}
[03/30 21:50:12][INFO] train_net.py:  692: Epoch 15 takes 494.18s. Epochs from 0 to 15 take 496.94s in average and 496.33s in median.
[03/30 21:50:12][INFO] train_net.py:  698: For epoch 15, each iteraction takes 26.01s in average. From epoch 0 to 15, each iteraction takes 26.15s in average.
[03/30 21:54:37][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.05427, "dt_data": 0.00071, "dt_net": 6.05356, "epoch": "17/600", "eta": "18:38:37", "gpu_mem": "27.10G", "grad_norm": 3.80767, "iter": "10/19", "loss": 3.47863, "lr": 0.04720, "top1_err": 82.51953, "top5_err": 73.09570}
[03/30 21:58:25][INFO] logging.py:   99: json_stats: {"RAM": "80.03/503.30G", "_type": "train_epoch_ssl", "dt": 1.45161, "dt_data": 1.45161, "dt_net": 18.70928, "epoch": "17/600", "eta": "4:27:58", "gpu_mem": "27.10G", "grad_norm": 3.19704, "loss": 3.47802, "lr": 0.04853, "top1_err": 83.55092, "top5_err": 73.73047}
[03/30 21:58:25][INFO] train_net.py:  692: Epoch 16 takes 493.11s. Epochs from 0 to 16 take 496.72s in average and 494.52s in median.
[03/30 21:58:25][INFO] train_net.py:  698: For epoch 16, each iteraction takes 25.95s in average. From epoch 0 to 16, each iteraction takes 26.14s in average.
[03/30 22:02:50][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.02674, "dt_data": 0.00095, "dt_net": 6.02579, "epoch": "18/600", "eta": "18:31:37", "gpu_mem": "27.10G", "grad_norm": 1.78713, "iter": "10/19", "loss": 3.43878, "lr": 0.05001, "top1_err": 84.01693, "top5_err": 73.33984}
[03/30 22:06:29][INFO] logging.py:   99: json_stats: {"RAM": "80.01/503.30G", "_type": "train_epoch_ssl", "dt": 1.33391, "dt_data": 1.33391, "dt_net": 24.21388, "epoch": "18/600", "eta": "4:05:49", "gpu_mem": "27.10G", "grad_norm": 2.07064, "loss": 3.44500, "lr": 0.05134, "top1_err": 84.94552, "top5_err": 74.33182}
[03/30 22:06:29][INFO] train_net.py:  692: Epoch 17 takes 484.23s. Epochs from 0 to 17 take 496.02s in average and 494.35s in median.
[03/30 22:06:29][INFO] train_net.py:  698: For epoch 17, each iteraction takes 25.49s in average. From epoch 0 to 17, each iteraction takes 26.11s in average.
[03/30 22:10:53][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.12705, "dt_data": 0.00071, "dt_net": 6.12633, "epoch": "19/600", "eta": "18:48:11", "gpu_mem": "27.10G", "grad_norm": 1.44386, "iter": "10/19", "loss": 3.45314, "lr": 0.05281, "top1_err": 86.57227, "top5_err": 74.73958}
[03/30 22:14:36][INFO] logging.py:   99: json_stats: {"RAM": "80.02/503.30G", "_type": "train_epoch_ssl", "dt": 1.11978, "dt_data": 1.11978, "dt_net": 15.33363, "epoch": "19/600", "eta": "3:26:00", "gpu_mem": "27.10G", "grad_norm": 1.60163, "loss": 3.45445, "lr": 0.05414, "top1_err": 86.23903, "top5_err": 74.98800}
[03/30 22:14:36][INFO] train_net.py:  692: Epoch 18 takes 486.22s. Epochs from 0 to 18 take 495.51s in average and 494.18s in median.
[03/30 22:14:36][INFO] train_net.py:  698: For epoch 18, each iteraction takes 25.59s in average. From epoch 0 to 18, each iteraction takes 26.08s in average.
[03/30 22:19:02][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.12098, "dt_data": 0.00070, "dt_net": 6.12029, "epoch": "20/600", "eta": "18:45:08", "gpu_mem": "27.10G", "grad_norm": 0.93134, "iter": "10/19", "loss": 3.46051, "lr": 0.05562, "top1_err": 85.67708, "top5_err": 73.95833}
[03/30 22:22:55][INFO] logging.py:   99: json_stats: {"RAM": "82.57/503.30G", "_type": "train_epoch_ssl", "dt": 0.87202, "dt_data": 0.87202, "dt_net": 14.59695, "epoch": "20/600", "eta": "2:40:09", "gpu_mem": "27.10G", "grad_norm": 0.80367, "loss": 3.47547, "lr": 0.05695, "top1_err": 85.93407, "top5_err": 74.99314}
[03/30 22:22:55][INFO] train_net.py:  692: Epoch 19 takes 499.91s. Epochs from 0 to 19 take 495.73s in average and 494.35s in median.
[03/30 22:22:55][INFO] train_net.py:  698: For epoch 19, each iteraction takes 26.31s in average. From epoch 0 to 19, each iteraction takes 26.09s in average.
[03/30 22:27:23][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.10271, "dt_data": 0.00072, "dt_net": 6.10198, "epoch": "21/600", "eta": "18:39:50", "gpu_mem": "27.10G", "grad_norm": 2.93916, "iter": "10/19", "loss": 3.48693, "lr": 0.05842, "top1_err": 85.46549, "top5_err": 73.38867}
[03/30 22:31:22][INFO] logging.py:   99: json_stats: {"RAM": "87.20/503.30G", "_type": "train_epoch_ssl", "dt": 0.91070, "dt_data": 0.91069, "dt_net": 5.90408, "epoch": "21/600", "eta": "2:46:57", "gpu_mem": "27.10G", "grad_norm": 1.30026, "loss": 3.49997, "lr": 0.05975, "top1_err": 85.31730, "top5_err": 73.25932}
[03/30 22:31:22][INFO] train_net.py:  692: Epoch 20 takes 506.28s. Epochs from 0 to 20 take 496.23s in average and 494.52s in median.
[03/30 22:31:22][INFO] train_net.py:  698: For epoch 20, each iteraction takes 26.65s in average. From epoch 0 to 20, each iteraction takes 26.12s in average.
[03/30 22:35:45][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.04873, "dt_data": 0.00083, "dt_net": 6.04790, "epoch": "22/600", "eta": "18:28:01", "gpu_mem": "27.10G", "grad_norm": 2.40450, "iter": "10/19", "loss": 3.53035, "lr": 0.06123, "top1_err": 83.75652, "top5_err": 71.12630}
[03/30 22:39:37][INFO] logging.py:   99: json_stats: {"RAM": "82.05/503.30G", "_type": "train_epoch_ssl", "dt": 1.43463, "dt_data": 1.43462, "dt_net": 35.44194, "epoch": "22/600", "eta": "4:22:34", "gpu_mem": "27.10G", "grad_norm": 0.96535, "loss": 3.53441, "lr": 0.06255, "top1_err": 83.24938, "top5_err": 70.66372}
[03/30 22:39:37][INFO] train_net.py:  692: Epoch 21 takes 494.92s. Epochs from 0 to 21 take 496.17s in average and 494.72s in median.
[03/30 22:39:37][INFO] train_net.py:  698: For epoch 21, each iteraction takes 26.05s in average. From epoch 0 to 21, each iteraction takes 26.11s in average.
[03/30 22:44:05][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.05381, "dt_data": 0.00072, "dt_net": 6.05309, "epoch": "23/600", "eta": "18:27:02", "gpu_mem": "27.10G", "grad_norm": 2.08212, "iter": "10/19", "loss": 3.55299, "lr": 0.06403, "top1_err": 81.72200, "top5_err": 71.33789}
[03/30 22:47:54][INFO] logging.py:   99: json_stats: {"RAM": "82.06/503.30G", "_type": "train_epoch_ssl", "dt": 1.38203, "dt_data": 1.38202, "dt_net": 36.63961, "epoch": "23/600", "eta": "4:12:30", "gpu_mem": "27.10G", "grad_norm": 1.30711, "loss": 3.54632, "lr": 0.06536, "top1_err": 81.23458, "top5_err": 69.45072}
[03/30 22:47:54][INFO] train_net.py:  692: Epoch 22 takes 497.79s. Epochs from 0 to 22 take 496.24s in average and 494.92s in median.
[03/30 22:47:54][INFO] train_net.py:  698: For epoch 22, each iteraction takes 26.20s in average. From epoch 0 to 22, each iteraction takes 26.12s in average.
[03/30 22:52:16][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.04462, "dt_data": 0.00061, "dt_net": 6.04400, "epoch": "24/600", "eta": "18:23:26", "gpu_mem": "27.10G", "grad_norm": 2.93102, "iter": "10/19", "loss": 3.52483, "lr": 0.06684, "top1_err": 80.46875, "top5_err": 68.84766}
[03/30 22:56:04][INFO] logging.py:   99: json_stats: {"RAM": "82.06/503.30G", "_type": "train_epoch_ssl", "dt": 1.23105, "dt_data": 1.23105, "dt_net": 25.80931, "epoch": "24/600", "eta": "3:44:32", "gpu_mem": "27.10G", "grad_norm": 1.06792, "loss": 3.51799, "lr": 0.06816, "top1_err": 78.51048, "top5_err": 67.23204}
[03/30 22:56:04][INFO] train_net.py:  692: Epoch 23 takes 489.34s. Epochs from 0 to 23 take 495.95s in average and 494.72s in median.
[03/30 22:56:04][INFO] train_net.py:  698: For epoch 23, each iteraction takes 25.75s in average. From epoch 0 to 23, each iteraction takes 26.10s in average.
[03/30 23:00:28][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.04659, "dt_data": 0.00090, "dt_net": 6.04568, "epoch": "25/600", "eta": "18:21:53", "gpu_mem": "27.10G", "grad_norm": 1.48145, "iter": "10/19", "loss": 3.49084, "lr": 0.06964, "top1_err": 78.10872, "top5_err": 67.41536}
[03/30 23:04:17][INFO] logging.py:   99: json_stats: {"RAM": "86.21/503.30G", "_type": "train_epoch_ssl", "dt": 0.94002, "dt_data": 0.94002, "dt_net": 8.95342, "epoch": "25/600", "eta": "2:51:09", "gpu_mem": "27.10G", "grad_norm": 2.50112, "loss": 3.49067, "lr": 0.07097, "top1_err": 78.75891, "top5_err": 67.88822}
[03/30 23:04:17][INFO] train_net.py:  692: Epoch 24 takes 493.44s. Epochs from 0 to 24 take 495.85s in average and 494.52s in median.
[03/30 23:04:17][INFO] train_net.py:  698: For epoch 24, each iteraction takes 25.97s in average. From epoch 0 to 24, each iteraction takes 26.10s in average.
[03/30 23:08:45][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.05757, "dt_data": 0.00082, "dt_net": 6.05675, "epoch": "26/600", "eta": "18:21:58", "gpu_mem": "27.10G", "grad_norm": 2.55186, "iter": "10/19", "loss": 3.49584, "lr": 0.07244, "top1_err": 80.79427, "top5_err": 69.97070}
[03/30 23:12:39][INFO] logging.py:   99: json_stats: {"RAM": "82.13/503.30G", "_type": "train_epoch_ssl", "dt": 1.38699, "dt_data": 1.38699, "dt_net": 11.63515, "epoch": "26/600", "eta": "4:12:06", "gpu_mem": "27.10G", "grad_norm": 1.53408, "loss": 3.49674, "lr": 0.07377, "top1_err": 80.26144, "top5_err": 69.99897}
[03/30 23:12:39][INFO] train_net.py:  692: Epoch 25 takes 501.92s. Epochs from 0 to 25 take 496.09s in average and 494.72s in median.
[03/30 23:12:39][INFO] train_net.py:  698: For epoch 25, each iteraction takes 26.42s in average. From epoch 0 to 25, each iteraction takes 26.11s in average.
[03/30 23:17:02][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.05579, "dt_data": 0.00068, "dt_net": 6.05511, "epoch": "27/600", "eta": "18:19:43", "gpu_mem": "27.10G", "grad_norm": 1.92842, "iter": "10/19", "loss": 3.48640, "lr": 0.07525, "top1_err": 80.82682, "top5_err": 70.24739}
[03/30 23:20:52][INFO] logging.py:   99: json_stats: {"RAM": "82.04/503.30G", "_type": "train_epoch_ssl", "dt": 1.23864, "dt_data": 1.23864, "dt_net": 5.96593, "epoch": "27/600", "eta": "3:44:44", "gpu_mem": "27.10G", "grad_norm": 1.69245, "loss": 3.49523, "lr": 0.07658, "top1_err": 81.28255, "top5_err": 70.79393}
[03/30 23:20:52][INFO] train_net.py:  692: Epoch 26 takes 493.19s. Epochs from 0 to 26 take 495.98s in average and 494.52s in median.
[03/30 23:20:52][INFO] train_net.py:  698: For epoch 26, each iteraction takes 25.96s in average. From epoch 0 to 26, each iteraction takes 26.10s in average.
[03/30 23:25:16][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.04029, "dt_data": 0.00075, "dt_net": 6.03953, "epoch": "28/600", "eta": "18:15:00", "gpu_mem": "27.10G", "grad_norm": 1.22873, "iter": "10/19", "loss": 3.50710, "lr": 0.07805, "top1_err": 83.90299, "top5_err": 72.70507}
[03/30 23:28:55][INFO] logging.py:   99: json_stats: {"RAM": "82.05/503.30G", "_type": "train_epoch_ssl", "dt": 1.55531, "dt_data": 1.55531, "dt_net": 17.88051, "epoch": "28/600", "eta": "4:41:42", "gpu_mem": "27.10G", "grad_norm": 2.16716, "loss": 3.51305, "lr": 0.07938, "top1_err": 84.52748, "top5_err": 73.63281}
[03/30 23:28:55][INFO] train_net.py:  692: Epoch 27 takes 483.11s. Epochs from 0 to 27 take 495.52s in average and 494.35s in median.
[03/30 23:28:55][INFO] train_net.py:  698: For epoch 27, each iteraction takes 25.43s in average. From epoch 0 to 27, each iteraction takes 26.08s in average.
[03/30 23:33:24][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.04848, "dt_data": 0.00115, "dt_net": 6.04733, "epoch": "29/600", "eta": "18:14:34", "gpu_mem": "27.10G", "grad_norm": 1.73528, "iter": "10/19", "loss": 3.55492, "lr": 0.08086, "top1_err": 82.97525, "top5_err": 73.40495}
[03/30 23:37:11][INFO] logging.py:   99: json_stats: {"RAM": "82.36/503.30G", "_type": "train_epoch_ssl", "dt": 1.04693, "dt_data": 1.04693, "dt_net": 28.75154, "epoch": "29/600", "eta": "3:09:17", "gpu_mem": "27.10G", "grad_norm": 1.08903, "loss": 3.55746, "lr": 0.08219, "top1_err": 83.69826, "top5_err": 73.68078}
[03/30 23:37:11][INFO] train_net.py:  692: Epoch 28 takes 495.55s. Epochs from 0 to 28 take 495.52s in average and 494.52s in median.
[03/30 23:37:11][INFO] train_net.py:  698: For epoch 28, each iteraction takes 26.08s in average. From epoch 0 to 28, each iteraction takes 26.08s in average.
[03/30 23:41:35][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.05787, "dt_data": 0.00082, "dt_net": 6.05705, "epoch": "30/600", "eta": "18:14:21", "gpu_mem": "27.10G", "grad_norm": 2.32176, "iter": "10/19", "loss": 3.54752, "lr": 0.08366, "top1_err": 86.10026, "top5_err": 75.52083}
[03/30 23:45:30][INFO] logging.py:   99: json_stats: {"RAM": "82.07/503.30G", "_type": "train_epoch_ssl", "dt": 1.30503, "dt_data": 1.30503, "dt_net": 10.65175, "epoch": "30/600", "eta": "3:55:32", "gpu_mem": "27.10G", "grad_norm": 1.97612, "loss": 3.54906, "lr": 0.08499, "top1_err": 85.71306, "top5_err": 75.34779}
[03/30 23:45:30][INFO] train_net.py:  692: Epoch 29 takes 499.10s. Epochs from 0 to 29 take 495.64s in average and 494.72s in median.
[03/30 23:45:30][INFO] train_net.py:  698: For epoch 29, each iteraction takes 26.27s in average. From epoch 0 to 29, each iteraction takes 26.09s in average.
[03/30 23:49:55][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 9.89102, "dt_data": 4.01789, "dt_net": 5.87312, "epoch": "31/600", "eta": "1 day, 5:43:40", "gpu_mem": "27.10G", "grad_norm": 1.47043, "iter": "10/19", "loss": 3.53559, "lr": 0.08647, "top1_err": 84.92838, "top5_err": 75.03255}
[03/30 23:53:39][INFO] logging.py:   99: json_stats: {"RAM": "82.08/503.30G", "_type": "train_epoch_ssl", "dt": 1.20431, "dt_data": 1.20431, "dt_net": 16.38845, "epoch": "31/600", "eta": "3:36:59", "gpu_mem": "27.10G", "grad_norm": 0.93148, "loss": 3.55053, "lr": 0.08780, "top1_err": 85.99403, "top5_err": 75.76925}
[03/30 23:53:39][INFO] train_net.py:  692: Epoch 30 takes 489.28s. Epochs from 0 to 30 take 495.43s in average and 494.52s in median.
[03/30 23:53:39][INFO] train_net.py:  698: For epoch 30, each iteraction takes 25.75s in average. From epoch 0 to 30, each iteraction takes 26.08s in average.
[03/30 23:58:17][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.14600, "dt_data": 0.00122, "dt_net": 6.14477, "epoch": "32/600", "eta": "18:26:22", "gpu_mem": "27.10G", "grad_norm": 1.64823, "iter": "10/19", "loss": 3.56163, "lr": 0.08927, "top1_err": 86.32812, "top5_err": 76.04166}
[03/31 00:02:16][INFO] logging.py:   99: json_stats: {"RAM": "82.08/503.30G", "_type": "train_epoch_ssl", "dt": 1.20403, "dt_data": 1.20403, "dt_net": 11.29164, "epoch": "32/600", "eta": "3:36:32", "gpu_mem": "27.10G", "grad_norm": 1.75944, "loss": 3.55355, "lr": 0.09060, "top1_err": 85.44750, "top5_err": 75.56538}
[03/31 00:02:16][INFO] train_net.py:  692: Epoch 31 takes 516.65s. Epochs from 0 to 31 take 496.10s in average and 494.72s in median.
[03/31 00:02:16][INFO] train_net.py:  698: For epoch 31, each iteraction takes 27.19s in average. From epoch 0 to 31, each iteraction takes 26.11s in average.
[03/31 00:06:33][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.03060, "dt_data": 0.00056, "dt_net": 6.03004, "epoch": "33/600", "eta": "18:03:41", "gpu_mem": "27.10G", "grad_norm": 2.96414, "iter": "10/19", "loss": 3.51848, "lr": 0.09208, "top1_err": 85.95377, "top5_err": 74.91862}
[03/31 00:10:19][INFO] logging.py:   99: json_stats: {"RAM": "82.07/503.30G", "_type": "train_epoch_ssl", "dt": 1.04030, "dt_data": 1.04030, "dt_net": 24.09310, "epoch": "33/600", "eta": "3:06:46", "gpu_mem": "27.10G", "grad_norm": 1.57136, "loss": 3.50892, "lr": 0.09341, "top1_err": 84.12315, "top5_err": 73.76987}
[03/31 00:10:19][INFO] train_net.py:  692: Epoch 32 takes 483.23s. Epochs from 0 to 32 take 495.71s in average and 494.52s in median.
[03/31 00:10:19][INFO] train_net.py:  698: For epoch 32, each iteraction takes 25.43s in average. From epoch 0 to 32, each iteraction takes 26.09s in average.
[03/31 00:14:44][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.02116, "dt_data": 0.00092, "dt_net": 6.02023, "epoch": "34/600", "eta": "18:00:05", "gpu_mem": "27.10G", "grad_norm": 1.25878, "iter": "10/19", "loss": 3.47102, "lr": 0.09488, "top1_err": 84.34245, "top5_err": 71.84245}
[03/31 00:18:36][INFO] logging.py:   99: json_stats: {"RAM": "83.19/503.30G", "_type": "train_epoch_ssl", "dt": 0.98586, "dt_data": 0.98586, "dt_net": 20.25188, "epoch": "34/600", "eta": "2:56:41", "gpu_mem": "27.10G", "grad_norm": 1.60701, "loss": 3.46099, "lr": 0.09621, "top1_err": 84.31675, "top5_err": 73.02288}
[03/31 00:18:36][INFO] train_net.py:  692: Epoch 33 takes 496.57s. Epochs from 0 to 33 take 495.73s in average and 494.72s in median.
[03/31 00:18:36][INFO] train_net.py:  698: For epoch 33, each iteraction takes 26.14s in average. From epoch 0 to 33, each iteraction takes 26.09s in average.
[03/31 00:23:03][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.07645, "dt_data": 0.00080, "dt_net": 6.07564, "epoch": "35/600", "eta": "18:08:05", "gpu_mem": "27.10G", "grad_norm": 1.20792, "iter": "10/19", "loss": 3.41446, "lr": 0.09769, "top1_err": 82.74739, "top5_err": 69.95442}
[03/31 00:26:57][INFO] logging.py:   99: json_stats: {"RAM": "82.11/503.30G", "_type": "train_epoch_ssl", "dt": 1.16467, "dt_data": 1.16467, "dt_net": 15.45146, "epoch": "35/600", "eta": "3:28:22", "gpu_mem": "27.10G", "grad_norm": 1.08011, "loss": 3.39426, "lr": 0.09902, "top1_err": 83.29221, "top5_err": 71.06291}
[03/31 00:26:57][INFO] train_net.py:  692: Epoch 34 takes 500.80s. Epochs from 0 to 34 take 495.88s in average and 494.92s in median.
[03/31 00:26:57][INFO] train_net.py:  698: For epoch 34, each iteraction takes 26.36s in average. From epoch 0 to 34, each iteraction takes 26.10s in average.
[03/31 00:31:19][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.04742, "dt_data": 0.00074, "dt_net": 6.04667, "epoch": "36/600", "eta": "18:00:58", "gpu_mem": "27.10G", "grad_norm": 1.81921, "iter": "10/19", "loss": 3.36653, "lr": 0.09914, "top1_err": 83.75651, "top5_err": 72.49348}
[03/31 00:35:11][INFO] logging.py:   99: json_stats: {"RAM": "82.05/503.30G", "_type": "train_epoch_ssl", "dt": 1.30925, "dt_data": 1.30927, "dt_net": 16.91059, "epoch": "36/600", "eta": "3:53:49", "gpu_mem": "27.10G", "grad_norm": 1.12388, "loss": 3.35120, "lr": 0.09912, "top1_err": 83.26137, "top5_err": 71.24109}
[03/31 00:35:11][INFO] train_net.py:  692: Epoch 35 takes 494.12s. Epochs from 0 to 35 take 495.83s in average and 494.72s in median.
[03/31 00:35:11][INFO] train_net.py:  698: For epoch 35, each iteraction takes 26.01s in average. From epoch 0 to 35, each iteraction takes 26.10s in average.
[03/31 00:39:39][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.03681, "dt_data": 0.00067, "dt_net": 6.03614, "epoch": "37/600", "eta": "17:57:10", "gpu_mem": "27.10G", "grad_norm": 1.68323, "iter": "10/19", "loss": 3.31974, "lr": 0.09909, "top1_err": 84.27734, "top5_err": 71.80989}
[03/31 00:43:24][INFO] logging.py:   99: json_stats: {"RAM": "82.08/503.30G", "_type": "train_epoch_ssl", "dt": 1.14625, "dt_data": 1.14625, "dt_net": 5.91363, "epoch": "37/600", "eta": "3:24:20", "gpu_mem": "27.10G", "grad_norm": 1.56207, "loss": 3.30590, "lr": 0.09907, "top1_err": 83.36417, "top5_err": 70.58148}
[03/31 00:43:24][INFO] train_net.py:  692: Epoch 36 takes 492.90s. Epochs from 0 to 36 take 495.75s in average and 494.52s in median.
[03/31 00:43:24][INFO] train_net.py:  698: For epoch 36, each iteraction takes 25.94s in average. From epoch 0 to 36, each iteraction takes 26.09s in average.
[03/31 00:47:45][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.08118, "dt_data": 0.00086, "dt_net": 6.08032, "epoch": "38/600", "eta": "18:03:09", "gpu_mem": "27.10G", "grad_norm": 1.34906, "iter": "10/19", "loss": 3.29405, "lr": 0.09904, "top1_err": 82.42188, "top5_err": 69.46614}
[03/31 00:51:32][INFO] logging.py:   99: json_stats: {"RAM": "82.11/503.30G", "_type": "train_epoch_ssl", "dt": 1.19033, "dt_data": 1.19033, "dt_net": 30.44595, "epoch": "38/600", "eta": "3:31:49", "gpu_mem": "27.10G", "grad_norm": 1.26489, "loss": 3.28720, "lr": 0.09902, "top1_err": 82.02097, "top5_err": 69.61691}
[03/31 00:51:32][INFO] train_net.py:  692: Epoch 37 takes 488.48s. Epochs from 0 to 37 take 495.56s in average and 494.35s in median.
[03/31 00:51:32][INFO] train_net.py:  698: For epoch 37, each iteraction takes 25.71s in average. From epoch 0 to 37, each iteraction takes 26.08s in average.
[03/31 00:55:56][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.04305, "dt_data": 0.00084, "dt_net": 6.04220, "epoch": "39/600", "eta": "17:54:27", "gpu_mem": "27.10G", "grad_norm": 1.28210, "iter": "10/19", "loss": 3.26160, "lr": 0.09899, "top1_err": 82.74739, "top5_err": 69.09179}
[03/31 00:59:42][INFO] logging.py:   99: json_stats: {"RAM": "87.60/503.30G", "_type": "train_epoch_ssl", "dt": 0.90591, "dt_data": 0.90591, "dt_net": 16.77267, "epoch": "39/600", "eta": "2:40:55", "gpu_mem": "27.10G", "grad_norm": 1.65247, "loss": 3.25565, "lr": 0.09896, "top1_err": 83.58861, "top5_err": 70.24396}
[03/31 00:59:42][INFO] train_net.py:  692: Epoch 38 takes 489.98s. Epochs from 0 to 38 take 495.42s in average and 494.18s in median.
[03/31 00:59:42][INFO] train_net.py:  698: For epoch 38, each iteraction takes 25.79s in average. From epoch 0 to 38, each iteraction takes 26.07s in average.
[03/31 01:04:04][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 5.99838, "dt_data": 0.00053, "dt_net": 5.99785, "epoch": "40/600", "eta": "17:44:36", "gpu_mem": "27.10G", "grad_norm": 1.20714, "iter": "10/19", "loss": 3.24776, "lr": 0.09894, "top1_err": 83.04036, "top5_err": 71.01236}
[03/31 01:07:47][INFO] logging.py:   99: json_stats: {"RAM": "88.11/503.30G", "_type": "train_epoch_ssl", "dt": 0.88741, "dt_data": 0.88741, "dt_net": 6.13207, "epoch": "40/600", "eta": "2:37:21", "gpu_mem": "27.10G", "grad_norm": 1.28870, "loss": 3.24517, "lr": 0.09891, "top1_err": 83.39844, "top5_err": 70.34162}
[03/31 01:07:47][INFO] train_net.py:  692: Epoch 39 takes 485.32s. Epochs from 0 to 39 take 495.16s in average and 494.15s in median.
[03/31 01:07:47][INFO] train_net.py:  698: For epoch 39, each iteraction takes 25.54s in average. From epoch 0 to 39, each iteraction takes 26.06s in average.
[03/31 01:12:14][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.04934, "dt_data": 0.00073, "dt_net": 6.04861, "epoch": "41/600", "eta": "17:51:44", "gpu_mem": "27.10G", "grad_norm": 1.55815, "iter": "10/19", "loss": 3.22326, "lr": 0.09888, "top1_err": 84.63541, "top5_err": 71.07747}
[03/31 01:15:57][INFO] logging.py:   99: json_stats: {"RAM": "82.10/503.30G", "_type": "train_epoch_ssl", "dt": 1.22255, "dt_data": 1.22255, "dt_net": 36.86836, "epoch": "41/600", "eta": "3:36:24", "gpu_mem": "27.10G", "grad_norm": 1.69524, "loss": 3.23185, "lr": 0.09886, "top1_err": 85.20593, "top5_err": 71.30276}
[03/31 01:15:57][INFO] train_net.py:  692: Epoch 40 takes 489.31s. Epochs from 0 to 40 take 495.02s in average and 494.12s in median.
[03/31 01:15:57][INFO] train_net.py:  698: For epoch 40, each iteraction takes 25.75s in average. From epoch 0 to 40, each iteraction takes 26.05s in average.
[03/31 01:20:17][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.02612, "dt_data": 0.00057, "dt_net": 6.02555, "epoch": "42/600", "eta": "17:45:43", "gpu_mem": "27.10G", "grad_norm": 1.37183, "iter": "10/19", "loss": 3.23077, "lr": 0.09883, "top1_err": 85.51432, "top5_err": 71.35416}
[03/31 01:23:57][INFO] logging.py:   99: json_stats: {"RAM": "82.08/503.30G", "_type": "train_epoch_ssl", "dt": 1.32296, "dt_data": 1.32296, "dt_net": 7.40749, "epoch": "42/600", "eta": "3:53:45", "gpu_mem": "27.10G", "grad_norm": 2.19716, "loss": 3.22704, "lr": 0.09880, "top1_err": 85.58628, "top5_err": 71.28735}
[03/31 01:23:57][INFO] train_net.py:  692: Epoch 41 takes 479.92s. Epochs from 0 to 41 take 494.66s in average and 493.78s in median.
[03/31 01:23:57][INFO] train_net.py:  698: For epoch 41, each iteraction takes 25.26s in average. From epoch 0 to 41, each iteraction takes 26.03s in average.
[03/31 01:28:25][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.08391, "dt_data": 0.00071, "dt_net": 6.08320, "epoch": "43/600", "eta": "17:54:00", "gpu_mem": "27.10G", "grad_norm": 1.92398, "iter": "10/19", "loss": 3.22655, "lr": 0.09877, "top1_err": 85.62825, "top5_err": 71.76106}
[03/31 01:32:20][INFO] logging.py:   99: json_stats: {"RAM": "82.10/503.30G", "_type": "train_epoch_ssl", "dt": 1.31640, "dt_data": 1.31640, "dt_net": 34.02365, "epoch": "43/600", "eta": "3:52:10", "gpu_mem": "27.10G", "grad_norm": 1.50278, "loss": 3.22573, "lr": 0.09874, "top1_err": 85.86040, "top5_err": 71.80989}
[03/31 01:32:20][INFO] train_net.py:  692: Epoch 42 takes 503.34s. Epochs from 0 to 42 take 494.86s in average and 494.12s in median.
[03/31 01:32:20][INFO] train_net.py:  698: For epoch 42, each iteraction takes 26.49s in average. From epoch 0 to 42, each iteraction takes 26.05s in average.
[03/31 01:36:41][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 9.38238, "dt_data": 0.00084, "dt_net": 9.38153, "epoch": "44/600", "eta": "1 day, 3:33:19", "gpu_mem": "27.10G", "grad_norm": 2.47813, "iter": "10/19", "loss": 3.22514, "lr": 0.09871, "top1_err": 85.67708, "top5_err": 72.13541}
[03/31 01:40:12][INFO] logging.py:   99: json_stats: {"RAM": "82.10/503.30G", "_type": "train_epoch_ssl", "dt": 1.41603, "dt_data": 1.41603, "dt_net": 23.44725, "epoch": "44/600", "eta": "4:09:18", "gpu_mem": "27.10G", "grad_norm": 2.24637, "loss": 3.22663, "lr": 0.09868, "top1_err": 86.29043, "top5_err": 71.38329}
[03/31 01:40:12][INFO] train_net.py:  692: Epoch 43 takes 471.75s. Epochs from 0 to 43 take 494.34s in average and 493.78s in median.
[03/31 01:40:12][INFO] train_net.py:  698: For epoch 43, each iteraction takes 24.83s in average. From epoch 0 to 43, each iteraction takes 26.02s in average.
[03/31 01:44:42][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.05312, "dt_data": 0.00092, "dt_net": 6.05220, "epoch": "45/600", "eta": "17:44:44", "gpu_mem": "27.10G", "grad_norm": 1.20837, "iter": "10/19", "loss": 3.24161, "lr": 0.09865, "top1_err": 87.51627, "top5_err": 72.77018}
[03/31 01:48:32][INFO] logging.py:   99: json_stats: {"RAM": "82.10/503.30G", "_type": "train_epoch_ssl", "dt": 1.19581, "dt_data": 1.19581, "dt_net": 37.19255, "epoch": "45/600", "eta": "3:30:09", "gpu_mem": "27.10G", "grad_norm": 1.58100, "loss": 3.23868, "lr": 0.09862, "top1_err": 87.09224, "top5_err": 72.41296}
[03/31 01:48:32][INFO] train_net.py:  692: Epoch 44 takes 499.69s. Epochs from 0 to 44 take 494.46s in average and 494.12s in median.
[03/31 01:48:32][INFO] train_net.py:  698: For epoch 44, each iteraction takes 26.30s in average. From epoch 0 to 44, each iteraction takes 26.02s in average.
[03/31 01:53:00][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.04201, "dt_data": 0.00086, "dt_net": 6.04115, "epoch": "46/600", "eta": "17:40:52", "gpu_mem": "27.10G", "grad_norm": 1.36390, "iter": "10/19", "loss": 3.23489, "lr": 0.09859, "top1_err": 87.58138, "top5_err": 72.50976}
[03/31 01:56:54][INFO] logging.py:   99: json_stats: {"RAM": "82.10/503.30G", "_type": "train_epoch_ssl", "dt": 1.29700, "dt_data": 1.29700, "dt_net": 21.18601, "epoch": "46/600", "eta": "3:47:31", "gpu_mem": "27.10G", "grad_norm": 1.10957, "loss": 3.22634, "lr": 0.09856, "top1_err": 87.12479, "top5_err": 72.23136}
[03/31 01:56:54][INFO] train_net.py:  692: Epoch 45 takes 502.48s. Epochs from 0 to 45 take 494.63s in average and 494.15s in median.
[03/31 01:56:54][INFO] train_net.py:  698: For epoch 45, each iteraction takes 26.45s in average. From epoch 0 to 45, each iteraction takes 26.03s in average.
[03/31 02:01:24][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.09560, "dt_data": 0.00111, "dt_net": 6.09449, "epoch": "47/600", "eta": "17:48:21", "gpu_mem": "27.10G", "grad_norm": 2.97492, "iter": "10/19", "loss": 3.23029, "lr": 0.09853, "top1_err": 88.63932, "top5_err": 74.33268}
[03/31 02:05:26][INFO] logging.py:   99: json_stats: {"RAM": "82.10/503.30G", "_type": "train_epoch_ssl", "dt": 1.27488, "dt_data": 1.27488, "dt_net": 12.74024, "epoch": "47/600", "eta": "3:43:14", "gpu_mem": "27.10G", "grad_norm": 1.64819, "loss": 3.23412, "lr": 0.09850, "top1_err": 88.44744, "top5_err": 73.46662}
[03/31 02:05:26][INFO] train_net.py:  692: Epoch 46 takes 512.13s. Epochs from 0 to 46 take 495.00s in average and 494.18s in median.
[03/31 02:05:26][INFO] train_net.py:  698: For epoch 46, each iteraction takes 26.95s in average. From epoch 0 to 46, each iteraction takes 26.05s in average.
[03/31 02:09:54][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.03649, "dt_data": 0.00080, "dt_net": 6.03569, "epoch": "48/600", "eta": "17:36:05", "gpu_mem": "27.10G", "grad_norm": 1.52981, "iter": "10/19", "loss": 3.24609, "lr": 0.09846, "top1_err": 88.24870, "top5_err": 73.50260}
[03/31 02:13:37][INFO] logging.py:   99: json_stats: {"RAM": "82.11/503.30G", "_type": "train_epoch_ssl", "dt": 1.17235, "dt_data": 1.17235, "dt_net": 6.17096, "epoch": "48/600", "eta": "3:24:55", "gpu_mem": "27.10G", "grad_norm": 1.48054, "loss": 3.25237, "lr": 0.09843, "top1_err": 88.83292, "top5_err": 73.61054}
[03/31 02:13:37][INFO] train_net.py:  692: Epoch 47 takes 490.39s. Epochs from 0 to 47 take 494.91s in average and 494.15s in median.
[03/31 02:13:37][INFO] train_net.py:  698: For epoch 47, each iteraction takes 25.81s in average. From epoch 0 to 47, each iteraction takes 26.05s in average.
[03/31 02:18:01][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.04093, "dt_data": 0.00068, "dt_net": 6.04025, "epoch": "49/600", "eta": "17:34:56", "gpu_mem": "27.10G", "grad_norm": 2.76775, "iter": "10/19", "loss": 3.24950, "lr": 0.09840, "top1_err": 88.73698, "top5_err": 73.97461}
[03/31 02:21:56][INFO] logging.py:   99: json_stats: {"RAM": "82.12/503.30G", "_type": "train_epoch_ssl", "dt": 1.36385, "dt_data": 1.36385, "dt_net": 5.89571, "epoch": "49/600", "eta": "3:57:57", "gpu_mem": "27.10G", "grad_norm": 1.73135, "loss": 3.25414, "lr": 0.09837, "top1_err": 87.96772, "top5_err": 73.72190}
[03/31 02:21:56][INFO] train_net.py:  692: Epoch 48 takes 499.45s. Epochs from 0 to 48 take 495.00s in average and 494.18s in median.
[03/31 02:21:56][INFO] train_net.py:  698: For epoch 48, each iteraction takes 26.29s in average. From epoch 0 to 48, each iteraction takes 26.05s in average.
[03/31 02:26:21][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.06862, "dt_data": 0.00089, "dt_net": 6.06773, "epoch": "50/600", "eta": "17:37:51", "gpu_mem": "27.10G", "grad_norm": 1.46451, "iter": "10/19", "loss": 3.25537, "lr": 0.09833, "top1_err": 88.62304, "top5_err": 73.24219}
[03/31 02:30:12][INFO] logging.py:   99: json_stats: {"RAM": "82.11/503.30G", "_type": "train_epoch_ssl", "dt": 1.40560, "dt_data": 1.40560, "dt_net": 17.34074, "epoch": "50/600", "eta": "4:04:48", "gpu_mem": "27.10G", "grad_norm": 2.40294, "loss": 3.25883, "lr": 0.09830, "top1_err": 87.98999, "top5_err": 73.12226}
[03/31 02:30:12][INFO] train_net.py:  692: Epoch 49 takes 496.30s. Epochs from 0 to 49 take 495.03s in average and 494.35s in median.
[03/31 02:30:12][INFO] train_net.py:  698: For epoch 49, each iteraction takes 26.12s in average. From epoch 0 to 49, each iteraction takes 26.05s in average.
[03/31 02:34:52][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.07367, "dt_data": 0.00072, "dt_net": 6.07295, "epoch": "51/600", "eta": "17:36:49", "gpu_mem": "27.10G", "grad_norm": 1.59492, "iter": "10/19", "loss": 3.26417, "lr": 0.09826, "top1_err": 88.81836, "top5_err": 74.12109}
[03/31 02:38:53][INFO] logging.py:   99: json_stats: {"RAM": "82.16/503.30G", "_type": "train_epoch_ssl", "dt": 1.22118, "dt_data": 1.22118, "dt_net": 5.89026, "epoch": "51/600", "eta": "3:32:17", "gpu_mem": "27.10G", "grad_norm": 1.40021, "loss": 3.27447, "lr": 0.09823, "top1_err": 88.80894, "top5_err": 74.38322}
[03/31 02:38:53][INFO] train_net.py:  692: Epoch 50 takes 519.38s. Epochs from 0 to 50 take 495.50s in average and 494.52s in median.
[03/31 02:38:53][INFO] train_net.py:  698: For epoch 50, each iteraction takes 27.34s in average. From epoch 0 to 50, each iteraction takes 26.08s in average.
[03/31 02:43:16][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.05321, "dt_data": 0.00092, "dt_net": 6.05229, "epoch": "52/600", "eta": "17:31:20", "gpu_mem": "27.10G", "grad_norm": 1.92140, "iter": "10/19", "loss": 3.25445, "lr": 0.09819, "top1_err": 86.88151, "top5_err": 71.77734}
[03/31 02:47:01][INFO] logging.py:   99: json_stats: {"RAM": "82.14/503.30G", "_type": "train_epoch_ssl", "dt": 1.19166, "dt_data": 1.19165, "dt_net": 18.18692, "epoch": "52/600", "eta": "3:26:46", "gpu_mem": "27.10G", "grad_norm": 1.93246, "loss": 3.26617, "lr": 0.09816, "top1_err": 87.70216, "top5_err": 72.17653}
[03/31 02:47:01][INFO] train_net.py:  692: Epoch 51 takes 488.17s. Epochs from 0 to 51 take 495.36s in average and 494.35s in median.
[03/31 02:47:01][INFO] train_net.py:  698: For epoch 51, each iteraction takes 25.69s in average. From epoch 0 to 51, each iteraction takes 26.07s in average.
[03/31 02:51:23][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.07355, "dt_data": 0.00071, "dt_net": 6.07283, "epoch": "53/600", "eta": "17:32:57", "gpu_mem": "27.10G", "grad_norm": 2.74297, "iter": "10/19", "loss": 3.25670, "lr": 0.09812, "top1_err": 87.76042, "top5_err": 73.35612}
[03/31 02:55:11][INFO] logging.py:   99: json_stats: {"RAM": "83.02/503.30G", "_type": "train_epoch_ssl", "dt": 1.06363, "dt_data": 1.06363, "dt_net": 21.70869, "epoch": "53/600", "eta": "3:04:13", "gpu_mem": "27.10G", "grad_norm": 1.51593, "loss": 3.26625, "lr": 0.09809, "top1_err": 87.92318, "top5_err": 73.18222}
[03/31 02:55:11][INFO] train_net.py:  692: Epoch 52 takes 489.31s. Epochs from 0 to 52 take 495.25s in average and 494.18s in median.
[03/31 02:55:11][INFO] train_net.py:  698: For epoch 52, each iteraction takes 25.75s in average. From epoch 0 to 52, each iteraction takes 26.07s in average.
[03/31 02:59:40][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.07847, "dt_data": 0.00106, "dt_net": 6.07740, "epoch": "54/600", "eta": "17:31:52", "gpu_mem": "27.10G", "grad_norm": 2.99072, "iter": "10/19", "loss": 3.26663, "lr": 0.09805, "top1_err": 87.76042, "top5_err": 72.20052}
[03/31 03:03:30][INFO] logging.py:   99: json_stats: {"RAM": "82.16/503.30G", "_type": "train_epoch_ssl", "dt": 1.18711, "dt_data": 1.18710, "dt_net": 36.29467, "epoch": "54/600", "eta": "3:25:14", "gpu_mem": "27.10G", "grad_norm": 2.07642, "loss": 3.28150, "lr": 0.09802, "top1_err": 87.90776, "top5_err": 72.95264}
[03/31 03:03:30][INFO] train_net.py:  692: Epoch 53 takes 499.38s. Epochs from 0 to 53 take 495.32s in average and 494.35s in median.
[03/31 03:03:30][INFO] train_net.py:  698: For epoch 53, each iteraction takes 26.28s in average. From epoch 0 to 53, each iteraction takes 26.07s in average.
[03/31 03:07:49][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 8.34790, "dt_data": 0.00077, "dt_net": 8.34713, "epoch": "55/600", "eta": "1 day, 0:01:57", "gpu_mem": "27.10G", "grad_norm": 1.73280, "iter": "10/19", "loss": 3.26586, "lr": 0.09798, "top1_err": 88.96484, "top5_err": 72.88411}
[03/31 03:11:40][INFO] logging.py:   99: json_stats: {"RAM": "82.15/503.30G", "_type": "train_epoch_ssl", "dt": 1.14702, "dt_data": 1.14702, "dt_net": 31.38420, "epoch": "55/600", "eta": "3:17:56", "gpu_mem": "27.10G", "grad_norm": 2.31373, "loss": 3.26638, "lr": 0.09794, "top1_err": 87.37836, "top5_err": 72.09429}
[03/31 03:11:40][INFO] train_net.py:  692: Epoch 54 takes 489.86s. Epochs from 0 to 54 take 495.23s in average and 494.18s in median.
[03/31 03:11:40][INFO] train_net.py:  698: For epoch 54, each iteraction takes 25.78s in average. From epoch 0 to 54, each iteraction takes 26.06s in average.
[03/31 03:16:22][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.14425, "dt_data": 0.00087, "dt_net": 6.14338, "epoch": "56/600", "eta": "17:39:22", "gpu_mem": "27.10G", "grad_norm": 1.63618, "iter": "10/19", "loss": 3.27426, "lr": 0.09791, "top1_err": 89.14388, "top5_err": 73.48633}
[03/31 03:20:34][INFO] logging.py:   99: json_stats: {"RAM": "82.95/503.30G", "_type": "train_epoch_ssl", "dt": 1.41912, "dt_data": 1.41912, "dt_net": 32.34635, "epoch": "56/600", "eta": "4:04:27", "gpu_mem": "27.10G", "grad_norm": 1.61776, "loss": 3.28190, "lr": 0.09787, "top1_err": 88.28639, "top5_err": 73.24218}
[03/31 03:20:34][INFO] train_net.py:  692: Epoch 55 takes 533.70s. Epochs from 0 to 55 take 495.91s in average and 494.35s in median.
[03/31 03:20:34][INFO] train_net.py:  698: For epoch 55, each iteraction takes 28.09s in average. From epoch 0 to 55, each iteraction takes 26.10s in average.
[03/31 03:24:57][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.05616, "dt_data": 0.00071, "dt_net": 6.05545, "epoch": "57/600", "eta": "17:22:15", "gpu_mem": "27.10G", "grad_norm": 1.86340, "iter": "10/19", "loss": 3.26473, "lr": 0.09783, "top1_err": 86.73502, "top5_err": 71.72851}
[03/31 03:28:48][INFO] logging.py:   99: json_stats: {"RAM": "82.19/503.30G", "_type": "train_epoch_ssl", "dt": 1.47215, "dt_data": 1.47214, "dt_net": 37.37188, "epoch": "57/600", "eta": "4:13:07", "gpu_mem": "27.10G", "grad_norm": 2.62908, "loss": 3.26622, "lr": 0.09779, "top1_err": 87.58052, "top5_err": 72.18510}
[03/31 03:28:48][INFO] train_net.py:  692: Epoch 56 takes 494.10s. Epochs from 0 to 56 take 495.88s in average and 494.18s in median.
[03/31 03:28:48][INFO] train_net.py:  698: For epoch 56, each iteraction takes 26.01s in average. From epoch 0 to 56, each iteraction takes 26.10s in average.
[03/31 03:33:14][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.15820, "dt_data": 0.00095, "dt_net": 6.15725, "epoch": "58/600", "eta": "17:37:52", "gpu_mem": "27.10G", "grad_norm": 2.19387, "iter": "10/19", "loss": 3.26453, "lr": 0.09775, "top1_err": 88.62304, "top5_err": 72.68880}
[03/31 03:36:59][INFO] logging.py:   99: json_stats: {"RAM": "82.16/503.30G", "_type": "train_epoch_ssl", "dt": 1.19698, "dt_data": 1.19697, "dt_net": 27.62650, "epoch": "58/600", "eta": "3:25:25", "gpu_mem": "27.10G", "grad_norm": 2.46276, "loss": 3.26493, "lr": 0.09772, "top1_err": 87.75013, "top5_err": 72.38384}
[03/31 03:36:59][INFO] train_net.py:  692: Epoch 57 takes 490.85s. Epochs from 0 to 57 take 495.79s in average and 494.15s in median.
[03/31 03:36:59][INFO] train_net.py:  698: For epoch 57, each iteraction takes 25.83s in average. From epoch 0 to 57, each iteraction takes 26.09s in average.
[03/31 03:41:16][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.09651, "dt_data": 0.00075, "dt_net": 6.09576, "epoch": "59/600", "eta": "17:25:20", "gpu_mem": "27.10G", "grad_norm": 2.82206, "iter": "10/19", "loss": 3.26543, "lr": 0.09767, "top1_err": 87.43490, "top5_err": 71.90755}
[03/31 03:44:56][INFO] logging.py:   99: json_stats: {"RAM": "82.17/503.30G", "_type": "train_epoch_ssl", "dt": 1.41589, "dt_data": 1.41589, "dt_net": 10.77791, "epoch": "59/600", "eta": "4:02:33", "gpu_mem": "27.10G", "grad_norm": 2.19528, "loss": 3.27009, "lr": 0.09764, "top1_err": 87.42290, "top5_err": 72.52432}
[03/31 03:44:56][INFO] train_net.py:  692: Epoch 58 takes 477.50s. Epochs from 0 to 58 take 495.48s in average and 494.12s in median.
[03/31 03:44:56][INFO] train_net.py:  698: For epoch 58, each iteraction takes 25.13s in average. From epoch 0 to 58, each iteraction takes 26.08s in average.
[03/31 03:49:20][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.05556, "dt_data": 0.00094, "dt_net": 6.05461, "epoch": "60/600", "eta": "17:16:24", "gpu_mem": "27.10G", "grad_norm": 1.94531, "iter": "10/19", "loss": 3.29994, "lr": 0.09760, "top1_err": 88.44401, "top5_err": 73.87695}
[03/31 03:53:09][INFO] logging.py:   99: json_stats: {"RAM": "82.16/503.30G", "_type": "train_epoch_ssl", "dt": 1.51076, "dt_data": 1.51076, "dt_net": 24.14776, "epoch": "60/600", "eta": "4:18:19", "gpu_mem": "27.10G", "grad_norm": 1.80488, "loss": 3.28211, "lr": 0.09756, "top1_err": 87.73129, "top5_err": 72.99376}
[03/31 03:53:09][INFO] train_net.py:  692: Epoch 59 takes 493.33s. Epochs from 0 to 59 take 495.45s in average and 494.11s in median.
[03/31 03:53:09][INFO] train_net.py:  698: For epoch 59, each iteraction takes 25.96s in average. From epoch 0 to 59, each iteraction takes 26.08s in average.
[03/31 03:57:36][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.05838, "dt_data": 0.00100, "dt_net": 6.05738, "epoch": "61/600", "eta": "17:14:58", "gpu_mem": "27.10G", "grad_norm": 3.12516, "iter": "10/19", "loss": 3.27619, "lr": 0.09751, "top1_err": 88.46029, "top5_err": 73.48632}
[03/31 04:01:31][INFO] logging.py:   99: json_stats: {"RAM": "82.17/503.30G", "_type": "train_epoch_ssl", "dt": 1.42222, "dt_data": 1.42222, "dt_net": 24.55437, "epoch": "61/600", "eta": "4:02:44", "gpu_mem": "27.10G", "grad_norm": 2.52666, "loss": 3.27570, "lr": 0.09748, "top1_err": 88.55023, "top5_err": 73.46662}
[03/31 04:01:31][INFO] train_net.py:  692: Epoch 60 takes 501.82s. Epochs from 0 to 60 take 495.55s in average and 494.12s in median.
[03/31 04:01:31][INFO] train_net.py:  698: For epoch 60, each iteraction takes 26.41s in average. From epoch 0 to 60, each iteraction takes 26.08s in average.
[03/31 04:06:00][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.04830, "dt_data": 0.00151, "dt_net": 6.04679, "epoch": "62/600", "eta": "17:11:20", "gpu_mem": "27.10G", "grad_norm": 3.07204, "iter": "10/19", "loss": 3.28267, "lr": 0.09743, "top1_err": 88.44401, "top5_err": 74.34896}
[03/31 04:09:46][INFO] logging.py:   99: json_stats: {"RAM": "82.18/503.30G", "_type": "train_epoch_ssl", "dt": 1.35837, "dt_data": 1.35837, "dt_net": 22.81902, "epoch": "62/600", "eta": "3:51:24", "gpu_mem": "27.10G", "grad_norm": 2.19802, "loss": 3.27979, "lr": 0.09739, "top1_err": 88.22471, "top5_err": 73.79043}
[03/31 04:09:46][INFO] train_net.py:  692: Epoch 61 takes 494.66s. Epochs from 0 to 61 take 495.54s in average and 494.15s in median.
[03/31 04:09:46][INFO] train_net.py:  698: For epoch 61, each iteraction takes 26.03s in average. From epoch 0 to 61, each iteraction takes 26.08s in average.
[03/31 04:14:20][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.16603, "dt_data": 0.00091, "dt_net": 6.16512, "epoch": "63/600", "eta": "17:29:27", "gpu_mem": "27.10G", "grad_norm": 2.16034, "iter": "10/19", "loss": 3.25622, "lr": 0.09735, "top1_err": 88.33008, "top5_err": 73.32356}
[03/31 04:18:11][INFO] logging.py:   99: json_stats: {"RAM": "82.19/503.30G", "_type": "train_epoch_ssl", "dt": 1.42934, "dt_data": 1.42934, "dt_net": 37.91323, "epoch": "63/600", "eta": "4:03:03", "gpu_mem": "27.10G", "grad_norm": 3.44123, "loss": 3.25974, "lr": 0.09731, "top1_err": 88.00884, "top5_err": 73.27988}
[03/31 04:18:11][INFO] train_net.py:  692: Epoch 62 takes 504.75s. Epochs from 0 to 62 take 495.68s in average and 494.18s in median.
[03/31 04:18:11][INFO] train_net.py:  698: For epoch 62, each iteraction takes 26.57s in average. From epoch 0 to 62, each iteraction takes 26.09s in average.
[03/31 04:22:36][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.04188, "dt_data": 0.00070, "dt_net": 6.04117, "epoch": "64/600", "eta": "17:06:24", "gpu_mem": "27.10G", "grad_norm": 2.33886, "iter": "10/19", "loss": 3.23850, "lr": 0.09726, "top1_err": 87.72786, "top5_err": 71.95638}
[03/31 04:26:19][INFO] logging.py:   99: json_stats: {"RAM": "83.70/503.30G", "_type": "train_epoch_ssl", "dt": 0.99006, "dt_data": 0.99006, "dt_net": 5.87991, "epoch": "64/600", "eta": "2:48:02", "gpu_mem": "27.10G", "grad_norm": 2.43790, "loss": 3.24614, "lr": 0.09722, "top1_err": 88.28810, "top5_err": 73.20278}
[03/31 04:26:19][INFO] train_net.py:  692: Epoch 63 takes 488.85s. Epochs from 0 to 63 take 495.58s in average and 494.15s in median.
[03/31 04:26:19][INFO] train_net.py:  698: For epoch 63, each iteraction takes 25.73s in average. From epoch 0 to 63, each iteraction takes 26.08s in average.
[03/31 04:30:43][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.03683, "dt_data": 0.00060, "dt_net": 6.03623, "epoch": "65/600", "eta": "17:03:38", "gpu_mem": "27.10G", "grad_norm": 1.96882, "iter": "10/19", "loss": 3.22822, "lr": 0.09718, "top1_err": 87.32096, "top5_err": 71.06120}
[03/31 04:34:36][INFO] logging.py:   99: json_stats: {"RAM": "82.24/503.30G", "_type": "train_epoch_ssl", "dt": 1.23496, "dt_data": 1.23495, "dt_net": 10.17220, "epoch": "65/600", "eta": "3:29:12", "gpu_mem": "27.10G", "grad_norm": 3.03953, "loss": 3.22202, "lr": 0.09714, "top1_err": 87.31839, "top5_err": 71.73622}
[03/31 04:34:36][INFO] train_net.py:  692: Epoch 64 takes 496.32s. Epochs from 0 to 64 take 495.59s in average and 494.18s in median.
[03/31 04:34:36][INFO] train_net.py:  698: For epoch 64, each iteraction takes 26.12s in average. From epoch 0 to 64, each iteraction takes 26.08s in average.
[03/31 04:38:56][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 10.03602, "dt_data": 0.00061, "dt_net": 10.03541, "epoch": "66/600", "eta": "1 day, 4:18:35", "gpu_mem": "27.10G", "grad_norm": 2.78387, "iter": "10/19", "loss": 3.21426, "lr": 0.09709, "top1_err": 87.76041, "top5_err": 71.94010}
[03/31 04:42:38][INFO] logging.py:   99: json_stats: {"RAM": "82.16/503.30G", "_type": "train_epoch_ssl", "dt": 1.22212, "dt_data": 1.22212, "dt_net": 33.78824, "epoch": "66/600", "eta": "3:26:39", "gpu_mem": "27.10G", "grad_norm": 2.55721, "loss": 3.20353, "lr": 0.09705, "top1_err": 87.07168, "top5_err": 71.12973}
[03/31 04:42:38][INFO] train_net.py:  692: Epoch 65 takes 481.73s. Epochs from 0 to 65 take 495.38s in average and 494.15s in median.
[03/31 04:42:38][INFO] train_net.py:  698: For epoch 65, each iteraction takes 25.35s in average. From epoch 0 to 65, each iteraction takes 26.07s in average.
[03/31 04:47:02][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.02791, "dt_data": 0.00073, "dt_net": 6.02718, "epoch": "67/600", "eta": "16:58:18", "gpu_mem": "27.10G", "grad_norm": 2.43420, "iter": "10/19", "loss": 3.17979, "lr": 0.09700, "top1_err": 86.29557, "top5_err": 70.84961}
[03/31 04:50:50][INFO] logging.py:   99: json_stats: {"RAM": "82.17/503.30G", "_type": "train_epoch_ssl", "dt": 1.12323, "dt_data": 1.12323, "dt_net": 26.61609, "epoch": "67/600", "eta": "3:09:34", "gpu_mem": "27.10G", "grad_norm": 2.63844, "loss": 3.20254, "lr": 0.09696, "top1_err": 86.54057, "top5_err": 71.29249}
[03/31 04:50:50][INFO] train_net.py:  692: Epoch 66 takes 492.83s. Epochs from 0 to 66 take 495.34s in average and 494.12s in median.
[03/31 04:50:50][INFO] train_net.py:  698: For epoch 66, each iteraction takes 25.94s in average. From epoch 0 to 66, each iteraction takes 26.07s in average.
[03/31 04:55:26][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.12678, "dt_data": 0.00089, "dt_net": 6.12589, "epoch": "68/600", "eta": "17:13:04", "gpu_mem": "27.10G", "grad_norm": 2.92320, "iter": "10/19", "loss": 3.14366, "lr": 0.09691, "top1_err": 85.43294, "top5_err": 69.53125}
[03/31 04:59:28][INFO] logging.py:   99: json_stats: {"RAM": "82.59/503.30G", "_type": "train_epoch_ssl", "dt": 1.20726, "dt_data": 1.20726, "dt_net": 19.20734, "epoch": "68/600", "eta": "3:23:22", "gpu_mem": "27.10G", "grad_norm": 1.88078, "loss": 3.13572, "lr": 0.09687, "top1_err": 85.25048, "top5_err": 68.60266}
[03/31 04:59:28][INFO] train_net.py:  692: Epoch 67 takes 517.66s. Epochs from 0 to 67 take 495.67s in average and 494.15s in median.
[03/31 04:59:28][INFO] train_net.py:  698: For epoch 67, each iteraction takes 27.25s in average. From epoch 0 to 67, each iteraction takes 26.09s in average.
[03/31 05:03:51][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.06205, "dt_data": 0.00082, "dt_net": 6.06123, "epoch": "69/600", "eta": "17:00:14", "gpu_mem": "27.10G", "grad_norm": 2.53834, "iter": "10/19", "loss": 3.12294, "lr": 0.09682, "top1_err": 84.61914, "top5_err": 68.22917}
[03/31 05:07:47][INFO] logging.py:   99: json_stats: {"RAM": "82.18/503.30G", "_type": "train_epoch_ssl", "dt": 1.42795, "dt_data": 1.42795, "dt_net": 37.51800, "epoch": "69/600", "eta": "4:00:06", "gpu_mem": "27.10G", "grad_norm": 2.42300, "loss": 3.11395, "lr": 0.09678, "top1_err": 85.08087, "top5_err": 68.30797}
[03/31 05:07:47][INFO] train_net.py:  692: Epoch 68 takes 498.77s. Epochs from 0 to 68 take 495.71s in average and 494.18s in median.
[03/31 05:07:47][INFO] train_net.py:  698: For epoch 68, each iteraction takes 26.25s in average. From epoch 0 to 68, each iteraction takes 26.09s in average.
[03/31 05:12:15][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.10824, "dt_data": 0.00073, "dt_net": 6.10751, "epoch": "70/600", "eta": "17:06:04", "gpu_mem": "27.10G", "grad_norm": 3.49616, "iter": "10/19", "loss": 3.08595, "lr": 0.09673, "top1_err": 84.97721, "top5_err": 68.14778}
[03/31 05:16:11][INFO] logging.py:   99: json_stats: {"RAM": "88.24/503.30G", "_type": "train_epoch_ssl", "dt": 0.76541, "dt_data": 0.76541, "dt_net": 5.85638, "epoch": "70/600", "eta": "2:08:26", "gpu_mem": "27.10G", "grad_norm": 2.33264, "loss": 3.08021, "lr": 0.09668, "top1_err": 84.58230, "top5_err": 67.66207}
[03/31 05:16:11][INFO] train_net.py:  692: Epoch 69 takes 504.57s. Epochs from 0 to 69 take 495.84s in average and 494.35s in median.
[03/31 05:16:11][INFO] train_net.py:  698: For epoch 69, each iteraction takes 26.56s in average. From epoch 0 to 69, each iteraction takes 26.10s in average.
[03/31 05:20:43][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.16786, "dt_data": 0.00096, "dt_net": 6.16690, "epoch": "71/600", "eta": "17:14:08", "gpu_mem": "27.10G", "grad_norm": 2.21037, "iter": "10/19", "loss": 3.04384, "lr": 0.09663, "top1_err": 84.52148, "top5_err": 68.13151}
[03/31 05:24:34][INFO] logging.py:   99: json_stats: {"RAM": "85.12/503.30G", "_type": "train_epoch_ssl", "dt": 0.97514, "dt_data": 0.97514, "dt_net": 12.79706, "epoch": "71/600", "eta": "2:43:20", "gpu_mem": "27.10G", "grad_norm": 2.24368, "loss": 3.03584, "lr": 0.09659, "top1_err": 84.03920, "top5_err": 66.45251}
[03/31 05:24:34][INFO] train_net.py:  692: Epoch 70 takes 502.66s. Epochs from 0 to 70 take 495.94s in average and 494.52s in median.
[03/31 05:24:34][INFO] train_net.py:  698: For epoch 70, each iteraction takes 26.46s in average. From epoch 0 to 70, each iteraction takes 26.10s in average.
[03/31 05:29:01][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.58678, "dt_data": 0.00082, "dt_net": 6.58596, "epoch": "72/600", "eta": "18:22:17", "gpu_mem": "27.10G", "grad_norm": 3.26945, "iter": "10/19", "loss": 3.03117, "lr": 0.09654, "top1_err": 83.75651, "top5_err": 65.62500}
[03/31 05:32:53][INFO] logging.py:   99: json_stats: {"RAM": "82.18/503.30G", "_type": "train_epoch_ssl", "dt": 1.24375, "dt_data": 1.24375, "dt_net": 11.99586, "epoch": "72/600", "eta": "3:27:56", "gpu_mem": "27.10G", "grad_norm": 2.59350, "loss": 3.02861, "lr": 0.09649, "top1_err": 83.76336, "top5_err": 66.13384}
[03/31 05:32:53][INFO] train_net.py:  692: Epoch 71 takes 499.08s. Epochs from 0 to 71 take 495.98s in average and 494.59s in median.
[03/31 05:32:53][INFO] train_net.py:  698: For epoch 71, each iteraction takes 26.27s in average. From epoch 0 to 71, each iteraction takes 26.10s in average.
[03/31 05:37:19][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.12251, "dt_data": 0.00081, "dt_net": 6.12170, "epoch": "73/600", "eta": "17:02:39", "gpu_mem": "27.10G", "grad_norm": 2.21759, "iter": "10/19", "loss": 2.99633, "lr": 0.09644, "top1_err": 83.23567, "top5_err": 64.19271}
[03/31 05:41:03][INFO] logging.py:   99: json_stats: {"RAM": "82.29/503.30G", "_type": "train_epoch_ssl", "dt": 1.48477, "dt_data": 1.48476, "dt_net": 33.30215, "epoch": "73/600", "eta": "4:07:46", "gpu_mem": "27.10G", "grad_norm": 1.62456, "loss": 2.99868, "lr": 0.09640, "top1_err": 83.22197, "top5_err": 64.93284}
[03/31 05:41:03][INFO] train_net.py:  692: Epoch 72 takes 489.81s. Epochs from 0 to 72 take 495.90s in average and 494.52s in median.
[03/31 05:41:03][INFO] train_net.py:  698: For epoch 72, each iteraction takes 25.78s in average. From epoch 0 to 72, each iteraction takes 26.10s in average.
[03/31 05:45:32][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.10289, "dt_data": 0.00082, "dt_net": 6.10207, "epoch": "74/600", "eta": "16:57:27", "gpu_mem": "27.10G", "grad_norm": 2.07238, "iter": "10/19", "loss": 2.98351, "lr": 0.09635, "top1_err": 83.36589, "top5_err": 65.02279}
[03/31 05:49:32][INFO] logging.py:   99: json_stats: {"RAM": "82.16/503.30G", "_type": "train_epoch_ssl", "dt": 1.29284, "dt_data": 1.29284, "dt_net": 5.90649, "epoch": "74/600", "eta": "3:35:19", "gpu_mem": "27.10G", "grad_norm": 2.22666, "loss": 2.97959, "lr": 0.09630, "top1_err": 82.75253, "top5_err": 64.76151}
[03/31 05:49:32][INFO] train_net.py:  692: Epoch 73 takes 509.54s. Epochs from 0 to 73 take 496.08s in average and 494.59s in median.
[03/31 05:49:32][INFO] train_net.py:  698: For epoch 73, each iteraction takes 26.82s in average. From epoch 0 to 73, each iteraction takes 26.11s in average.
[03/31 05:53:57][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.14071, "dt_data": 0.00084, "dt_net": 6.13987, "epoch": "75/600", "eta": "17:01:48", "gpu_mem": "27.10G", "grad_norm": 1.92181, "iter": "10/19", "loss": 2.98313, "lr": 0.09625, "top1_err": 83.28450, "top5_err": 65.90168}
[03/31 05:57:49][INFO] logging.py:   99: json_stats: {"RAM": "82.20/503.30G", "_type": "train_epoch_ssl", "dt": 1.37502, "dt_data": 1.37502, "dt_net": 27.42805, "epoch": "75/600", "eta": "3:48:35", "gpu_mem": "27.10G", "grad_norm": 3.75186, "loss": 2.98126, "lr": 0.09620, "top1_err": 82.82620, "top5_err": 64.87459}
[03/31 05:57:49][INFO] train_net.py:  692: Epoch 74 takes 496.38s. Epochs from 0 to 74 take 496.08s in average and 494.66s in median.
[03/31 05:57:49][INFO] train_net.py:  698: For epoch 74, each iteraction takes 26.13s in average. From epoch 0 to 74, each iteraction takes 26.11s in average.
[03/31 06:02:25][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.13463, "dt_data": 0.00067, "dt_net": 6.13396, "epoch": "76/600", "eta": "16:58:51", "gpu_mem": "27.10G", "grad_norm": 3.32377, "iter": "10/19", "loss": 2.96918, "lr": 0.09615, "top1_err": 82.66601, "top5_err": 64.97395}
[03/31 06:06:26][INFO] logging.py:   99: json_stats: {"RAM": "88.43/503.30G", "_type": "train_epoch_ssl", "dt": 0.86619, "dt_data": 0.86619, "dt_net": 5.89106, "epoch": "76/600", "eta": "2:23:43", "gpu_mem": "27.10G", "grad_norm": 2.56113, "loss": 2.96570, "lr": 0.09610, "top1_err": 82.34477, "top5_err": 64.74095}
[03/31 06:06:26][INFO] train_net.py:  692: Epoch 75 takes 517.00s. Epochs from 0 to 75 take 496.36s in average and 494.79s in median.
[03/31 06:06:26][INFO] train_net.py:  698: For epoch 75, each iteraction takes 27.21s in average. From epoch 0 to 75, each iteraction takes 26.12s in average.
[03/31 06:10:47][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.04753, "dt_data": 0.00076, "dt_net": 6.04676, "epoch": "77/600", "eta": "16:42:28", "gpu_mem": "27.10G", "grad_norm": 2.75505, "iter": "10/19", "loss": 2.96127, "lr": 0.09604, "top1_err": 81.88476, "top5_err": 63.73698}
[03/31 06:14:31][INFO] logging.py:   99: json_stats: {"RAM": "85.95/503.30G", "_type": "train_epoch_ssl", "dt": 0.99062, "dt_data": 0.99062, "dt_net": 21.58899, "epoch": "77/600", "eta": "2:44:03", "gpu_mem": "27.10G", "grad_norm": 3.11725, "loss": 2.95794, "lr": 0.09600, "top1_err": 82.65316, "top5_err": 64.53193}
[03/31 06:14:31][INFO] train_net.py:  692: Epoch 76 takes 485.43s. Epochs from 0 to 76 take 496.22s in average and 494.66s in median.
[03/31 06:14:31][INFO] train_net.py:  698: For epoch 76, each iteraction takes 25.55s in average. From epoch 0 to 76, each iteraction takes 26.12s in average.
[03/31 06:19:02][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.09597, "dt_data": 0.00136, "dt_net": 6.09460, "epoch": "78/600", "eta": "16:48:34", "gpu_mem": "27.10G", "grad_norm": 2.23589, "iter": "10/19", "loss": 2.94208, "lr": 0.09594, "top1_err": 82.32421, "top5_err": 64.27409}
[03/31 06:22:59][INFO] logging.py:   99: json_stats: {"RAM": "88.90/503.30G", "_type": "train_epoch_ssl", "dt": 0.85740, "dt_data": 0.85740, "dt_net": 42.15205, "epoch": "78/600", "eta": "2:21:42", "gpu_mem": "27.10G", "grad_norm": 2.57453, "loss": 2.95096, "lr": 0.09589, "top1_err": 81.97813, "top5_err": 64.01967}
[03/31 06:22:59][INFO] train_net.py:  692: Epoch 77 takes 507.87s. Epochs from 0 to 77 take 496.37s in average and 494.79s in median.
[03/31 06:22:59][INFO] train_net.py:  698: For epoch 77, each iteraction takes 26.73s in average. From epoch 0 to 77, each iteraction takes 26.12s in average.
[03/31 06:27:34][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.10265, "dt_data": 0.00084, "dt_net": 6.10181, "epoch": "79/600", "eta": "16:47:45", "gpu_mem": "27.10G", "grad_norm": 3.65276, "iter": "10/19", "loss": 2.97088, "lr": 0.09584, "top1_err": 82.76367, "top5_err": 64.22526}
[03/31 06:31:36][INFO] logging.py:   99: json_stats: {"RAM": "89.17/503.30G", "_type": "train_epoch_ssl", "dt": 0.87989, "dt_data": 0.87989, "dt_net": 24.04267, "epoch": "79/600", "eta": "2:25:09", "gpu_mem": "27.10G", "grad_norm": 3.79432, "loss": 2.97344, "lr": 0.09579, "top1_err": 82.40474, "top5_err": 64.39830}
[03/31 06:31:36][INFO] train_net.py:  692: Epoch 78 takes 516.47s. Epochs from 0 to 78 take 496.62s in average and 494.92s in median.
[03/31 06:31:36][INFO] train_net.py:  698: For epoch 78, each iteraction takes 27.18s in average. From epoch 0 to 78, each iteraction takes 26.14s in average.
[03/31 06:35:57][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.02578, "dt_data": 0.00084, "dt_net": 6.02493, "epoch": "80/600", "eta": "16:33:08", "gpu_mem": "27.10G", "grad_norm": 2.00820, "iter": "10/19", "loss": 2.97165, "lr": 0.09573, "top1_err": 82.09635, "top5_err": 64.40429}
[03/31 06:39:43][INFO] logging.py:   99: json_stats: {"RAM": "83.72/503.30G", "_type": "train_epoch_ssl", "dt": 1.36378, "dt_data": 1.36378, "dt_net": 32.72345, "epoch": "80/600", "eta": "3:44:33", "gpu_mem": "27.10G", "grad_norm": 1.88140, "loss": 2.96257, "lr": 0.09568, "top1_err": 80.94161, "top5_err": 63.37719}
[03/31 06:39:43][INFO] train_net.py:  692: Epoch 79 takes 487.31s. Epochs from 0 to 79 take 496.50s in average and 494.79s in median.
[03/31 06:39:43][INFO] train_net.py:  698: For epoch 79, each iteraction takes 25.65s in average. From epoch 0 to 79, each iteraction takes 26.13s in average.
[03/31 06:44:27][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.13766, "dt_data": 0.00120, "dt_net": 6.13646, "epoch": "81/600", "eta": "16:49:38", "gpu_mem": "27.10G", "grad_norm": 1.93012, "iter": "10/19", "loss": 2.95261, "lr": 0.09563, "top1_err": 82.37305, "top5_err": 64.27409}
[03/31 06:48:31][INFO] logging.py:   99: json_stats: {"RAM": "86.48/503.30G", "_type": "train_epoch_ssl", "dt": 0.95387, "dt_data": 0.95387, "dt_net": 32.26217, "epoch": "81/600", "eta": "2:36:45", "gpu_mem": "27.10G", "grad_norm": 2.06951, "loss": 2.94363, "lr": 0.09558, "top1_err": 81.49671, "top5_err": 63.27782}
[03/31 06:48:31][INFO] train_net.py:  692: Epoch 80 takes 528.41s. Epochs from 0 to 80 take 496.90s in average and 494.92s in median.
[03/31 06:48:31][INFO] train_net.py:  698: For epoch 80, each iteraction takes 27.81s in average. From epoch 0 to 80, each iteraction takes 26.15s in average.
[03/31 06:53:02][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.07588, "dt_data": 0.00095, "dt_net": 6.07492, "epoch": "82/600", "eta": "16:37:33", "gpu_mem": "27.10G", "grad_norm": 2.41026, "iter": "10/19", "loss": 2.93193, "lr": 0.09552, "top1_err": 80.58268, "top5_err": 61.11653}
[03/31 06:56:49][INFO] logging.py:   99: json_stats: {"RAM": "87.64/503.30G", "_type": "train_epoch_ssl", "dt": 1.01487, "dt_data": 1.01487, "dt_net": 39.41930, "epoch": "82/600", "eta": "2:46:27", "gpu_mem": "27.10G", "grad_norm": 3.13230, "loss": 2.93192, "lr": 0.09547, "top1_err": 81.01699, "top5_err": 62.06654}
[03/31 06:56:49][INFO] train_net.py:  692: Epoch 81 takes 498.01s. Epochs from 0 to 81 take 496.91s in average and 495.23s in median.
[03/31 06:56:49][INFO] train_net.py:  698: For epoch 81, each iteraction takes 26.21s in average. From epoch 0 to 81, each iteraction takes 26.15s in average.
[03/31 07:01:09][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.03323, "dt_data": 0.00076, "dt_net": 6.03247, "epoch": "83/600", "eta": "16:28:38", "gpu_mem": "27.10G", "grad_norm": 2.22691, "iter": "10/19", "loss": 2.92259, "lr": 0.09541, "top1_err": 79.96419, "top5_err": 60.92122}
[03/31 07:05:05][INFO] logging.py:   99: json_stats: {"RAM": "83.70/503.30G", "_type": "train_epoch_ssl", "dt": 1.30152, "dt_data": 1.30152, "dt_net": 39.06520, "epoch": "83/600", "eta": "3:33:04", "gpu_mem": "27.10G", "grad_norm": 2.85570, "loss": 2.91921, "lr": 0.09536, "top1_err": 79.97190, "top5_err": 61.14652}
[03/31 07:05:05][INFO] train_net.py:  692: Epoch 82 takes 495.19s. Epochs from 0 to 82 take 496.89s in average and 495.19s in median.
[03/31 07:05:05][INFO] train_net.py:  698: For epoch 82, each iteraction takes 26.06s in average. From epoch 0 to 82, each iteraction takes 26.15s in average.
[03/31 07:09:42][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.12371, "dt_data": 0.00086, "dt_net": 6.12285, "epoch": "84/600", "eta": "16:41:31", "gpu_mem": "27.10G", "grad_norm": 2.25002, "iter": "10/19", "loss": 2.94466, "lr": 0.09530, "top1_err": 80.85937, "top5_err": 62.30468}
[03/31 07:13:42][INFO] logging.py:   99: json_stats: {"RAM": "83.69/503.30G", "_type": "train_epoch_ssl", "dt": 1.41002, "dt_data": 1.41001, "dt_net": 19.56739, "epoch": "84/600", "eta": "3:50:23", "gpu_mem": "27.10G", "grad_norm": 3.49368, "loss": 2.93042, "lr": 0.09525, "top1_err": 80.32312, "top5_err": 61.63994}
[03/31 07:13:42][INFO] train_net.py:  692: Epoch 83 takes 517.85s. Epochs from 0 to 83 take 497.14s in average and 495.37s in median.
[03/31 07:13:42][INFO] train_net.py:  698: For epoch 83, each iteraction takes 27.26s in average. From epoch 0 to 83, each iteraction takes 26.17s in average.
[03/31 07:18:03][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.03107, "dt_data": 0.00090, "dt_net": 6.03017, "epoch": "85/600", "eta": "16:24:28", "gpu_mem": "27.10G", "grad_norm": 2.12157, "iter": "10/19", "loss": 2.91723, "lr": 0.09519, "top1_err": 79.44336, "top5_err": 60.13997}
[03/31 07:21:54][INFO] logging.py:   99: json_stats: {"RAM": "83.69/503.30G", "_type": "train_epoch_ssl", "dt": 1.17496, "dt_data": 1.17496, "dt_net": 5.89896, "epoch": "85/600", "eta": "3:11:36", "gpu_mem": "27.10G", "grad_norm": 3.94638, "loss": 2.92149, "lr": 0.09514, "top1_err": 79.43736, "top5_err": 60.27104}
[03/31 07:21:54][INFO] train_net.py:  692: Epoch 84 takes 491.40s. Epochs from 0 to 84 take 497.07s in average and 495.19s in median.
[03/31 07:21:54][INFO] train_net.py:  698: For epoch 84, each iteraction takes 25.86s in average. From epoch 0 to 84, each iteraction takes 26.16s in average.
[03/31 07:26:28][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.10045, "dt_data": 0.00219, "dt_net": 6.09826, "epoch": "86/600", "eta": "16:33:51", "gpu_mem": "27.10G", "grad_norm": 2.75149, "iter": "10/19", "loss": 2.91628, "lr": 0.09508, "top1_err": 79.26432, "top5_err": 59.92838}
[03/31 07:30:29][INFO] logging.py:   99: json_stats: {"RAM": "83.73/503.30G", "_type": "train_epoch_ssl", "dt": 1.09584, "dt_data": 1.09584, "dt_net": 22.16600, "epoch": "86/600", "eta": "2:58:21", "gpu_mem": "27.10G", "grad_norm": 3.02977, "loss": 2.92575, "lr": 0.09502, "top1_err": 79.69264, "top5_err": 60.99575}
[03/31 07:30:29][INFO] train_net.py:  692: Epoch 85 takes 515.40s. Epochs from 0 to 85 take 497.29s in average and 495.37s in median.
[03/31 07:30:29][INFO] train_net.py:  698: For epoch 85, each iteraction takes 27.13s in average. From epoch 0 to 85, each iteraction takes 26.17s in average.
[03/31 07:35:13][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.11417, "dt_data": 0.00126, "dt_net": 6.11291, "epoch": "87/600", "eta": "16:34:09", "gpu_mem": "27.10G", "grad_norm": 2.28393, "iter": "10/19", "loss": 2.90080, "lr": 0.09496, "top1_err": 79.05274, "top5_err": 60.02604}
[03/31 07:39:14][INFO] logging.py:   99: json_stats: {"RAM": "83.72/503.30G", "_type": "train_epoch_ssl", "dt": 1.43388, "dt_data": 1.43388, "dt_net": 35.99102, "epoch": "87/600", "eta": "3:52:55", "gpu_mem": "27.10G", "grad_norm": 2.21947, "loss": 2.91048, "lr": 0.09491, "top1_err": 78.86170, "top5_err": 59.65769}
[03/31 07:39:14][INFO] train_net.py:  692: Epoch 86 takes 524.72s. Epochs from 0 to 86 take 497.60s in average and 495.55s in median.
[03/31 07:39:14][INFO] train_net.py:  698: For epoch 86, each iteraction takes 27.62s in average. From epoch 0 to 86, each iteraction takes 26.19s in average.
[03/31 07:43:44][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.07963, "dt_data": 0.00081, "dt_net": 6.07882, "epoch": "88/600", "eta": "16:26:37", "gpu_mem": "27.10G", "grad_norm": 3.31455, "iter": "10/19", "loss": 2.94311, "lr": 0.09485, "top1_err": 81.34766, "top5_err": 61.10026}
[03/31 07:47:37][INFO] logging.py:   99: json_stats: {"RAM": "87.58/503.30G", "_type": "train_epoch_ssl", "dt": 0.93237, "dt_data": 0.93237, "dt_net": 12.79705, "epoch": "88/600", "eta": "2:31:09", "gpu_mem": "27.10G", "grad_norm": 2.39733, "loss": 2.96086, "lr": 0.09479, "top1_err": 81.15748, "top5_err": 62.74842}
[03/31 07:47:37][INFO] train_net.py:  692: Epoch 87 takes 503.44s. Epochs from 0 to 87 take 497.67s in average and 495.93s in median.
[03/31 07:47:37][INFO] train_net.py:  698: For epoch 87, each iteraction takes 26.50s in average. From epoch 0 to 87, each iteraction takes 26.19s in average.
[03/31 07:52:10][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.09109, "dt_data": 0.00081, "dt_net": 6.09028, "epoch": "89/600", "eta": "16:26:33", "gpu_mem": "27.10G", "grad_norm": 2.47363, "iter": "10/19", "loss": 2.91449, "lr": 0.09473, "top1_err": 79.10156, "top5_err": 59.92838}
[03/31 07:56:05][INFO] logging.py:   99: json_stats: {"RAM": "83.70/503.30G", "_type": "train_epoch_ssl", "dt": 1.18515, "dt_data": 1.18515, "dt_net": 9.69564, "epoch": "89/600", "eta": "3:11:46", "gpu_mem": "27.10G", "grad_norm": 2.43380, "loss": 2.90969, "lr": 0.09467, "top1_err": 78.14556, "top5_err": 59.25850}
[03/31 07:56:05][INFO] train_net.py:  692: Epoch 88 takes 507.67s. Epochs from 0 to 88 take 497.78s in average and 496.30s in median.
[03/31 07:56:05][INFO] train_net.py:  698: For epoch 88, each iteraction takes 26.72s in average. From epoch 0 to 88, each iteraction takes 26.20s in average.
[03/31 08:00:25][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.06887, "dt_data": 0.00084, "dt_net": 6.06803, "epoch": "90/600", "eta": "16:21:02", "gpu_mem": "27.10G", "grad_norm": 2.36333, "iter": "10/19", "loss": 2.89169, "lr": 0.09461, "top1_err": 78.93880, "top5_err": 59.45638}
[03/31 08:04:16][INFO] logging.py:   99: json_stats: {"RAM": "83.70/503.30G", "_type": "train_epoch_ssl", "dt": 1.47846, "dt_data": 1.47846, "dt_net": 23.81056, "epoch": "90/600", "eta": "3:58:45", "gpu_mem": "27.10G", "grad_norm": 2.09000, "loss": 2.89601, "lr": 0.09456, "top1_err": 77.93311, "top5_err": 58.45155}
[03/31 08:04:16][INFO] train_net.py:  692: Epoch 89 takes 490.81s. Epochs from 0 to 89 take 497.70s in average and 495.93s in median.
[03/31 08:04:16][INFO] train_net.py:  698: For epoch 89, each iteraction takes 25.83s in average. From epoch 0 to 89, each iteraction takes 26.19s in average.
[03/31 08:08:40][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.05905, "dt_data": 0.00067, "dt_net": 6.05838, "epoch": "91/600", "eta": "16:17:31", "gpu_mem": "27.10G", "grad_norm": 3.30470, "iter": "10/19", "loss": 2.90454, "lr": 0.09449, "top1_err": 78.15755, "top5_err": 58.34961}
[03/31 08:12:33][INFO] logging.py:   99: json_stats: {"RAM": "83.71/503.30G", "_type": "train_epoch_ssl", "dt": 1.39597, "dt_data": 1.39597, "dt_net": 17.51383, "epoch": "91/600", "eta": "3:44:59", "gpu_mem": "27.10G", "grad_norm": 2.88676, "loss": 2.89360, "lr": 0.09444, "top1_err": 77.99479, "top5_err": 58.51322}
[03/31 08:12:33][INFO] train_net.py:  692: Epoch 90 takes 496.95s. Epochs from 0 to 90 take 497.69s in average and 496.30s in median.
[03/31 08:12:33][INFO] train_net.py:  698: For epoch 90, each iteraction takes 26.16s in average. From epoch 0 to 90, each iteraction takes 26.19s in average.
[03/31 08:16:57][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.07875, "dt_data": 0.00093, "dt_net": 6.07782, "epoch": "92/600", "eta": "16:18:46", "gpu_mem": "27.10G", "grad_norm": 2.83304, "iter": "10/19", "loss": 2.88595, "lr": 0.09437, "top1_err": 77.45768, "top5_err": 57.69857}
[03/31 08:20:44][INFO] logging.py:   99: json_stats: {"RAM": "83.72/503.30G", "_type": "train_epoch_ssl", "dt": 1.48687, "dt_data": 1.48687, "dt_net": 5.93378, "epoch": "92/600", "eta": "3:59:10", "gpu_mem": "27.10G", "grad_norm": 2.97476, "loss": 2.90146, "lr": 0.09432, "top1_err": 78.05818, "top5_err": 58.62116}
[03/31 08:20:44][INFO] train_net.py:  692: Epoch 91 takes 490.78s. Epochs from 0 to 91 take 497.62s in average and 495.93s in median.
[03/31 08:20:44][INFO] train_net.py:  698: For epoch 91, each iteraction takes 25.83s in average. From epoch 0 to 91, each iteraction takes 26.19s in average.
[03/31 08:25:14][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.11663, "dt_data": 0.00141, "dt_net": 6.11521, "epoch": "93/600", "eta": "16:22:56", "gpu_mem": "27.10G", "grad_norm": 2.29222, "iter": "10/19", "loss": 2.88567, "lr": 0.09425, "top1_err": 77.45768, "top5_err": 57.79622}
[03/31 08:29:02][INFO] logging.py:   99: json_stats: {"RAM": "83.75/503.30G", "_type": "train_epoch_ssl", "dt": 1.16649, "dt_data": 1.16649, "dt_net": 19.05823, "epoch": "93/600", "eta": "3:07:16", "gpu_mem": "27.10G", "grad_norm": 3.18907, "loss": 2.87534, "lr": 0.09419, "top1_err": 76.97368, "top5_err": 57.02097}
[03/31 08:29:02][INFO] train_net.py:  692: Epoch 92 takes 498.05s. Epochs from 0 to 92 take 497.62s in average and 496.30s in median.
[03/31 08:29:02][INFO] train_net.py:  698: For epoch 92, each iteraction takes 26.21s in average. From epoch 0 to 92, each iteraction takes 26.19s in average.
[03/31 08:33:26][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.06771, "dt_data": 0.00079, "dt_net": 6.06692, "epoch": "94/600", "eta": "16:13:09", "gpu_mem": "27.10G", "grad_norm": 2.77794, "iter": "10/19", "loss": 2.87798, "lr": 0.09413, "top1_err": 77.16471, "top5_err": 57.04752}
[03/31 08:37:10][INFO] logging.py:   99: json_stats: {"RAM": "90.27/503.30G", "_type": "train_epoch_ssl", "dt": 0.84075, "dt_data": 0.84075, "dt_net": 6.49945, "epoch": "94/600", "eta": "2:14:42", "gpu_mem": "27.10G", "grad_norm": 3.71250, "loss": 2.87607, "lr": 0.09407, "top1_err": 77.60930, "top5_err": 57.47327}
[03/31 08:37:10][INFO] train_net.py:  692: Epoch 93 takes 488.38s. Epochs from 0 to 93 take 497.53s in average and 495.93s in median.
[03/31 08:37:10][INFO] train_net.py:  698: For epoch 93, each iteraction takes 25.70s in average. From epoch 0 to 93, each iteraction takes 26.19s in average.
[03/31 08:41:43][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.14470, "dt_data": 0.00111, "dt_net": 6.14359, "epoch": "95/600", "eta": "16:23:33", "gpu_mem": "27.10G", "grad_norm": 2.27226, "iter": "10/19", "loss": 2.87292, "lr": 0.09401, "top1_err": 75.89518, "top5_err": 56.86849}
[03/31 08:45:40][INFO] logging.py:   99: json_stats: {"RAM": "83.70/503.30G", "_type": "train_epoch_ssl", "dt": 1.35879, "dt_data": 1.35879, "dt_net": 5.89769, "epoch": "95/600", "eta": "3:37:17", "gpu_mem": "27.10G", "grad_norm": 3.70431, "loss": 2.86475, "lr": 0.09395, "top1_err": 76.64645, "top5_err": 57.07751}
[03/31 08:45:40][INFO] train_net.py:  692: Epoch 94 takes 510.27s. Epochs from 0 to 94 take 497.66s in average and 496.30s in median.
[03/31 08:45:40][INFO] train_net.py:  698: For epoch 94, each iteraction takes 26.86s in average. From epoch 0 to 94, each iteraction takes 26.19s in average.
[03/31 08:50:19][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.37461, "dt_data": 0.00113, "dt_net": 6.37348, "epoch": "96/600", "eta": "16:58:20", "gpu_mem": "27.10G", "grad_norm": 2.27518, "iter": "10/19", "loss": 2.84940, "lr": 0.09388, "top1_err": 76.00911, "top5_err": 56.07096}
[03/31 08:54:14][INFO] logging.py:   99: json_stats: {"RAM": "92.86/503.30G", "_type": "train_epoch_ssl", "dt": 0.79582, "dt_data": 0.79582, "dt_net": 35.14849, "epoch": "96/600", "eta": "2:07:00", "gpu_mem": "27.10G", "grad_norm": 2.46378, "loss": 2.84564, "lr": 0.09382, "top1_err": 75.35122, "top5_err": 55.27344}
[03/31 08:54:14][INFO] train_net.py:  692: Epoch 95 takes 513.23s. Epochs from 0 to 95 take 497.82s in average and 496.31s in median.
[03/31 08:54:14][INFO] train_net.py:  698: For epoch 95, each iteraction takes 27.01s in average. From epoch 0 to 95, each iteraction takes 26.20s in average.
[03/31 08:58:52][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.17992, "dt_data": 0.00094, "dt_net": 6.17898, "epoch": "97/600", "eta": "16:25:17", "gpu_mem": "27.10G", "grad_norm": 2.53776, "iter": "10/19", "loss": 2.82711, "lr": 0.09376, "top1_err": 75.78125, "top5_err": 54.88281}
[03/31 09:02:52][INFO] logging.py:   99: json_stats: {"RAM": "85.19/503.30G", "_type": "train_epoch_ssl", "dt": 0.94631, "dt_data": 0.94631, "dt_net": 5.90588, "epoch": "97/600", "eta": "2:30:43", "gpu_mem": "27.10G", "grad_norm": 3.71805, "loss": 2.82141, "lr": 0.09370, "top1_err": 75.08909, "top5_err": 54.61897}
[03/31 09:02:52][INFO] train_net.py:  692: Epoch 96 takes 518.45s. Epochs from 0 to 96 take 498.03s in average and 496.32s in median.
[03/31 09:02:52][INFO] train_net.py:  698: For epoch 96, each iteraction takes 27.29s in average. From epoch 0 to 96, each iteraction takes 26.21s in average.
[03/31 09:07:29][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.08535, "dt_data": 0.00113, "dt_net": 6.08422, "epoch": "98/600", "eta": "16:08:16", "gpu_mem": "27.10G", "grad_norm": 5.34890, "iter": "10/19", "loss": 2.85063, "lr": 0.09363, "top1_err": 76.30208, "top5_err": 56.31510}
[03/31 09:11:33][INFO] logging.py:   99: json_stats: {"RAM": "83.70/503.30G", "_type": "train_epoch_ssl", "dt": 1.34037, "dt_data": 1.34037, "dt_net": 31.65740, "epoch": "98/600", "eta": "3:33:04", "gpu_mem": "27.10G", "grad_norm": 2.42796, "loss": 2.86222, "lr": 0.09357, "top1_err": 77.37973, "top5_err": 57.51096}
[03/31 09:11:33][INFO] train_net.py:  692: Epoch 97 takes 521.44s. Epochs from 0 to 97 take 498.27s in average and 496.35s in median.
[03/31 09:11:33][INFO] train_net.py:  698: For epoch 97, each iteraction takes 27.44s in average. From epoch 0 to 97, each iteraction takes 26.22s in average.
[03/31 09:16:10][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.12153, "dt_data": 0.00090, "dt_net": 6.12063, "epoch": "99/600", "eta": "16:12:05", "gpu_mem": "27.10G", "grad_norm": 2.40061, "iter": "10/19", "loss": 2.79598, "lr": 0.09350, "top1_err": 74.00716, "top5_err": 53.51562}
[03/31 09:19:57][INFO] logging.py:   99: json_stats: {"RAM": "83.70/503.30G", "_type": "train_epoch_ssl", "dt": 1.31883, "dt_data": 1.31883, "dt_net": 17.58041, "epoch": "99/600", "eta": "3:29:13", "gpu_mem": "27.10G", "grad_norm": 3.96882, "loss": 2.80315, "lr": 0.09344, "top1_err": 74.56483, "top5_err": 53.90796}
[03/31 09:19:57][INFO] train_net.py:  692: Epoch 98 takes 503.75s. Epochs from 0 to 98 take 498.33s in average and 496.38s in median.
[03/31 09:19:57][INFO] train_net.py:  698: For epoch 98, each iteraction takes 26.51s in average. From epoch 0 to 98, each iteraction takes 26.23s in average.
[03/31 09:24:26][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.09484, "dt_data": 0.00146, "dt_net": 6.09337, "epoch": "100/600", "eta": "16:05:55", "gpu_mem": "27.10G", "grad_norm": 3.75227, "iter": "10/19", "loss": 2.79640, "lr": 0.09337, "top1_err": 74.31640, "top5_err": 53.33659}
[03/31 09:28:13][INFO] logging.py:   99: json_stats: {"RAM": "87.56/503.30G", "_type": "train_epoch_ssl", "dt": 0.87699, "dt_data": 0.87699, "dt_net": 7.14833, "epoch": "100/600", "eta": "2:18:50", "gpu_mem": "27.10G", "grad_norm": 2.84221, "loss": 2.79478, "lr": 0.09331, "top1_err": 74.34724, "top5_err": 53.99362}
[03/31 09:28:13][INFO] train_net.py:  692: Epoch 99 takes 495.49s. Epochs from 0 to 99 take 498.30s in average and 496.35s in median.
[03/31 09:28:13][INFO] train_net.py:  698: For epoch 99, each iteraction takes 26.08s in average. From epoch 0 to 99, each iteraction takes 26.23s in average.
[03/31 09:32:40][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.05425, "dt_data": 0.00080, "dt_net": 6.05345, "epoch": "101/600", "eta": "15:57:34", "gpu_mem": "27.10G", "grad_norm": 2.86437, "iter": "10/19", "loss": 2.77056, "lr": 0.09324, "top1_err": 74.52799, "top5_err": 54.06901}
[03/31 09:36:22][INFO] logging.py:   99: json_stats: {"RAM": "83.60/503.30G", "_type": "train_epoch_ssl", "dt": 2.42363, "dt_data": 2.42363, "dt_net": 11.79613, "epoch": "101/600", "eta": "6:22:58", "gpu_mem": "27.10G", "grad_norm": 2.94573, "loss": 2.76851, "lr": 0.09318, "top1_err": 74.20333, "top5_err": 53.14898}
[03/31 09:36:22][INFO] train_net.py:  692: Epoch 100 takes 488.72s. Epochs from 0 to 100 take 498.21s in average and 496.32s in median.
[03/31 09:36:22][INFO] train_net.py:  698: For epoch 100, each iteraction takes 25.72s in average. From epoch 0 to 100, each iteraction takes 26.22s in average.
[03/31 09:40:57][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.06289, "dt_data": 0.00082, "dt_net": 6.06207, "epoch": "102/600", "eta": "15:57:01", "gpu_mem": "27.10G", "grad_norm": 2.73781, "iter": "10/19", "loss": 2.76322, "lr": 0.09311, "top1_err": 74.51171, "top5_err": 53.61328}
[03/31 09:44:47][INFO] logging.py:   99: json_stats: {"RAM": "88.75/503.30G", "_type": "train_epoch_ssl", "dt": 0.88236, "dt_data": 0.88236, "dt_net": 9.83542, "epoch": "102/600", "eta": "2:19:08", "gpu_mem": "27.10G", "grad_norm": 3.78127, "loss": 2.74806, "lr": 0.09304, "top1_err": 73.17194, "top5_err": 52.45511}
[03/31 09:44:47][INFO] train_net.py:  692: Epoch 101 takes 504.13s. Epochs from 0 to 101 take 498.26s in average and 496.35s in median.
[03/31 09:44:47][INFO] train_net.py:  698: For epoch 101, each iteraction takes 26.53s in average. From epoch 0 to 101, each iteraction takes 26.22s in average.
[03/31 09:49:23][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.12731, "dt_data": 0.00109, "dt_net": 6.12622, "epoch": "103/600", "eta": "16:05:15", "gpu_mem": "27.10G", "grad_norm": 3.05136, "iter": "10/19", "loss": 2.73261, "lr": 0.09297, "top1_err": 72.65625, "top5_err": 51.36719}
[03/31 09:53:21][INFO] logging.py:   99: json_stats: {"RAM": "83.67/503.30G", "_type": "train_epoch_ssl", "dt": 1.60277, "dt_data": 1.60277, "dt_net": 17.46849, "epoch": "103/600", "eta": "4:12:14", "gpu_mem": "27.10G", "grad_norm": 2.52495, "loss": 2.73492, "lr": 0.09291, "top1_err": 73.20963, "top5_err": 52.35231}
[03/31 09:53:21][INFO] train_net.py:  692: Epoch 102 takes 514.29s. Epochs from 0 to 102 take 498.42s in average and 496.38s in median.
[03/31 09:53:21][INFO] train_net.py:  698: For epoch 102, each iteraction takes 27.07s in average. From epoch 0 to 102, each iteraction takes 26.23s in average.
[03/31 09:57:43][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.01963, "dt_data": 0.00096, "dt_net": 6.01866, "epoch": "104/600", "eta": "15:46:23", "gpu_mem": "27.10G", "grad_norm": 2.45798, "iter": "10/19", "loss": 2.70063, "lr": 0.09284, "top1_err": 71.80989, "top5_err": 50.11393}
[03/31 10:01:30][INFO] logging.py:   99: json_stats: {"RAM": "83.66/503.30G", "_type": "train_epoch_ssl", "dt": 1.38835, "dt_data": 1.38835, "dt_net": 5.89853, "epoch": "104/600", "eta": "3:38:03", "gpu_mem": "27.10G", "grad_norm": 2.95989, "loss": 2.71064, "lr": 0.09278, "top1_err": 71.96923, "top5_err": 50.53283}
[03/31 10:01:30][INFO] train_net.py:  692: Epoch 103 takes 489.65s. Epochs from 0 to 103 take 498.34s in average and 496.35s in median.
[03/31 10:01:30][INFO] train_net.py:  698: For epoch 103, each iteraction takes 25.77s in average. From epoch 0 to 103, each iteraction takes 26.23s in average.
[03/31 10:05:58][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.07913, "dt_data": 0.00093, "dt_net": 6.07820, "epoch": "105/600", "eta": "15:53:48", "gpu_mem": "27.10G", "grad_norm": 2.48981, "iter": "10/19", "loss": 2.69273, "lr": 0.09270, "top1_err": 70.93099, "top5_err": 50.39062}
[03/31 10:09:50][INFO] logging.py:   99: json_stats: {"RAM": "87.62/503.30G", "_type": "train_epoch_ssl", "dt": 0.90431, "dt_data": 0.90430, "dt_net": 6.21064, "epoch": "105/600", "eta": "2:21:44", "gpu_mem": "27.10G", "grad_norm": 2.69399, "loss": 2.68733, "lr": 0.09264, "top1_err": 70.92756, "top5_err": 49.82353}
[03/31 10:09:50][INFO] train_net.py:  692: Epoch 104 takes 499.28s. Epochs from 0 to 104 take 498.34s in average and 496.38s in median.
[03/31 10:09:50][INFO] train_net.py:  698: For epoch 104, each iteraction takes 26.28s in average. From epoch 0 to 104, each iteraction takes 26.23s in average.
[03/31 10:14:09][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.04766, "dt_data": 0.00085, "dt_net": 6.04680, "epoch": "106/600", "eta": "15:46:57", "gpu_mem": "27.10G", "grad_norm": 2.43451, "iter": "10/19", "loss": 2.67199, "lr": 0.09257, "top1_err": 70.96354, "top5_err": 50.37435}
[03/31 10:17:52][INFO] logging.py:   99: json_stats: {"RAM": "83.65/503.30G", "_type": "train_epoch_ssl", "dt": 1.37703, "dt_data": 1.37702, "dt_net": 33.06156, "epoch": "106/600", "eta": "3:35:24", "gpu_mem": "27.10G", "grad_norm": 3.12626, "loss": 2.66370, "lr": 0.09250, "top1_err": 70.07093, "top5_err": 48.81613}
[03/31 10:17:52][INFO] train_net.py:  692: Epoch 105 takes 481.89s. Epochs from 0 to 105 take 498.19s in average and 496.35s in median.
[03/31 10:17:52][INFO] train_net.py:  698: For epoch 105, each iteraction takes 25.36s in average. From epoch 0 to 105, each iteraction takes 26.22s in average.
[03/31 10:22:20][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.15142, "dt_data": 0.00117, "dt_net": 6.15025, "epoch": "107/600", "eta": "16:01:15", "gpu_mem": "27.10G", "grad_norm": 3.86037, "iter": "10/19", "loss": 2.65784, "lr": 0.09243, "top1_err": 71.58203, "top5_err": 49.85352}
[03/31 10:26:13][INFO] logging.py:   99: json_stats: {"RAM": "83.64/503.30G", "_type": "train_epoch_ssl", "dt": 1.36440, "dt_data": 1.36440, "dt_net": 16.15470, "epoch": "107/600", "eta": "3:32:59", "gpu_mem": "27.10G", "grad_norm": 2.58539, "loss": 2.65348, "lr": 0.09236, "top1_err": 70.30393, "top5_err": 48.97889}
[03/31 10:26:13][INFO] train_net.py:  692: Epoch 106 takes 501.34s. Epochs from 0 to 106 take 498.22s in average and 496.38s in median.
[03/31 10:26:13][INFO] train_net.py:  698: For epoch 106, each iteraction takes 26.39s in average. From epoch 0 to 106, each iteraction takes 26.22s in average.
[03/31 10:30:43][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.29423, "dt_data": 0.41508, "dt_net": 5.87914, "epoch": "108/600", "eta": "16:21:35", "gpu_mem": "27.10G", "grad_norm": 3.63840, "iter": "10/19", "loss": 2.65215, "lr": 0.09229, "top1_err": 70.57291, "top5_err": 48.04687}
[03/31 10:34:28][INFO] logging.py:   99: json_stats: {"RAM": "83.67/503.30G", "_type": "train_epoch_ssl", "dt": 1.38055, "dt_data": 1.38054, "dt_net": 21.69671, "epoch": "108/600", "eta": "3:35:04", "gpu_mem": "27.10G", "grad_norm": 2.73184, "loss": 2.63989, "lr": 0.09222, "top1_err": 70.00925, "top5_err": 47.91838}
[03/31 10:34:28][INFO] train_net.py:  692: Epoch 107 takes 494.84s. Epochs from 0 to 107 take 498.19s in average and 496.35s in median.
[03/31 10:34:28][INFO] train_net.py:  698: For epoch 107, each iteraction takes 26.04s in average. From epoch 0 to 107, each iteraction takes 26.22s in average.
[03/31 10:38:55][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.06731, "dt_data": 0.00063, "dt_net": 6.06668, "epoch": "109/600", "eta": "15:44:16", "gpu_mem": "27.10G", "grad_norm": 2.86776, "iter": "10/19", "loss": 2.66433, "lr": 0.09215, "top1_err": 72.34700, "top5_err": 50.53711}
[03/31 10:42:50][INFO] logging.py:   99: json_stats: {"RAM": "83.97/503.30G", "_type": "train_epoch_ssl", "dt": 1.10551, "dt_data": 1.10551, "dt_net": 15.00731, "epoch": "109/600", "eta": "2:51:52", "gpu_mem": "27.10G", "grad_norm": 2.62473, "loss": 2.65079, "lr": 0.09208, "top1_err": 70.68085, "top5_err": 49.51000}
[03/31 10:42:50][INFO] train_net.py:  692: Epoch 108 takes 501.82s. Epochs from 0 to 108 take 498.22s in average and 496.38s in median.
[03/31 10:42:50][INFO] train_net.py:  698: For epoch 108, each iteraction takes 26.41s in average. From epoch 0 to 108, each iteraction takes 26.22s in average.
[03/31 10:47:16][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 8.54699, "dt_data": 0.00064, "dt_net": 8.54635, "epoch": "110/600", "eta": "22:07:29", "gpu_mem": "27.10G", "grad_norm": 3.49655, "iter": "10/19", "loss": 2.61889, "lr": 0.09201, "top1_err": 69.07552, "top5_err": 46.90755}
[03/31 10:51:03][INFO] logging.py:   99: json_stats: {"RAM": "83.64/503.30G", "_type": "train_epoch_ssl", "dt": 1.43494, "dt_data": 1.43494, "dt_net": 9.97445, "epoch": "110/600", "eta": "3:42:38", "gpu_mem": "27.10G", "grad_norm": 2.18566, "loss": 2.62725, "lr": 0.09194, "top1_err": 69.56551, "top5_err": 47.69737}
[03/31 10:51:03][INFO] train_net.py:  692: Epoch 109 takes 493.13s. Epochs from 0 to 109 take 498.17s in average and 496.35s in median.
[03/31 10:51:03][INFO] train_net.py:  698: For epoch 109, each iteraction takes 25.95s in average. From epoch 0 to 109, each iteraction takes 26.22s in average.
[03/31 10:55:41][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.16145, "dt_data": 0.00078, "dt_net": 6.16067, "epoch": "111/600", "eta": "15:55:01", "gpu_mem": "27.10G", "grad_norm": 2.66994, "iter": "10/19", "loss": 2.61227, "lr": 0.09187, "top1_err": 68.96159, "top5_err": 47.10286}
[03/31 10:59:37][INFO] logging.py:   99: json_stats: {"RAM": "83.64/503.30G", "_type": "train_epoch_ssl", "dt": 1.47950, "dt_data": 1.47949, "dt_net": 29.35439, "epoch": "111/600", "eta": "3:49:05", "gpu_mem": "27.10G", "grad_norm": 3.35799, "loss": 2.62032, "lr": 0.09180, "top1_err": 69.28111, "top5_err": 47.32730}
[03/31 10:59:37][INFO] train_net.py:  692: Epoch 110 takes 514.55s. Epochs from 0 to 110 take 498.32s in average and 496.38s in median.
[03/31 10:59:37][INFO] train_net.py:  698: For epoch 110, each iteraction takes 27.08s in average. From epoch 0 to 110, each iteraction takes 26.23s in average.
[03/31 11:04:00][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.10395, "dt_data": 0.00107, "dt_net": 6.10287, "epoch": "112/600", "eta": "15:44:10", "gpu_mem": "27.10G", "grad_norm": 3.35749, "iter": "10/19", "loss": 2.60186, "lr": 0.09172, "top1_err": 68.08268, "top5_err": 45.93099}
[03/31 11:07:48][INFO] logging.py:   99: json_stats: {"RAM": "83.64/503.30G", "_type": "train_epoch_ssl", "dt": 1.42653, "dt_data": 1.42653, "dt_net": 35.93682, "epoch": "112/600", "eta": "3:40:25", "gpu_mem": "27.10G", "grad_norm": 2.92896, "loss": 2.61053, "lr": 0.09165, "top1_err": 68.44675, "top5_err": 46.63000}
[03/31 11:07:48][INFO] train_net.py:  692: Epoch 111 takes 490.90s. Epochs from 0 to 111 take 498.26s in average and 496.35s in median.
[03/31 11:07:48][INFO] train_net.py:  698: For epoch 111, each iteraction takes 25.84s in average. From epoch 0 to 111, each iteraction takes 26.22s in average.
[03/31 11:12:36][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.15484, "dt_data": 0.00122, "dt_net": 6.15362, "epoch": "113/600", "eta": "15:50:06", "gpu_mem": "27.10G", "grad_norm": 2.50841, "iter": "10/19", "loss": 2.59398, "lr": 0.09158, "top1_err": 68.37564, "top5_err": 45.88216}
[03/31 11:16:38][INFO] logging.py:   99: json_stats: {"RAM": "88.18/503.30G", "_type": "train_epoch_ssl", "dt": 0.92721, "dt_data": 0.92721, "dt_net": 7.78054, "epoch": "113/600", "eta": "2:22:58", "gpu_mem": "27.10G", "grad_norm": 3.31350, "loss": 2.60933, "lr": 0.09151, "top1_err": 68.71744, "top5_err": 46.71566}
[03/31 11:16:38][INFO] train_net.py:  692: Epoch 112 takes 529.81s. Epochs from 0 to 112 take 498.53s in average and 496.38s in median.
[03/31 11:16:38][INFO] train_net.py:  698: For epoch 112, each iteraction takes 27.88s in average. From epoch 0 to 112, each iteraction takes 26.24s in average.
[03/31 11:21:09][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.06153, "dt_data": 0.00085, "dt_net": 6.06067, "epoch": "114/600", "eta": "15:33:46", "gpu_mem": "27.10G", "grad_norm": 2.68396, "iter": "10/19", "loss": 2.60006, "lr": 0.09143, "top1_err": 69.25455, "top5_err": 47.10286}
[03/31 11:25:06][INFO] logging.py:   99: json_stats: {"RAM": "83.65/503.30G", "_type": "train_epoch_ssl", "dt": 1.42165, "dt_data": 1.42167, "dt_net": 38.87335, "epoch": "114/600", "eta": "3:38:46", "gpu_mem": "27.10G", "grad_norm": 3.19454, "loss": 2.61438, "lr": 0.09136, "top1_err": 69.41303, "top5_err": 47.68709}
[03/31 11:25:06][INFO] train_net.py:  692: Epoch 113 takes 507.55s. Epochs from 0 to 113 take 498.61s in average and 496.48s in median.
[03/31 11:25:06][INFO] train_net.py:  698: For epoch 113, each iteraction takes 26.71s in average. From epoch 0 to 113, each iteraction takes 26.24s in average.
[03/31 11:29:41][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.14467, "dt_data": 0.00065, "dt_net": 6.14403, "epoch": "115/600", "eta": "15:44:38", "gpu_mem": "27.10G", "grad_norm": 2.81929, "iter": "10/19", "loss": 2.59133, "lr": 0.09128, "top1_err": 68.45703, "top5_err": 46.25651}
[03/31 11:33:39][INFO] logging.py:   99: json_stats: {"RAM": "84.17/503.30G", "_type": "train_epoch_ssl", "dt": 1.15834, "dt_data": 1.15834, "dt_net": 29.11489, "epoch": "115/600", "eta": "2:57:53", "gpu_mem": "27.10G", "grad_norm": 3.16489, "loss": 2.59595, "lr": 0.09121, "top1_err": 69.05838, "top5_err": 46.71224}
[03/31 11:33:39][INFO] train_net.py:  692: Epoch 114 takes 513.18s. Epochs from 0 to 114 take 498.74s in average and 496.57s in median.
[03/31 11:33:39][INFO] train_net.py:  698: For epoch 114, each iteraction takes 27.01s in average. From epoch 0 to 114, each iteraction takes 26.25s in average.
[03/31 11:38:08][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.02945, "dt_data": 0.00091, "dt_net": 6.02853, "epoch": "116/600", "eta": "15:25:01", "gpu_mem": "27.10G", "grad_norm": 3.41332, "iter": "10/19", "loss": 2.55747, "lr": 0.09114, "top1_err": 66.32486, "top5_err": 44.53125}
[03/31 11:41:57][INFO] logging.py:   99: json_stats: {"RAM": "83.64/503.30G", "_type": "train_epoch_ssl", "dt": 1.25522, "dt_data": 1.25523, "dt_net": 40.76034, "epoch": "116/600", "eta": "3:12:22", "gpu_mem": "27.10G", "grad_norm": 3.07215, "loss": 2.57515, "lr": 0.09107, "top1_err": 66.59985, "top5_err": 44.79167}
[03/31 11:41:57][INFO] train_net.py:  692: Epoch 115 takes 498.18s. Epochs from 0 to 115 take 498.74s in average and 496.76s in median.
[03/31 11:41:57][INFO] train_net.py:  698: For epoch 115, each iteraction takes 26.22s in average. From epoch 0 to 115, each iteraction takes 26.25s in average.
[03/31 11:46:24][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.15440, "dt_data": 0.00074, "dt_net": 6.15366, "epoch": "117/600", "eta": "15:42:14", "gpu_mem": "27.10G", "grad_norm": 3.15127, "iter": "10/19", "loss": 2.56647, "lr": 0.09099, "top1_err": 66.06445, "top5_err": 43.66862}
[03/31 11:50:16][INFO] logging.py:   99: json_stats: {"RAM": "84.37/503.30G", "_type": "train_epoch_ssl", "dt": 0.95862, "dt_data": 0.95862, "dt_net": 30.37326, "epoch": "117/600", "eta": "2:26:36", "gpu_mem": "27.10G", "grad_norm": 3.17142, "loss": 2.56862, "lr": 0.09092, "top1_err": 66.73177, "top5_err": 44.54838}
[03/31 11:50:16][INFO] train_net.py:  692: Epoch 116 takes 499.08s. Epochs from 0 to 116 take 498.74s in average and 496.95s in median.
[03/31 11:50:16][INFO] train_net.py:  698: For epoch 116, each iteraction takes 26.27s in average. From epoch 0 to 116, each iteraction takes 26.25s in average.
[03/31 11:54:47][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.09504, "dt_data": 0.00100, "dt_net": 6.09403, "epoch": "118/600", "eta": "15:31:13", "gpu_mem": "27.10G", "grad_norm": 2.93907, "iter": "10/19", "loss": 2.57017, "lr": 0.09084, "top1_err": 66.24349, "top5_err": 43.99413}
[03/31 11:58:45][INFO] logging.py:   99: json_stats: {"RAM": "83.64/503.30G", "_type": "train_epoch_ssl", "dt": 1.43258, "dt_data": 1.43258, "dt_net": 39.47203, "epoch": "118/600", "eta": "3:38:38", "gpu_mem": "27.10G", "grad_norm": 2.32648, "loss": 2.56611, "lr": 0.09076, "top1_err": 66.70264, "top5_err": 44.18174}
[03/31 11:58:45][INFO] train_net.py:  692: Epoch 117 takes 508.76s. Epochs from 0 to 117 take 498.82s in average and 497.37s in median.
[03/31 11:58:45][INFO] train_net.py:  698: For epoch 117, each iteraction takes 26.78s in average. From epoch 0 to 117, each iteraction takes 26.25s in average.
[03/31 12:03:39][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.15989, "dt_data": 0.00082, "dt_net": 6.15907, "epoch": "119/600", "eta": "15:39:10", "gpu_mem": "27.10G", "grad_norm": 3.16484, "iter": "10/19", "loss": 2.57687, "lr": 0.09068, "top1_err": 67.20377, "top5_err": 45.32877}
[03/31 12:07:45][INFO] logging.py:   99: json_stats: {"RAM": "91.90/503.30G", "_type": "train_epoch_ssl", "dt": 0.92524, "dt_data": 0.92524, "dt_net": 5.89699, "epoch": "119/600", "eta": "2:20:55", "gpu_mem": "27.10G", "grad_norm": 2.52540, "loss": 2.56478, "lr": 0.09061, "top1_err": 66.65467, "top5_err": 44.43017}
[03/31 12:07:45][INFO] train_net.py:  692: Epoch 118 takes 540.01s. Epochs from 0 to 118 take 499.17s in average and 497.79s in median.
[03/31 12:07:45][INFO] train_net.py:  698: For epoch 118, each iteraction takes 28.42s in average. From epoch 0 to 118, each iteraction takes 26.27s in average.
[03/31 12:12:12][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.09184, "dt_data": 0.00094, "dt_net": 6.09091, "epoch": "120/600", "eta": "15:26:52", "gpu_mem": "27.10G", "grad_norm": 2.81933, "iter": "10/19", "loss": 2.50804, "lr": 0.09053, "top1_err": 65.16927, "top5_err": 41.38997}
[03/31 12:16:03][INFO] logging.py:   99: json_stats: {"RAM": "83.61/503.30G", "_type": "train_epoch_ssl", "dt": 1.60347, "dt_data": 1.60347, "dt_net": 32.87741, "epoch": "120/600", "eta": "4:03:43", "gpu_mem": "27.10G", "grad_norm": 3.05486, "loss": 2.52505, "lr": 0.09046, "top1_err": 65.65412, "top5_err": 42.57641}
[03/31 12:16:03][INFO] train_net.py:  692: Epoch 119 takes 498.19s. Epochs from 0 to 119 take 499.16s in average and 497.90s in median.
[03/31 12:16:03][INFO] train_net.py:  698: For epoch 119, each iteraction takes 26.22s in average. From epoch 0 to 119, each iteraction takes 26.27s in average.
[03/31 12:20:28][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.05162, "dt_data": 0.00080, "dt_net": 6.05082, "epoch": "121/600", "eta": "15:18:50", "gpu_mem": "27.10G", "grad_norm": 3.18986, "iter": "10/19", "loss": 2.53192, "lr": 0.09038, "top1_err": 65.64127, "top5_err": 42.57812}
[03/31 12:24:15][INFO] logging.py:   99: json_stats: {"RAM": "83.63/503.30G", "_type": "train_epoch_ssl", "dt": 1.24926, "dt_data": 1.24925, "dt_net": 22.97637, "epoch": "121/600", "eta": "3:09:29", "gpu_mem": "27.10G", "grad_norm": 3.42128, "loss": 2.53340, "lr": 0.09030, "top1_err": 65.50507, "top5_err": 42.80941}
[03/31 12:24:15][INFO] train_net.py:  692: Epoch 120 takes 492.20s. Epochs from 0 to 120 take 499.10s in average and 497.79s in median.
[03/31 12:24:15][INFO] train_net.py:  698: For epoch 120, each iteraction takes 25.91s in average. From epoch 0 to 120, each iteraction takes 26.27s in average.
[03/31 12:28:45][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.18363, "dt_data": 0.00066, "dt_net": 6.18297, "epoch": "122/600", "eta": "15:36:55", "gpu_mem": "27.10G", "grad_norm": 3.01043, "iter": "10/19", "loss": 2.54665, "lr": 0.09022, "top1_err": 66.43880, "top5_err": 43.60351}
[03/31 12:32:43][INFO] logging.py:   99: json_stats: {"RAM": "83.65/503.30G", "_type": "train_epoch_ssl", "dt": 1.19098, "dt_data": 1.19098, "dt_net": 5.89143, "epoch": "122/600", "eta": "3:00:15", "gpu_mem": "27.10G", "grad_norm": 2.45637, "loss": 2.53560, "lr": 0.09015, "top1_err": 66.29831, "top5_err": 43.39021}
[03/31 12:32:43][INFO] train_net.py:  692: Epoch 121 takes 507.94s. Epochs from 0 to 121 take 499.18s in average and 497.90s in median.
[03/31 12:32:43][INFO] train_net.py:  698: For epoch 121, each iteraction takes 26.73s in average. From epoch 0 to 121, each iteraction takes 26.27s in average.
[03/31 12:37:03][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.02198, "dt_data": 0.00074, "dt_net": 6.02124, "epoch": "123/600", "eta": "15:10:31", "gpu_mem": "27.10G", "grad_norm": 2.96938, "iter": "10/19", "loss": 2.50999, "lr": 0.09007, "top1_err": 66.08073, "top5_err": 42.74089}
[03/31 12:40:41][INFO] logging.py:   99: json_stats: {"RAM": "83.69/503.30G", "_type": "train_epoch_ssl", "dt": 1.39836, "dt_data": 1.39836, "dt_net": 21.55274, "epoch": "123/600", "eta": "3:31:12", "gpu_mem": "27.10G", "grad_norm": 3.38172, "loss": 2.51502, "lr": 0.08999, "top1_err": 64.63987, "top5_err": 41.58785}
[03/31 12:40:41][INFO] train_net.py:  692: Epoch 122 takes 477.91s. Epochs from 0 to 122 take 499.00s in average and 497.79s in median.
[03/31 12:40:41][INFO] train_net.py:  698: For epoch 122, each iteraction takes 25.15s in average. From epoch 0 to 122, each iteraction takes 26.26s in average.
[03/31 12:45:11][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.09611, "dt_data": 0.00117, "dt_net": 6.09494, "epoch": "124/600", "eta": "15:19:48", "gpu_mem": "27.10G", "grad_norm": 3.14553, "iter": "10/19", "loss": 2.55325, "lr": 0.08991, "top1_err": 66.09700, "top5_err": 43.32682}
[03/31 12:49:01][INFO] logging.py:   99: json_stats: {"RAM": "87.04/503.30G", "_type": "train_epoch_ssl", "dt": 0.87510, "dt_data": 0.87509, "dt_net": 5.90229, "epoch": "124/600", "eta": "2:11:53", "gpu_mem": "27.10G", "grad_norm": 2.87672, "loss": 2.54050, "lr": 0.08983, "top1_err": 65.42969, "top5_err": 43.19147}
[03/31 12:49:01][INFO] train_net.py:  692: Epoch 123 takes 500.13s. Epochs from 0 to 123 take 499.01s in average and 497.90s in median.
[03/31 12:49:01][INFO] train_net.py:  698: For epoch 123, each iteraction takes 26.32s in average. From epoch 0 to 123, each iteraction takes 26.26s in average.
[03/31 12:53:32][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.11301, "dt_data": 0.00079, "dt_net": 6.11221, "epoch": "125/600", "eta": "15:20:24", "gpu_mem": "27.10G", "grad_norm": 2.99807, "iter": "10/19", "loss": 2.50997, "lr": 0.08975, "top1_err": 65.07161, "top5_err": 41.19466}
[03/31 12:57:25][INFO] logging.py:   99: json_stats: {"RAM": "85.16/503.30G", "_type": "train_epoch_ssl", "dt": 1.02851, "dt_data": 1.02851, "dt_net": 12.93502, "epoch": "125/600", "eta": "2:34:41", "gpu_mem": "27.10G", "grad_norm": 2.46781, "loss": 2.51030, "lr": 0.08968, "top1_err": 64.18414, "top5_err": 41.06017}
[03/31 12:57:25][INFO] train_net.py:  692: Epoch 124 takes 503.54s. Epochs from 0 to 124 take 499.05s in average and 498.01s in median.
[03/31 12:57:25][INFO] train_net.py:  698: For epoch 124, each iteraction takes 26.50s in average. From epoch 0 to 124, each iteraction takes 26.27s in average.
[03/31 13:01:51][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.05896, "dt_data": 0.00092, "dt_net": 6.05803, "epoch": "126/600", "eta": "15:10:21", "gpu_mem": "27.10G", "grad_norm": 4.39233, "iter": "10/19", "loss": 2.47588, "lr": 0.08959, "top1_err": 63.94857, "top5_err": 40.20182}
[03/31 13:05:42][INFO] logging.py:   99: json_stats: {"RAM": "83.73/503.30G", "_type": "train_epoch_ssl", "dt": 1.46608, "dt_data": 1.46608, "dt_net": 38.32326, "epoch": "126/600", "eta": "3:40:03", "gpu_mem": "27.10G", "grad_norm": 2.59303, "loss": 2.50857, "lr": 0.08952, "top1_err": 64.62274, "top5_err": 41.65296}
[03/31 13:05:42][INFO] train_net.py:  692: Epoch 125 takes 497.50s. Epochs from 0 to 125 take 499.04s in average and 497.90s in median.
[03/31 13:05:42][INFO] train_net.py:  698: For epoch 125, each iteraction takes 26.18s in average. From epoch 0 to 125, each iteraction takes 26.27s in average.
[03/31 13:10:00][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.05605, "dt_data": 0.00096, "dt_net": 6.05508, "epoch": "127/600", "eta": "15:08:00", "gpu_mem": "27.10G", "grad_norm": 3.35492, "iter": "10/19", "loss": 2.49662, "lr": 0.08943, "top1_err": 62.97200, "top5_err": 40.10417}
[03/31 13:13:48][INFO] logging.py:   99: json_stats: {"RAM": "83.64/503.30G", "_type": "train_epoch_ssl", "dt": 1.11539, "dt_data": 1.11539, "dt_net": 24.42789, "epoch": "127/600", "eta": "2:47:03", "gpu_mem": "27.10G", "grad_norm": 5.12036, "loss": 2.63370, "lr": 0.08936, "top1_err": 68.90762, "top5_err": 47.48492}
[03/31 13:13:48][INFO] train_net.py:  692: Epoch 126 takes 485.48s. Epochs from 0 to 126 take 498.93s in average and 497.79s in median.
[03/31 13:13:48][INFO] train_net.py:  698: For epoch 126, each iteraction takes 25.55s in average. From epoch 0 to 126, each iteraction takes 26.26s in average.
[03/31 13:18:16][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.08217, "dt_data": 0.00094, "dt_net": 6.08122, "epoch": "128/600", "eta": "15:09:59", "gpu_mem": "27.10G", "grad_norm": 3.28339, "iter": "10/19", "loss": 2.67393, "lr": 0.08927, "top1_err": 73.25846, "top5_err": 51.07422}
[03/31 13:22:11][INFO] logging.py:   99: json_stats: {"RAM": "85.81/503.30G", "_type": "train_epoch_ssl", "dt": 0.89886, "dt_data": 0.89887, "dt_net": 12.82156, "epoch": "128/600", "eta": "2:14:20", "gpu_mem": "27.10G", "grad_norm": 2.93433, "loss": 2.62593, "lr": 0.08919, "top1_err": 69.80537, "top5_err": 48.18051}
[03/31 13:22:11][INFO] train_net.py:  692: Epoch 127 takes 503.21s. Epochs from 0 to 127 take 498.96s in average and 497.90s in median.
[03/31 13:22:11][INFO] train_net.py:  698: For epoch 127, each iteraction takes 26.48s in average. From epoch 0 to 127, each iteraction takes 26.26s in average.
[03/31 13:26:35][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.04821, "dt_data": 0.00054, "dt_net": 6.04767, "epoch": "129/600", "eta": "15:02:59", "gpu_mem": "27.10G", "grad_norm": 3.55465, "iter": "10/19", "loss": 2.53562, "lr": 0.08911, "top1_err": 63.86718, "top5_err": 41.71549}
[03/31 13:30:23][INFO] logging.py:   99: json_stats: {"RAM": "83.65/503.30G", "_type": "train_epoch_ssl", "dt": 1.49384, "dt_data": 1.49384, "dt_net": 14.00038, "epoch": "129/600", "eta": "3:42:47", "gpu_mem": "27.10G", "grad_norm": 2.46203, "loss": 2.51112, "lr": 0.08903, "top1_err": 63.74212, "top5_err": 41.27261}
[03/31 13:30:23][INFO] train_net.py:  692: Epoch 128 takes 492.22s. Epochs from 0 to 128 take 498.91s in average and 497.79s in median.
[03/31 13:30:23][INFO] train_net.py:  698: For epoch 128, each iteraction takes 25.91s in average. From epoch 0 to 128, each iteraction takes 26.26s in average.
[03/31 13:35:08][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.17912, "dt_data": 0.00090, "dt_net": 6.17822, "epoch": "130/600", "eta": "15:20:35", "gpu_mem": "27.10G", "grad_norm": 3.20124, "iter": "10/19", "loss": 2.48869, "lr": 0.08894, "top1_err": 63.96484, "top5_err": 40.12044}
[03/31 13:39:05][INFO] logging.py:   99: json_stats: {"RAM": "83.66/503.30G", "_type": "train_epoch_ssl", "dt": 1.27750, "dt_data": 1.27750, "dt_net": 23.36888, "epoch": "130/600", "eta": "3:10:07", "gpu_mem": "27.10G", "grad_norm": 2.80356, "loss": 2.47102, "lr": 0.08887, "top1_err": 63.21272, "top5_err": 39.53536}
[03/31 13:39:05][INFO] train_net.py:  692: Epoch 129 takes 522.22s. Epochs from 0 to 129 take 499.09s in average and 497.90s in median.
[03/31 13:39:05][INFO] train_net.py:  698: For epoch 129, each iteraction takes 27.49s in average. From epoch 0 to 129, each iteraction takes 26.27s in average.
[03/31 13:43:48][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.19434, "dt_data": 0.00138, "dt_net": 6.19296, "epoch": "131/600", "eta": "15:20:53", "gpu_mem": "27.10G", "grad_norm": 2.43606, "iter": "10/19", "loss": 2.46519, "lr": 0.08878, "top1_err": 62.61393, "top5_err": 39.38802}
[03/31 13:47:52][INFO] logging.py:   99: json_stats: {"RAM": "86.12/503.30G", "_type": "train_epoch_ssl", "dt": 1.17891, "dt_data": 1.17891, "dt_net": 5.86795, "epoch": "131/600", "eta": "2:55:04", "gpu_mem": "27.10G", "grad_norm": 2.19009, "loss": 2.46864, "lr": 0.08870, "top1_err": 63.33265, "top5_err": 40.05277}
[03/31 13:47:52][INFO] train_net.py:  692: Epoch 130 takes 526.98s. Epochs from 0 to 130 take 499.30s in average and 498.01s in median.
[03/31 13:47:52][INFO] train_net.py:  698: For epoch 130, each iteraction takes 27.74s in average. From epoch 0 to 130, each iteraction takes 26.28s in average.
[03/31 13:52:16][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.06659, "dt_data": 0.00078, "dt_net": 6.06581, "epoch": "132/600", "eta": "14:59:58", "gpu_mem": "27.10G", "grad_norm": 2.57704, "iter": "10/19", "loss": 2.42994, "lr": 0.08861, "top1_err": 62.51628, "top5_err": 38.29752}
[03/31 13:56:07][INFO] logging.py:   99: json_stats: {"RAM": "86.39/503.30G", "_type": "train_epoch_ssl", "dt": 0.96278, "dt_data": 0.96278, "dt_net": 38.90822, "epoch": "132/600", "eta": "2:22:40", "gpu_mem": "27.10G", "grad_norm": 3.10914, "loss": 2.44941, "lr": 0.08853, "top1_err": 62.35951, "top5_err": 38.80037}
[03/31 13:56:07][INFO] train_net.py:  692: Epoch 131 takes 494.46s. Epochs from 0 to 131 take 499.27s in average and 497.90s in median.
[03/31 13:56:07][INFO] train_net.py:  698: For epoch 131, each iteraction takes 26.02s in average. From epoch 0 to 131, each iteraction takes 26.28s in average.
[03/31 14:00:35][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.15858, "dt_data": 0.00060, "dt_net": 6.15798, "epoch": "133/600", "eta": "15:11:40", "gpu_mem": "27.10G", "grad_norm": 2.61630, "iter": "10/19", "loss": 2.45037, "lr": 0.08845, "top1_err": 62.10937, "top5_err": 39.20898}
[03/31 14:04:16][INFO] logging.py:   99: json_stats: {"RAM": "85.67/503.30G", "_type": "train_epoch_ssl", "dt": 1.11702, "dt_data": 1.11702, "dt_net": 5.88712, "epoch": "133/600", "eta": "2:45:10", "gpu_mem": "27.10G", "grad_norm": 3.14242, "loss": 2.44458, "lr": 0.08837, "top1_err": 62.20189, "top5_err": 39.49253}
[03/31 14:04:16][INFO] train_net.py:  692: Epoch 132 takes 488.93s. Epochs from 0 to 132 take 499.19s in average and 497.79s in median.
[03/31 14:04:16][INFO] train_net.py:  698: For epoch 132, each iteraction takes 25.73s in average. From epoch 0 to 132, each iteraction takes 26.27s in average.
[03/31 14:08:46][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.09559, "dt_data": 0.00102, "dt_net": 6.09457, "epoch": "134/600", "eta": "15:00:25", "gpu_mem": "27.10G", "grad_norm": 2.60337, "iter": "10/19", "loss": 2.42972, "lr": 0.08828, "top1_err": 62.56510, "top5_err": 38.13476}
[03/31 14:12:45][INFO] logging.py:   99: json_stats: {"RAM": "85.71/503.30G", "_type": "train_epoch_ssl", "dt": 1.36922, "dt_data": 1.36922, "dt_net": 9.21786, "epoch": "134/600", "eta": "3:22:02", "gpu_mem": "27.10G", "grad_norm": 2.48032, "loss": 2.42924, "lr": 0.08820, "top1_err": 62.01514, "top5_err": 38.55366}
[03/31 14:12:45][INFO] train_net.py:  692: Epoch 133 takes 509.01s. Epochs from 0 to 133 take 499.26s in average and 497.90s in median.
[03/31 14:12:45][INFO] train_net.py:  698: For epoch 133, each iteraction takes 26.79s in average. From epoch 0 to 133, each iteraction takes 26.28s in average.
[03/31 14:17:11][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.07793, "dt_data": 0.00084, "dt_net": 6.07709, "epoch": "135/600", "eta": "14:55:53", "gpu_mem": "27.10G", "grad_norm": 3.13287, "iter": "10/19", "loss": 2.42347, "lr": 0.08811, "top1_err": 61.32812, "top5_err": 38.18359}
[03/31 14:20:59][INFO] logging.py:   99: json_stats: {"RAM": "85.89/503.30G", "_type": "train_epoch_ssl", "dt": 1.05383, "dt_data": 1.05383, "dt_net": 31.33744, "epoch": "135/600", "eta": "2:35:10", "gpu_mem": "27.10G", "grad_norm": 3.01319, "loss": 2.43385, "lr": 0.08803, "top1_err": 61.24589, "top5_err": 38.50740}
[03/31 14:20:59][INFO] train_net.py:  692: Epoch 134 takes 493.77s. Epochs from 0 to 134 take 499.22s in average and 497.79s in median.
[03/31 14:20:59][INFO] train_net.py:  698: For epoch 134, each iteraction takes 25.99s in average. From epoch 0 to 134, each iteraction takes 26.27s in average.
[03/31 14:25:26][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.10093, "dt_data": 0.00083, "dt_net": 6.10009, "epoch": "136/600", "eta": "14:57:20", "gpu_mem": "27.10G", "grad_norm": 2.85188, "iter": "10/19", "loss": 2.41460, "lr": 0.08794, "top1_err": 60.00976, "top5_err": 36.75130}
[03/31 14:29:18][INFO] logging.py:   99: json_stats: {"RAM": "85.67/503.30G", "_type": "train_epoch_ssl", "dt": 1.24032, "dt_data": 1.24032, "dt_net": 9.84108, "epoch": "136/600", "eta": "3:02:14", "gpu_mem": "27.10G", "grad_norm": 2.59532, "loss": 2.40923, "lr": 0.08786, "top1_err": 60.25562, "top5_err": 36.83011}
[03/31 14:29:18][INFO] train_net.py:  692: Epoch 135 takes 499.42s. Epochs from 0 to 135 take 499.22s in average and 497.90s in median.
[03/31 14:29:18][INFO] train_net.py:  698: For epoch 135, each iteraction takes 26.29s in average. From epoch 0 to 135, each iteraction takes 26.27s in average.
[03/31 14:33:48][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.10331, "dt_data": 0.00096, "dt_net": 6.10234, "epoch": "137/600", "eta": "14:55:45", "gpu_mem": "27.10G", "grad_norm": 2.24828, "iter": "10/19", "loss": 2.38777, "lr": 0.08777, "top1_err": 59.30989, "top5_err": 36.53971}
[03/31 14:37:39][INFO] logging.py:   99: json_stats: {"RAM": "85.67/503.30G", "_type": "train_epoch_ssl", "dt": 1.06951, "dt_data": 1.06951, "dt_net": 8.70366, "epoch": "137/600", "eta": "2:36:48", "gpu_mem": "27.10G", "grad_norm": 2.67356, "loss": 2.39129, "lr": 0.08769, "top1_err": 59.33902, "top5_err": 36.17050}
[03/31 14:37:39][INFO] train_net.py:  692: Epoch 136 takes 501.03s. Epochs from 0 to 136 take 499.24s in average and 498.01s in median.
[03/31 14:37:39][INFO] train_net.py:  698: For epoch 136, each iteraction takes 26.37s in average. From epoch 0 to 136, each iteraction takes 26.28s in average.
[03/31 14:42:01][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.02069, "dt_data": 0.00076, "dt_net": 6.01993, "epoch": "138/600", "eta": "14:41:43", "gpu_mem": "27.10G", "grad_norm": 2.72593, "iter": "10/19", "loss": 2.39638, "lr": 0.08760, "top1_err": 59.16341, "top5_err": 36.75130}
[03/31 14:45:41][INFO] logging.py:   99: json_stats: {"RAM": "85.69/503.30G", "_type": "train_epoch_ssl", "dt": 1.38153, "dt_data": 1.38152, "dt_net": 23.98631, "epoch": "138/600", "eta": "3:22:06", "gpu_mem": "27.10G", "grad_norm": 3.22824, "loss": 2.39809, "lr": 0.08751, "top1_err": 60.42352, "top5_err": 37.12651}
[03/31 14:45:41][INFO] train_net.py:  692: Epoch 137 takes 481.55s. Epochs from 0 to 137 take 499.11s in average and 497.90s in median.
[03/31 14:45:41][INFO] train_net.py:  698: For epoch 137, each iteraction takes 25.34s in average. From epoch 0 to 137, each iteraction takes 26.27s in average.
[03/31 14:50:22][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.10302, "dt_data": 0.00115, "dt_net": 6.10187, "epoch": "139/600", "eta": "14:51:51", "gpu_mem": "27.10G", "grad_norm": 2.56433, "iter": "10/19", "loss": 2.36939, "lr": 0.08742, "top1_err": 59.58659, "top5_err": 35.44922}
[03/31 14:54:30][INFO] logging.py:   99: json_stats: {"RAM": "87.22/503.30G", "_type": "train_epoch_ssl", "dt": 1.29464, "dt_data": 1.29464, "dt_net": 27.96202, "epoch": "139/600", "eta": "3:08:59", "gpu_mem": "27.10G", "grad_norm": 2.78432, "loss": 2.38581, "lr": 0.08734, "top1_err": 59.57374, "top5_err": 36.11910}
[03/31 14:54:30][INFO] train_net.py:  692: Epoch 138 takes 529.10s. Epochs from 0 to 138 take 499.32s in average and 498.01s in median.
[03/31 14:54:30][INFO] train_net.py:  698: For epoch 138, each iteraction takes 27.85s in average. From epoch 0 to 138, each iteraction takes 26.28s in average.
[03/31 14:58:53][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.08140, "dt_data": 0.00097, "dt_net": 6.08043, "epoch": "140/600", "eta": "14:46:46", "gpu_mem": "27.10G", "grad_norm": 2.49132, "iter": "10/19", "loss": 2.38375, "lr": 0.08725, "top1_err": 59.45638, "top5_err": 37.04427}
[03/31 15:02:51][INFO] logging.py:   99: json_stats: {"RAM": "87.65/503.30G", "_type": "train_epoch_ssl", "dt": 1.04779, "dt_data": 1.04779, "dt_net": 11.33902, "epoch": "140/600", "eta": "2:32:37", "gpu_mem": "27.10G", "grad_norm": 3.75376, "loss": 2.37526, "lr": 0.08717, "top1_err": 58.99979, "top5_err": 35.94092}
[03/31 15:02:51][INFO] train_net.py:  692: Epoch 139 takes 500.96s. Epochs from 0 to 139 take 499.34s in average and 498.03s in median.
[03/31 15:02:51][INFO] train_net.py:  698: For epoch 139, each iteraction takes 26.37s in average. From epoch 0 to 139, each iteraction takes 26.28s in average.
[03/31 15:07:11][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.12233, "dt_data": 0.00065, "dt_net": 6.12168, "epoch": "141/600", "eta": "14:50:47", "gpu_mem": "27.10G", "grad_norm": 2.48964, "iter": "10/19", "loss": 2.36203, "lr": 0.08707, "top1_err": 58.49609, "top5_err": 35.04231}
[03/31 15:10:57][INFO] logging.py:   99: json_stats: {"RAM": "94.77/503.30G", "_type": "train_epoch_ssl", "dt": 0.90989, "dt_data": 0.90989, "dt_net": 22.27125, "epoch": "141/600", "eta": "2:12:14", "gpu_mem": "27.10G", "grad_norm": 2.40658, "loss": 2.35203, "lr": 0.08699, "top1_err": 57.29167, "top5_err": 33.72910}
[03/31 15:10:57][INFO] train_net.py:  692: Epoch 140 takes 486.23s. Epochs from 0 to 140 take 499.24s in average and 498.01s in median.
[03/31 15:10:57][INFO] train_net.py:  698: For epoch 140, each iteraction takes 25.59s in average. From epoch 0 to 140, each iteraction takes 26.28s in average.
[03/31 15:15:19][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.04500, "dt_data": 0.00068, "dt_net": 6.04432, "epoch": "142/600", "eta": "14:37:38", "gpu_mem": "27.10G", "grad_norm": 2.58858, "iter": "10/19", "loss": 2.33835, "lr": 0.08690, "top1_err": 56.83594, "top5_err": 33.08919}
[03/31 15:19:02][INFO] logging.py:   99: json_stats: {"RAM": "87.25/503.30G", "_type": "train_epoch_ssl", "dt": 1.48995, "dt_data": 1.48994, "dt_net": 16.75541, "epoch": "142/600", "eta": "3:36:05", "gpu_mem": "27.10G", "grad_norm": 2.79882, "loss": 2.35101, "lr": 0.08681, "top1_err": 57.52124, "top5_err": 34.18482}
[03/31 15:19:02][INFO] train_net.py:  692: Epoch 141 takes 485.12s. Epochs from 0 to 141 take 499.14s in average and 497.90s in median.
[03/31 15:19:02][INFO] train_net.py:  698: For epoch 141, each iteraction takes 25.53s in average. From epoch 0 to 141, each iteraction takes 26.27s in average.
[03/31 15:23:50][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.10682, "dt_data": 0.00099, "dt_net": 6.10583, "epoch": "143/600", "eta": "14:44:40", "gpu_mem": "27.10G", "grad_norm": 2.63581, "iter": "10/19", "loss": 2.32678, "lr": 0.08672, "top1_err": 59.08203, "top5_err": 34.39127}
[03/31 15:27:54][INFO] logging.py:   99: json_stats: {"RAM": "87.33/503.30G", "_type": "train_epoch_ssl", "dt": 1.23202, "dt_data": 1.23202, "dt_net": 17.22144, "epoch": "143/600", "eta": "2:58:17", "gpu_mem": "27.10G", "grad_norm": 2.79402, "loss": 2.34272, "lr": 0.08664, "top1_err": 57.52638, "top5_err": 34.35101}
[03/31 15:27:54][INFO] train_net.py:  692: Epoch 142 takes 532.08s. Epochs from 0 to 142 take 499.37s in average and 498.01s in median.
[03/31 15:27:54][INFO] train_net.py:  698: For epoch 142, each iteraction takes 28.00s in average. From epoch 0 to 142, each iteraction takes 26.28s in average.
[03/31 15:32:28][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.15663, "dt_data": 0.00090, "dt_net": 6.15573, "epoch": "144/600", "eta": "14:49:56", "gpu_mem": "27.10G", "grad_norm": 2.52555, "iter": "10/19", "loss": 2.33270, "lr": 0.08654, "top1_err": 57.79622, "top5_err": 33.52864}
[03/31 15:36:25][INFO] logging.py:   99: json_stats: {"RAM": "93.20/503.30G", "_type": "train_epoch_ssl", "dt": 0.94762, "dt_data": 0.94762, "dt_net": 40.01699, "epoch": "144/600", "eta": "2:16:49", "gpu_mem": "27.10G", "grad_norm": 2.75012, "loss": 2.32687, "lr": 0.08646, "top1_err": 56.58409, "top5_err": 33.51151}
[03/31 15:36:25][INFO] train_net.py:  692: Epoch 143 takes 511.13s. Epochs from 0 to 143 take 499.45s in average and 498.03s in median.
[03/31 15:36:25][INFO] train_net.py:  698: For epoch 143, each iteraction takes 26.90s in average. From epoch 0 to 143, each iteraction takes 26.29s in average.
[03/31 15:41:09][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.15069, "dt_data": 0.00097, "dt_net": 6.14971, "epoch": "145/600", "eta": "14:47:08", "gpu_mem": "27.10G", "grad_norm": 2.54493, "iter": "10/19", "loss": 2.31766, "lr": 0.08636, "top1_err": 56.44531, "top5_err": 33.51237}
[03/31 15:45:12][INFO] logging.py:   99: json_stats: {"RAM": "87.27/503.30G", "_type": "train_epoch_ssl", "dt": 1.72044, "dt_data": 1.72044, "dt_net": 37.37769, "epoch": "145/600", "eta": "4:07:52", "gpu_mem": "27.10G", "grad_norm": 2.59823, "loss": 2.32234, "lr": 0.08628, "top1_err": 55.57669, "top5_err": 32.90330}
[03/31 15:45:12][INFO] train_net.py:  692: Epoch 144 takes 527.23s. Epochs from 0 to 144 take 499.65s in average and 498.05s in median.
[03/31 15:45:12][INFO] train_net.py:  698: For epoch 144, each iteraction takes 27.75s in average. From epoch 0 to 144, each iteraction takes 26.30s in average.
[03/31 15:49:32][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.06043, "dt_data": 0.00066, "dt_net": 6.05976, "epoch": "146/600", "eta": "14:32:11", "gpu_mem": "27.10G", "grad_norm": 2.97718, "iter": "10/19", "loss": 2.31710, "lr": 0.08618, "top1_err": 56.44531, "top5_err": 32.34049}
[03/31 15:53:28][INFO] logging.py:   99: json_stats: {"RAM": "87.20/503.30G", "_type": "train_epoch_ssl", "dt": 1.03297, "dt_data": 1.03297, "dt_net": 5.89158, "epoch": "146/600", "eta": "2:28:29", "gpu_mem": "27.10G", "grad_norm": 2.92352, "loss": 2.31343, "lr": 0.08610, "top1_err": 55.75829, "top5_err": 32.58463}
[03/31 15:53:28][INFO] train_net.py:  692: Epoch 145 takes 495.46s. Epochs from 0 to 145 take 499.62s in average and 498.03s in median.
[03/31 15:53:28][INFO] train_net.py:  698: For epoch 145, each iteraction takes 26.08s in average. From epoch 0 to 145, each iteraction takes 26.30s in average.
[03/31 15:58:02][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.08444, "dt_data": 0.00076, "dt_net": 6.08368, "epoch": "147/600", "eta": "14:33:43", "gpu_mem": "27.10G", "grad_norm": 2.86044, "iter": "10/19", "loss": 2.30998, "lr": 0.08600, "top1_err": 56.55924, "top5_err": 33.12174}
[03/31 16:01:53][INFO] logging.py:   99: json_stats: {"RAM": "87.22/503.30G", "_type": "train_epoch_ssl", "dt": 1.35748, "dt_data": 1.35747, "dt_net": 38.08086, "epoch": "147/600", "eta": "3:14:43", "gpu_mem": "27.10G", "grad_norm": 3.27251, "loss": 2.30386, "lr": 0.08592, "top1_err": 56.17290, "top5_err": 32.43729}
[03/31 16:01:53][INFO] train_net.py:  692: Epoch 146 takes 505.09s. Epochs from 0 to 146 take 499.66s in average and 498.05s in median.
[03/31 16:01:53][INFO] train_net.py:  698: For epoch 146, each iteraction takes 26.58s in average. From epoch 0 to 146, each iteraction takes 26.30s in average.
[03/31 16:06:22][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.10453, "dt_data": 0.00111, "dt_net": 6.10342, "epoch": "148/600", "eta": "14:34:40", "gpu_mem": "27.10G", "grad_norm": 2.60884, "iter": "10/19", "loss": 2.28549, "lr": 0.08582, "top1_err": 56.25000, "top5_err": 32.47070}
[03/31 16:10:14][INFO] logging.py:   99: json_stats: {"RAM": "87.20/503.30G", "_type": "train_epoch_ssl", "dt": 1.31645, "dt_data": 1.31645, "dt_net": 19.40673, "epoch": "148/600", "eta": "3:08:24", "gpu_mem": "27.10G", "grad_norm": 3.05152, "loss": 2.29064, "lr": 0.08573, "top1_err": 55.84224, "top5_err": 32.71142}
[03/31 16:10:14][INFO] train_net.py:  692: Epoch 147 takes 501.40s. Epochs from 0 to 147 take 499.67s in average and 498.09s in median.
[03/31 16:10:14][INFO] train_net.py:  698: For epoch 147, each iteraction takes 26.39s in average. From epoch 0 to 147, each iteraction takes 26.30s in average.
[03/31 16:14:47][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.12219, "dt_data": 0.00104, "dt_net": 6.12114, "epoch": "149/600", "eta": "14:35:16", "gpu_mem": "27.10G", "grad_norm": 2.62959, "iter": "10/19", "loss": 2.27575, "lr": 0.08564, "top1_err": 54.41080, "top5_err": 30.68034}
[03/31 16:18:43][INFO] logging.py:   99: json_stats: {"RAM": "87.21/503.30G", "_type": "train_epoch_ssl", "dt": 1.17589, "dt_data": 1.17589, "dt_net": 16.92485, "epoch": "149/600", "eta": "2:47:55", "gpu_mem": "27.10G", "grad_norm": 2.66474, "loss": 2.29015, "lr": 0.08555, "top1_err": 55.60238, "top5_err": 31.76912}
[03/31 16:18:43][INFO] train_net.py:  692: Epoch 148 takes 509.01s. Epochs from 0 to 148 take 499.73s in average and 498.13s in median.
[03/31 16:18:43][INFO] train_net.py:  698: For epoch 148, each iteraction takes 26.79s in average. From epoch 0 to 148, each iteraction takes 26.30s in average.
[03/31 16:23:27][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.15138, "dt_data": 0.00119, "dt_net": 6.15019, "epoch": "150/600", "eta": "14:37:29", "gpu_mem": "27.10G", "grad_norm": 3.67000, "iter": "10/19", "loss": 2.28665, "lr": 0.08545, "top1_err": 56.25000, "top5_err": 32.12890}
[03/31 16:27:30][INFO] logging.py:   99: json_stats: {"RAM": "87.40/503.30G", "_type": "train_epoch_ssl", "dt": 1.18355, "dt_data": 1.18354, "dt_net": 17.33429, "epoch": "150/600", "eta": "2:48:38", "gpu_mem": "27.10G", "grad_norm": 3.00879, "loss": 2.29212, "lr": 0.08537, "top1_err": 55.79084, "top5_err": 32.51096}
[03/31 16:27:30][INFO] train_net.py:  692: Epoch 149 takes 526.63s. Epochs from 0 to 149 take 499.91s in average and 498.15s in median.
[03/31 16:27:30][INFO] train_net.py:  698: For epoch 149, each iteraction takes 27.72s in average. From epoch 0 to 149, each iteraction takes 26.31s in average.
[03/31 16:31:52][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.04963, "dt_data": 0.00055, "dt_net": 6.04908, "epoch": "151/600", "eta": "14:21:03", "gpu_mem": "27.10G", "grad_norm": 2.49188, "iter": "10/19", "loss": 2.27655, "lr": 0.08527, "top1_err": 54.32943, "top5_err": 31.47786}
[03/31 16:35:41][INFO] logging.py:   99: json_stats: {"RAM": "91.93/503.30G", "_type": "train_epoch_ssl", "dt": 0.88701, "dt_data": 0.88701, "dt_net": 5.88791, "epoch": "151/600", "eta": "2:06:06", "gpu_mem": "27.10G", "grad_norm": 2.62110, "loss": 2.26920, "lr": 0.08518, "top1_err": 53.68352, "top5_err": 30.85252}
[03/31 16:35:41][INFO] train_net.py:  692: Epoch 150 takes 490.16s. Epochs from 0 to 150 take 499.84s in average and 498.13s in median.
[03/31 16:35:41][INFO] train_net.py:  698: For epoch 150, each iteraction takes 25.80s in average. From epoch 0 to 150, each iteraction takes 26.31s in average.
[03/31 16:40:08][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.04578, "dt_data": 0.00058, "dt_net": 6.04520, "epoch": "152/600", "eta": "14:18:36", "gpu_mem": "27.10G", "grad_norm": 2.97128, "iter": "10/19", "loss": 2.28068, "lr": 0.08508, "top1_err": 55.04557, "top5_err": 31.80338}
[03/31 16:43:53][INFO] logging.py:   99: json_stats: {"RAM": "87.92/503.30G", "_type": "train_epoch_ssl", "dt": 0.97715, "dt_data": 0.97715, "dt_net": 11.38852, "epoch": "152/600", "eta": "2:18:37", "gpu_mem": "27.10G", "grad_norm": 3.52191, "loss": 2.26996, "lr": 0.08499, "top1_err": 54.60355, "top5_err": 31.16776}
[03/31 16:43:53][INFO] train_net.py:  692: Epoch 151 takes 491.40s. Epochs from 0 to 151 take 499.79s in average and 498.09s in median.
[03/31 16:43:53][INFO] train_net.py:  698: For epoch 151, each iteraction takes 25.86s in average. From epoch 0 to 151, each iteraction takes 26.30s in average.
[03/31 16:48:22][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.09231, "dt_data": 0.00073, "dt_net": 6.09157, "epoch": "153/600", "eta": "14:23:16", "gpu_mem": "27.10G", "grad_norm": 2.48286, "iter": "10/19", "loss": 2.25991, "lr": 0.08489, "top1_err": 53.53190, "top5_err": 29.86653}
[03/31 16:52:13][INFO] logging.py:   99: json_stats: {"RAM": "87.27/503.30G", "_type": "train_epoch_ssl", "dt": 1.44793, "dt_data": 1.44793, "dt_net": 6.00202, "epoch": "153/600", "eta": "3:24:56", "gpu_mem": "27.10G", "grad_norm": 2.62279, "loss": 2.25371, "lr": 0.08481, "top1_err": 53.52762, "top5_err": 30.16893}
[03/31 16:52:13][INFO] train_net.py:  692: Epoch 152 takes 500.19s. Epochs from 0 to 152 take 499.79s in average and 498.13s in median.
[03/31 16:52:13][INFO] train_net.py:  698: For epoch 152, each iteraction takes 26.33s in average. From epoch 0 to 152, each iteraction takes 26.30s in average.
[03/31 16:57:00][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.12181, "dt_data": 0.00091, "dt_net": 6.12090, "epoch": "154/600", "eta": "14:25:31", "gpu_mem": "27.10G", "grad_norm": 2.62774, "iter": "10/19", "loss": 2.24753, "lr": 0.08471, "top1_err": 53.19010, "top5_err": 29.62239}
[03/31 17:01:04][INFO] logging.py:   99: json_stats: {"RAM": "91.93/503.30G", "_type": "train_epoch_ssl", "dt": 0.99852, "dt_data": 0.99852, "dt_net": 14.11332, "epoch": "154/600", "eta": "2:21:00", "gpu_mem": "27.10G", "grad_norm": 2.57852, "loss": 2.24873, "lr": 0.08462, "top1_err": 53.10273, "top5_err": 29.66522}
[03/31 17:01:04][INFO] train_net.py:  692: Epoch 153 takes 531.31s. Epochs from 0 to 153 take 500.00s in average and 498.15s in median.
[03/31 17:01:04][INFO] train_net.py:  698: For epoch 153, each iteraction takes 27.96s in average. From epoch 0 to 153, each iteraction takes 26.32s in average.
[03/31 17:05:34][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.05486, "dt_data": 0.00087, "dt_net": 6.05398, "epoch": "155/600", "eta": "14:14:08", "gpu_mem": "27.10G", "grad_norm": 2.83163, "iter": "10/19", "loss": 2.23646, "lr": 0.08452, "top1_err": 53.15755, "top5_err": 28.54817}
[03/31 17:09:31][INFO] logging.py:   99: json_stats: {"RAM": "90.26/503.30G", "_type": "train_epoch_ssl", "dt": 0.87216, "dt_data": 0.87215, "dt_net": 26.66645, "epoch": "155/600", "eta": "2:02:53", "gpu_mem": "27.10G", "grad_norm": 2.76362, "loss": 2.23341, "lr": 0.08443, "top1_err": 53.30147, "top5_err": 29.30373}
[03/31 17:09:31][INFO] train_net.py:  692: Epoch 154 takes 506.42s. Epochs from 0 to 154 take 500.04s in average and 498.18s in median.
[03/31 17:09:31][INFO] train_net.py:  698: For epoch 154, each iteraction takes 26.65s in average. From epoch 0 to 154, each iteraction takes 26.32s in average.
[03/31 17:13:52][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.05341, "dt_data": 0.00149, "dt_net": 6.05191, "epoch": "156/600", "eta": "14:12:01", "gpu_mem": "27.10G", "grad_norm": 2.42980, "iter": "10/19", "loss": 2.22567, "lr": 0.08433, "top1_err": 53.77604, "top5_err": 29.36198}
[03/31 17:17:39][INFO] logging.py:   99: json_stats: {"RAM": "87.28/503.30G", "_type": "train_epoch_ssl", "dt": 1.45309, "dt_data": 1.45309, "dt_net": 15.42903, "epoch": "156/600", "eta": "3:24:17", "gpu_mem": "27.10G", "grad_norm": 2.68053, "loss": 2.22322, "lr": 0.08424, "top1_err": 53.00336, "top5_err": 28.99534}
[03/31 17:17:39][INFO] train_net.py:  692: Epoch 155 takes 488.04s. Epochs from 0 to 155 take 499.96s in average and 498.15s in median.
[03/31 17:17:39][INFO] train_net.py:  698: For epoch 155, each iteraction takes 25.69s in average. From epoch 0 to 155, each iteraction takes 26.31s in average.
[03/31 17:21:59][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 8.13818, "dt_data": 0.00063, "dt_net": 8.13754, "epoch": "157/600", "eta": "19:02:52", "gpu_mem": "27.10G", "grad_norm": 2.74221, "iter": "10/19", "loss": 2.21400, "lr": 0.08414, "top1_err": 52.09961, "top5_err": 27.96224}
[03/31 17:25:41][INFO] logging.py:   99: json_stats: {"RAM": "91.76/503.30G", "_type": "train_epoch_ssl", "dt": 0.92410, "dt_data": 0.92410, "dt_net": 10.12987, "epoch": "157/600", "eta": "2:09:37", "gpu_mem": "27.10G", "grad_norm": 3.44832, "loss": 2.20996, "lr": 0.08405, "top1_err": 51.56421, "top5_err": 28.21066}
[03/31 17:25:41][INFO] train_net.py:  692: Epoch 156 takes 482.50s. Epochs from 0 to 156 take 499.85s in average and 498.13s in median.
[03/31 17:25:41][INFO] train_net.py:  698: For epoch 156, each iteraction takes 25.39s in average. From epoch 0 to 156, each iteraction takes 26.31s in average.
[03/31 17:30:20][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.08616, "dt_data": 0.00122, "dt_net": 6.08494, "epoch": "158/600", "eta": "14:12:46", "gpu_mem": "27.10G", "grad_norm": 2.73146, "iter": "10/19", "loss": 2.24221, "lr": 0.08395, "top1_err": 53.56445, "top5_err": 30.02929}
[03/31 17:34:14][INFO] logging.py:   99: json_stats: {"RAM": "87.27/503.30G", "_type": "train_epoch_ssl", "dt": 1.18921, "dt_data": 1.18920, "dt_net": 38.73305, "epoch": "158/600", "eta": "2:46:26", "gpu_mem": "27.10G", "grad_norm": 2.40387, "loss": 2.22455, "lr": 0.08385, "top1_err": 52.44826, "top5_err": 29.32428}
[03/31 17:34:14][INFO] train_net.py:  692: Epoch 157 takes 512.54s. Epochs from 0 to 157 take 499.93s in average and 498.15s in median.
[03/31 17:34:14][INFO] train_net.py:  698: For epoch 157, each iteraction takes 26.98s in average. From epoch 0 to 157, each iteraction takes 26.31s in average.
[03/31 17:38:45][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.11084, "dt_data": 0.00088, "dt_net": 6.10996, "epoch": "159/600", "eta": "14:14:17", "gpu_mem": "27.10G", "grad_norm": 2.92377, "iter": "10/19", "loss": 2.20024, "lr": 0.08375, "top1_err": 52.44141, "top5_err": 27.71810}
[03/31 17:42:40][INFO] logging.py:   99: json_stats: {"RAM": "87.27/503.30G", "_type": "train_epoch_ssl", "dt": 1.40283, "dt_data": 1.40282, "dt_net": 39.19079, "epoch": "159/600", "eta": "3:15:53", "gpu_mem": "27.10G", "grad_norm": 2.42243, "loss": 2.20608, "lr": 0.08366, "top1_err": 52.17242, "top5_err": 28.22779}
[03/31 17:42:40][INFO] train_net.py:  692: Epoch 158 takes 506.52s. Epochs from 0 to 158 take 499.97s in average and 498.18s in median.
[03/31 17:42:40][INFO] train_net.py:  698: For epoch 158, each iteraction takes 26.66s in average. From epoch 0 to 158, each iteraction takes 26.31s in average.
[03/31 17:47:09][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.11671, "dt_data": 0.00099, "dt_net": 6.11572, "epoch": "160/600", "eta": "14:13:10", "gpu_mem": "27.10G", "grad_norm": 2.46659, "iter": "10/19", "loss": 2.20904, "lr": 0.08356, "top1_err": 52.45768, "top5_err": 28.74349}
[03/31 17:50:59][INFO] logging.py:   99: json_stats: {"RAM": "87.29/503.30G", "_type": "train_epoch_ssl", "dt": 1.42973, "dt_data": 1.42973, "dt_net": 38.99293, "epoch": "160/600", "eta": "3:19:12", "gpu_mem": "27.10G", "grad_norm": 2.77792, "loss": 2.19286, "lr": 0.08347, "top1_err": 50.98855, "top5_err": 27.67269}
[03/31 17:50:59][INFO] train_net.py:  692: Epoch 159 takes 499.13s. Epochs from 0 to 159 take 499.97s in average and 498.18s in median.
[03/31 17:50:59][INFO] train_net.py:  698: For epoch 159, each iteraction takes 26.27s in average. From epoch 0 to 159, each iteraction takes 26.31s in average.
[03/31 17:55:39][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.20376, "dt_data": 0.00126, "dt_net": 6.20249, "epoch": "161/600", "eta": "14:23:21", "gpu_mem": "27.10G", "grad_norm": 2.87638, "iter": "10/19", "loss": 2.20687, "lr": 0.08336, "top1_err": 52.57161, "top5_err": 28.17383}
[03/31 17:59:40][INFO] logging.py:   99: json_stats: {"RAM": "91.01/503.30G", "_type": "train_epoch_ssl", "dt": 1.07122, "dt_data": 1.07122, "dt_net": 17.94874, "epoch": "161/600", "eta": "2:28:54", "gpu_mem": "27.10G", "grad_norm": 3.10838, "loss": 2.20323, "lr": 0.08327, "top1_err": 52.27350, "top5_err": 28.46936}
[03/31 17:59:40][INFO] train_net.py:  692: Epoch 160 takes 520.15s. Epochs from 0 to 160 take 500.09s in average and 498.19s in median.
[03/31 17:59:40][INFO] train_net.py:  698: For epoch 160, each iteraction takes 27.38s in average. From epoch 0 to 160, each iteraction takes 26.32s in average.
[03/31 18:04:09][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.07910, "dt_data": 0.00089, "dt_net": 6.07821, "epoch": "162/600", "eta": "14:04:05", "gpu_mem": "27.10G", "grad_norm": 3.17680, "iter": "10/19", "loss": 2.18943, "lr": 0.08317, "top1_err": 52.01823, "top5_err": 28.12500}
[03/31 18:08:06][INFO] logging.py:   99: json_stats: {"RAM": "88.81/503.30G", "_type": "train_epoch_ssl", "dt": 1.28246, "dt_data": 1.28246, "dt_net": 39.93252, "epoch": "162/600", "eta": "2:57:52", "gpu_mem": "27.10G", "grad_norm": 3.64290, "loss": 2.20071, "lr": 0.08308, "top1_err": 52.02508, "top5_err": 28.41797}
[03/31 18:08:06][INFO] train_net.py:  692: Epoch 161 takes 506.95s. Epochs from 0 to 161 take 500.13s in average and 498.48s in median.
[03/31 18:08:06][INFO] train_net.py:  698: For epoch 161, each iteraction takes 26.68s in average. From epoch 0 to 161, each iteraction takes 26.32s in average.
[03/31 18:12:33][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.10330, "dt_data": 0.00082, "dt_net": 6.10248, "epoch": "163/600", "eta": "14:05:30", "gpu_mem": "27.10G", "grad_norm": 2.98028, "iter": "10/19", "loss": 2.19794, "lr": 0.08297, "top1_err": 53.46679, "top5_err": 28.51562}
[03/31 18:16:23][INFO] logging.py:   99: json_stats: {"RAM": "88.78/503.30G", "_type": "train_epoch_ssl", "dt": 1.25391, "dt_data": 1.25391, "dt_net": 8.97985, "epoch": "163/600", "eta": "2:53:30", "gpu_mem": "27.10G", "grad_norm": 2.61569, "loss": 2.18616, "lr": 0.08288, "top1_err": 51.68928, "top5_err": 27.39686}
[03/31 18:16:23][INFO] train_net.py:  692: Epoch 162 takes 496.78s. Epochs from 0 to 162 take 500.11s in average and 498.19s in median.
[03/31 18:16:23][INFO] train_net.py:  698: For epoch 162, each iteraction takes 26.15s in average. From epoch 0 to 162, each iteraction takes 26.32s in average.
[03/31 18:20:50][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.08780, "dt_data": 0.00081, "dt_net": 6.08699, "epoch": "164/600", "eta": "14:01:26", "gpu_mem": "27.10G", "grad_norm": 2.57216, "iter": "10/19", "loss": 2.19062, "lr": 0.08278, "top1_err": 50.92773, "top5_err": 26.66015}
[03/31 18:24:53][INFO] logging.py:   99: json_stats: {"RAM": "88.80/503.30G", "_type": "train_epoch_ssl", "dt": 1.24142, "dt_data": 1.24142, "dt_net": 19.47112, "epoch": "164/600", "eta": "2:51:23", "gpu_mem": "27.10G", "grad_norm": 2.94359, "loss": 2.18362, "lr": 0.08268, "top1_err": 50.14563, "top5_err": 27.21011}
[03/31 18:24:53][INFO] train_net.py:  692: Epoch 163 takes 509.78s. Epochs from 0 to 163 take 500.17s in average and 498.48s in median.
[03/31 18:24:53][INFO] train_net.py:  698: For epoch 163, each iteraction takes 26.83s in average. From epoch 0 to 163, each iteraction takes 26.32s in average.
[03/31 18:29:15][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.03631, "dt_data": 0.00079, "dt_net": 6.03552, "epoch": "165/600", "eta": "13:52:24", "gpu_mem": "27.10G", "grad_norm": 2.95537, "iter": "10/19", "loss": 2.16009, "lr": 0.08258, "top1_err": 48.92578, "top5_err": 26.00911}
[03/31 18:33:02][INFO] logging.py:   99: json_stats: {"RAM": "88.80/503.30G", "_type": "train_epoch_ssl", "dt": 1.22535, "dt_data": 1.22534, "dt_net": 6.50157, "epoch": "165/600", "eta": "2:48:46", "gpu_mem": "27.10G", "grad_norm": 2.85798, "loss": 2.16678, "lr": 0.08248, "top1_err": 49.12795, "top5_err": 26.36376}
[03/31 18:33:02][INFO] train_net.py:  692: Epoch 164 takes 488.88s. Epochs from 0 to 164 take 500.10s in average and 498.19s in median.
[03/31 18:33:02][INFO] train_net.py:  698: For epoch 164, each iteraction takes 25.73s in average. From epoch 0 to 164, each iteraction takes 26.32s in average.
[03/31 18:37:33][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.07893, "dt_data": 0.00090, "dt_net": 6.07802, "epoch": "166/600", "eta": "13:56:21", "gpu_mem": "27.10G", "grad_norm": 2.70737, "iter": "10/19", "loss": 2.15673, "lr": 0.08238, "top1_err": 49.51172, "top5_err": 25.99284}
[03/31 18:41:29][INFO] logging.py:   99: json_stats: {"RAM": "88.80/503.30G", "_type": "train_epoch_ssl", "dt": 1.36588, "dt_data": 1.36588, "dt_net": 5.88252, "epoch": "166/600", "eta": "3:07:42", "gpu_mem": "27.10G", "grad_norm": 2.67735, "loss": 2.16376, "lr": 0.08228, "top1_err": 50.14905, "top5_err": 26.37404}
[03/31 18:41:29][INFO] train_net.py:  692: Epoch 165 takes 507.55s. Epochs from 0 to 165 take 500.15s in average and 498.48s in median.
[03/31 18:41:29][INFO] train_net.py:  698: For epoch 165, each iteraction takes 26.71s in average. From epoch 0 to 165, each iteraction takes 26.32s in average.
[03/31 18:45:51][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.03804, "dt_data": 0.00060, "dt_net": 6.03744, "epoch": "167/600", "eta": "13:48:49", "gpu_mem": "27.10G", "grad_norm": 2.65455, "iter": "10/19", "loss": 2.16160, "lr": 0.08218, "top1_err": 50.58594, "top5_err": 27.13216}
[03/31 18:49:36][INFO] logging.py:   99: json_stats: {"RAM": "88.81/503.30G", "_type": "train_epoch_ssl", "dt": 1.21931, "dt_data": 1.21930, "dt_net": 22.66881, "epoch": "167/600", "eta": "2:47:10", "gpu_mem": "27.10G", "grad_norm": 3.35831, "loss": 2.15630, "lr": 0.08208, "top1_err": 49.14851, "top5_err": 26.44942}
[03/31 18:49:36][INFO] train_net.py:  692: Epoch 166 takes 486.12s. Epochs from 0 to 166 take 500.06s in average and 498.19s in median.
[03/31 18:49:36][INFO] train_net.py:  698: For epoch 166, each iteraction takes 25.59s in average. From epoch 0 to 166, each iteraction takes 26.32s in average.
[03/31 18:54:02][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.02855, "dt_data": 0.00110, "dt_net": 6.02745, "epoch": "168/600", "eta": "13:45:36", "gpu_mem": "27.10G", "grad_norm": 3.22939, "iter": "10/19", "loss": 2.14742, "lr": 0.08198, "top1_err": 49.03971, "top5_err": 25.69987}
[03/31 18:57:57][INFO] logging.py:   99: json_stats: {"RAM": "88.79/503.30G", "_type": "train_epoch_ssl", "dt": 1.23854, "dt_data": 1.23854, "dt_net": 26.83903, "epoch": "168/600", "eta": "2:49:25", "gpu_mem": "27.10G", "grad_norm": 2.99872, "loss": 2.15682, "lr": 0.08188, "top1_err": 49.63507, "top5_err": 26.44086}
[03/31 18:57:57][INFO] train_net.py:  692: Epoch 167 takes 501.20s. Epochs from 0 to 167 take 500.07s in average and 498.48s in median.
[03/31 18:57:57][INFO] train_net.py:  698: For epoch 167, each iteraction takes 26.38s in average. From epoch 0 to 167, each iteraction takes 26.32s in average.
[03/31 19:02:28][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.08536, "dt_data": 0.00101, "dt_net": 6.08435, "epoch": "169/600", "eta": "13:51:27", "gpu_mem": "27.10G", "grad_norm": 2.73765, "iter": "10/19", "loss": 2.13378, "lr": 0.08178, "top1_err": 48.42122, "top5_err": 25.74870}
[03/31 19:06:20][INFO] logging.py:   99: json_stats: {"RAM": "89.94/503.30G", "_type": "train_epoch_ssl", "dt": 1.07467, "dt_data": 1.07467, "dt_net": 22.46470, "epoch": "169/600", "eta": "2:26:39", "gpu_mem": "27.10G", "grad_norm": 2.81865, "loss": 2.13580, "lr": 0.08168, "top1_err": 48.61568, "top5_err": 25.76411}
[03/31 19:06:20][INFO] train_net.py:  692: Epoch 168 takes 503.11s. Epochs from 0 to 168 take 500.09s in average and 498.77s in median.
[03/31 19:06:20][INFO] train_net.py:  698: For epoch 168, each iteraction takes 26.48s in average. From epoch 0 to 168, each iteraction takes 26.32s in average.
[03/31 19:10:47][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.02345, "dt_data": 0.00078, "dt_net": 6.02266, "epoch": "170/600", "eta": "13:41:05", "gpu_mem": "27.10G", "grad_norm": 2.73896, "iter": "10/19", "loss": 2.12802, "lr": 0.08157, "top1_err": 48.33984, "top5_err": 24.88606}
[03/31 19:14:29][INFO] logging.py:   99: json_stats: {"RAM": "90.13/503.30G", "_type": "train_epoch_ssl", "dt": 0.97581, "dt_data": 0.97581, "dt_net": 21.33839, "epoch": "170/600", "eta": "2:12:51", "gpu_mem": "27.10G", "grad_norm": 2.55216, "loss": 2.12738, "lr": 0.08148, "top1_err": 47.57744, "top5_err": 24.81839}
[03/31 19:14:29][INFO] train_net.py:  692: Epoch 169 takes 488.76s. Epochs from 0 to 169 take 500.02s in average and 498.48s in median.
[03/31 19:14:29][INFO] train_net.py:  698: For epoch 169, each iteraction takes 25.72s in average. From epoch 0 to 169, each iteraction takes 26.32s in average.
[03/31 19:18:52][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.04401, "dt_data": 0.00141, "dt_net": 6.04260, "epoch": "171/600", "eta": "13:41:59", "gpu_mem": "27.10G", "grad_norm": 3.14907, "iter": "10/19", "loss": 2.11947, "lr": 0.08137, "top1_err": 48.24219, "top5_err": 24.90234}
[03/31 19:22:43][INFO] logging.py:   99: json_stats: {"RAM": "88.79/503.30G", "_type": "train_epoch_ssl", "dt": 1.05728, "dt_data": 1.05728, "dt_net": 12.25767, "epoch": "171/600", "eta": "2:23:37", "gpu_mem": "27.10G", "grad_norm": 2.76920, "loss": 2.13487, "lr": 0.08127, "top1_err": 47.77446, "top5_err": 25.52426}
[03/31 19:22:43][INFO] train_net.py:  692: Epoch 170 takes 494.57s. Epochs from 0 to 170 take 499.99s in average and 498.19s in median.
[03/31 19:22:43][INFO] train_net.py:  698: For epoch 170, each iteraction takes 26.03s in average. From epoch 0 to 170, each iteraction takes 26.32s in average.
[03/31 19:27:16][INFO] logging.py:   99: json_stats: {"_type": "train_iter_ssl", "dt": 6.06506, "dt_data": 0.00087, "dt_net": 6.06418, "epoch": "172/600", "eta": "13:42:55", "gpu_mem": "27.10G", "grad_norm": 2.67174, "iter": "10/19", "loss": 2.11617, "lr": 0.08117, "top1_err": 47.86784, "top5_err": 24.46289}
[03/31 19:31:13][INFO] logging.py:   99: json_stats: {"RAM": "88.77/503.30G", "_type": "train_epoch_ssl", "dt": 1.05985, "dt_data": 1.05985, "dt_net": 5.87911, "epoch": "172/600", "eta": "2:23:38", "gpu_mem": "27.10G", "grad_norm": 2.48744, "loss": 2.11291, "lr": 0.08107, "top1_err": 47.11657, "top5_err": 24.14165}
[03/31 19:31:13][INFO] train_net.py:  692: Epoch 171 takes 509.97s. Epochs from 0 to 171 take 500.05s in average and 498.48s in median.
[03/31 19:31:13][INFO] train_net.py:  698: For epoch 171, each iteraction takes 26.84s in average. From epoch 0 to 171, each iteraction takes 26.32s in average.
slurmstepd: error: *** JOB 454978 ON dgk422 CANCELLED AT 2023-03-31T19:34:38 DUE TO TIME LIMIT ***
